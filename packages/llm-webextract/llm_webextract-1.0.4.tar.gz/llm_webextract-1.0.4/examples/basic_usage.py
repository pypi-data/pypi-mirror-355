#!/usr/bin/env python3
"""
Basic Usage Example - WebExtract Library
==========================================

This example shows the simplest way to extract structured data from web pages.
Perfect for getting started with the library.

Requirements:
- Ollama running locally
- gemma3:27b model (or modify to use your available model)
"""

from webextract import WebExtractor, ConfigProfiles

def main():
    print("ğŸš€ WebExtract - Basic Usage Example")
    print("=" * 50)
    
    # Method 1: Use a pre-configured profile (easiest)
    print("\nğŸ“° Using News Scraping Profile:")
    news_extractor = WebExtractor(ConfigProfiles.news_scraping())
    
    # Test URL
    url = "https://dev.to/nodeshiftcloud/claude-4-opus-vs-sonnet-benchmarks-and-dev-workflow-with-claude-code-11fa"
    
    try:
        print(f"ğŸ” Extracting from: {url}")
        result = news_extractor.extract(url)
        
        if result:
            print("âœ… Extraction successful!")
            print(f"ğŸ¯ Confidence: {result.confidence:.1%}")
            
            # Basic information
            print(f"\nğŸ“„ Basic Info:")
            print(f"   Title: {result.content.title}")
            print(f"   Content length: {len(result.content.main_content)} characters")
            
            # LLM extracted data
            if result.structured_info:
                info = result.structured_info
                
                if 'summary' in info:
                    print(f"\nğŸ“ Summary:")
                    print(f"   {info['summary']}")
                
                if 'organizations' in info and info['organizations']:
                    print(f"\nğŸ¢ Organizations: {', '.join(info['organizations'])}")
                    
        else:
            print("âŒ Extraction failed")
            
    except Exception as e:
        print(f"âŒ Error: {e}")
        print("\nğŸ’¡ Troubleshooting:")
        print("   1. Make sure Ollama is running: ollama serve")
        print("   2. Check available models: ollama list")
        print("   3. Pull required model: ollama pull gemma3:27b")

    # Method 2: Simple default configuration
    print(f"\n" + "="*50)
    print("ğŸ”§ Using Default Configuration:")
    
    default_extractor = WebExtractor()  # Uses all defaults
    
    try:
        result = default_extractor.extract(url)
        if result:
            print("âœ… Default extraction successful!")
            print(f"ğŸ¯ Confidence: {result.confidence:.1%}")
            
            if result.structured_info and 'summary' in result.structured_info:
                summary = result.structured_info['summary'][:150] + "..." if len(result.structured_info['summary']) > 150 else result.structured_info['summary']
                print(f"ğŸ“ Summary: {summary}")
        else:
            print("âŒ Default extraction failed")
            
    except Exception as e:
        print(f"âŒ Error with default config: {e}")

if __name__ == "__main__":
    main()
