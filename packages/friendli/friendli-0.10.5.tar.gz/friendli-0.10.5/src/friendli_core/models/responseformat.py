"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations

from typing import Union

from pydantic import Discriminator, Tag
from typing_extensions import Annotated, TypeAliasType

from friendli_core.utils import get_discriminator

from .responseformatjsonobject import (
    ResponseFormatJSONObject,
    ResponseFormatJSONObjectTypedDict,
)
from .responseformatjsonschema import (
    ResponseFormatJSONSchema,
    ResponseFormatJSONSchemaTypedDict,
)
from .responseformatregex import ResponseFormatRegex, ResponseFormatRegexTypedDict
from .responseformattext import ResponseFormatText, ResponseFormatTextTypedDict

ResponseFormatTypedDict = TypeAliasType(
    "ResponseFormatTypedDict",
    Union[
        ResponseFormatJSONObjectTypedDict,
        ResponseFormatTextTypedDict,
        ResponseFormatJSONSchemaTypedDict,
        ResponseFormatRegexTypedDict,
    ],
)
r"""The enforced format of the model's output.

Note that the content of the output message may be truncated if it exceeds the `max_tokens`. You can check this by verifying that the `finish_reason` of the output message is `length`.

For more detailed information, please refer [here](https://friendli.ai/docs/guides/serverless_endpoints/structured-outputs).

***Important***
You must explicitly instruct the model to produce the desired output format using a system prompt or user message (e.g., `You are an API generating a valid JSON as output.`).
Otherwise, the model may result in an unending stream of whitespace or other characters.

**When `response_format` is specified, `min_tokens` field is unsupported.**
"""


ResponseFormat = Annotated[
    Union[
        Annotated[ResponseFormatJSONObject, Tag("json_object")],
        Annotated[ResponseFormatJSONSchema, Tag("json_schema")],
        Annotated[ResponseFormatRegex, Tag("regex")],
        Annotated[ResponseFormatText, Tag("text")],
    ],
    Discriminator(lambda m: get_discriminator(m, "type", "type")),
]
r"""The enforced format of the model's output.

Note that the content of the output message may be truncated if it exceeds the `max_tokens`. You can check this by verifying that the `finish_reason` of the output message is `length`.

For more detailed information, please refer [here](https://friendli.ai/docs/guides/serverless_endpoints/structured-outputs).

***Important***
You must explicitly instruct the model to produce the desired output format using a system prompt or user message (e.g., `You are an API generating a valid JSON as output.`).
Otherwise, the model may result in an unending stream of whitespace or other characters.

**When `response_format` is specified, `min_tokens` field is unsupported.**
"""
