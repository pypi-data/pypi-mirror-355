"""
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  WFGY SDK Â· Self-Healing Variance Gate for Any LLM       â”‚
â”‚----------------------------------------------------------â”‚
â”‚ ðŸ’Œ  Contact : hello@onestardao.com  /  TG @PSBigBig       â”‚
â”‚ ðŸŒ  Docs    : https://onestardao.com/papers               â”‚
â”‚ ðŸ™  GitHub  : https://github.com/onestardao/WFGY          â”‚
â”‚                                                          â”‚
â”‚ â˜… Star WFGY 1.0 â†’ Unlock 2.0                             â”‚
â”‚   10k â­ by **Aug 1st** = next-gen AI alchemy             â”‚
â”‚   Your click = our quantum leap                          â”‚
â”‚                                                          â”‚
â”‚ ðŸ”  Official PDF of WFGY 1.0 (Zenodo DOI):               â”‚
â”‚     https://doi.org/10.5281/zenodo.15630969              â”‚
â”‚     (Hosted on Zenodo â€“ trusted international archive)   â”‚
â”‚                                                          â”‚
â”‚ ðŸ§¬  WFGY BigBang Prompt Pack (v1.0):                     â”‚
â”‚     https://doi.org/10.5281/zenodo.15657016              â”‚
â”‚     (Prompts to trigger the gate; multilingual updates coming) â”‚
â”‚                                                          â”‚
â”‚ ðŸ§   Hidden folder inside repo: /I_am_not_lizardman        â”‚
â”‚     (X secret papers, wild prompts, and Einstein drama) â”‚
â”‚                                                          â”‚
â”‚ âš   GPT-2 demo is just the appetizer. With bigger LLMs,   â”‚
â”‚    WFGY activates variance-drop lasers and KL fireworks. â”‚
â”‚                                                          â”‚
â”‚ ðŸŽ®  Bonus: Honest Hero RPG Channel â†’                     â”‚
â”‚     https://www.youtube.com/@OneStarDao                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
"""
# bbam.py
# Attention Modulation (BBAM) â€” variance gating
# Author: PSBigBig & Contributors
# License: MIT

from __future__ import annotations
import logging
import numpy as np
from typing import Tuple

logger = logging.getLogger(__name__)


def modulate_attention(
    logits: np.ndarray,
    *,
    gamma: float = 0.5,
    window_size: int | None = None
) -> np.ndarray:
    """
    Apply variance-based gating to logits.

    Parameters
    ----------
    logits : np.ndarray
        Raw logits (any shape).
    gamma : float, optional
        Modulation strength (0 â†’ no effect).
    window_size : int or None, optional
        If provided, compute local std with the given sliding window
        (1D only). Otherwise, use global std of the tensor.

    Returns
    -------
    np.ndarray
        Modulated logits (same shape as input).
    """
    if window_size is None:
        sigma = float(np.std(logits))
        factor = np.exp(-gamma * sigma)
        logger.debug("BBAM - global Ïƒ = %.6f | factor = %.6f", sigma, factor)
        return logits * factor

    # Local (1-D) variant
    if logits.ndim != 1:
        raise ValueError("window_size is supported only for 1-D logits")

    pad = window_size // 2
    padded = np.pad(logits, (pad, pad), mode="reflect")
    modulated = np.empty_like(logits)

    for i in range(logits.size):
        window = padded[i : i + window_size]
        sigma = float(np.std(window))
        modulated[i] = logits[i] * np.exp(-gamma * sigma)

    logger.debug(
        "BBAM - local window=%d applied to %d logits", window_size, logits.size
    )
    return modulated

def run_demo() -> None:
    """Quick smoke-test for BBAM."""
    import numpy as np

    logits = np.random.randn(20)
    mod = modulate_attention(logits, gamma=0.6)
    print(f"BBAM demo | first 3 logits before/after: {logits[:3]} -> {mod[:3]}")


if __name__ == "__main__":
    run_demo()
