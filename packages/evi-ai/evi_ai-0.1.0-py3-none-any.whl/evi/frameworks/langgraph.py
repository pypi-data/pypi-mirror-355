"""
LangGraph framework implementation for the evi package.
"""
import os
import json
from typing import Dict, Any
from jinja2 import Environment, FileSystemLoader, Template

from .base import BaseFramework

# Default LangGraph system prompt
LANGGRAPH_SYSTEM_PROMPT = """
You are an agent system designer specializing in LangGraph. Your task is to take a natural language description of an agent system and convert it to a structured JSON configuration that can be used to generate LangGraph Python code.

The JSON should include:
1. nodes: List of nodes in the graph with name, description, and type (agent, tool, or conditional)
2. edges: List of connections between nodes with source, target, and condition (optional)
3. state: Description of the state that will be passed between nodes
4. entrypoint: The node where execution begins
5. tools: List of tools that will be available to the agents
6. output_file: Name of the output file to save the generated code

For each node, provide:
- name: A unique identifier for the node
- description: What the node is responsible for
- type: "agent", "tool", or "conditional"
- config: Additional configuration for the node (optional)

For each edge, provide:
- source: The name of the source node
- target: The name of the target node
- condition: The condition for following this edge (for conditional nodes)

For the state, provide a list of attributes that will be passed between nodes, with the following for each:
- name: Name of the attribute
- description: Description of what the attribute represents
- type: The data type of the attribute

Return just the JSON, ensuring it's properly formatted and valid.
"""

class LangGraphFramework(BaseFramework):
    """
    Framework handler for LangGraph agent framework.
    """
    
    def __init__(self):
        """Initialize the LangGraph framework handler."""
        # Locate the templates directory relative to this file
        self.template_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "templates")
        self.template_file = "langgraph.py.j2"
    
    def get_system_prompt(self) -> str:
        """
        Get the system prompt for the LangGraph framework.
        
        Returns:
            The system prompt as a string
        """
        return LANGGRAPH_SYSTEM_PROMPT
    
    def generate_code(self, config: Dict[str, Any]) -> str:
        """
        Generate LangGraph code from a JSON configuration.
        
        Args:
            config: The JSON configuration for the agent system
            
        Returns:
            The generated code as a string
            
        Raises:
            Exception: If code generation fails
        """
        try:
            # Validate the configuration
            if not self.validate_config(config):
                raise ValueError("Invalid LangGraph configuration")
                
            # Set up the Jinja2 environment
            env = Environment(
                loader=FileSystemLoader(self.template_dir),
                trim_blocks=True,
                lstrip_blocks=True
            )
            
            # Load the template
            try:
                template = env.get_template(self.template_file)
            except Exception as e:
                # If template not found, create a default template from predefined parts
                template = self._create_fallback_template(env)
            
            # Render the template with the configuration
            rendered_code = template.render(**config)
            
            return rendered_code
            
        except Exception as e:
            raise Exception(f"Error generating LangGraph code: {str(e)}")
    
    def _create_fallback_template(self, env: Environment) -> Template:
        """
        Create a fallback template when the template file is not found.
        
        Args:
            env: The Jinja2 environment
            
        Returns:
            A Jinja2 Template object
        """
        # Define template parts separately to avoid multi-line string syntax issues
        header = "# LangGraph Agent System\n# Generated by evi - Multi-Agent Framework Generator\n\n"
        imports = (
            "from typing import TypedDict, Annotated, Sequence, List\n"
            "from typing_extensions import Annotated\n"
            "from langgraph.graph import StateGraph, END\n"
            "from langchain_openai import ChatOpenAI\n"
            "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n"
            "from langchain_core.tools import tool\n\n"
        )
        
        state_class = (
            "# Define the state\n"
            "class GraphState(TypedDict):\n"
            "{%- for attr in state %}\n"
            "    {{ attr.name }}: {{ attr.type }}  # {{ attr.description }}\n"
            "{%- endfor %}\n\n"
        )
        
        tools_def = (
            "# Initialize tools\n"
            "{%- for tool in tools %}\n"
            "@tool(\"{{ tool.name }}\")\n"
            "def {{ tool.name }}({{ tool.args|join(', ') }}) -> str:\n"
            "    \"\"\"{{ tool.description }}\"\"\"\n"
            "    # TODO: Implement the tool functionality\n"
            "    return \"Result from {{ tool.name }}\"\n\n"
            "{%- endfor %}\n"
        )
        
        node_functions = (
            "# Define node functions\n"
            "{%- for node in nodes %}\n"
            "{%- if node.type == \"agent\" %}\n"
            "def {{ node.name }}_node(state: GraphState) -> GraphState:\n"
            "    \"\"\"{{ node.description }}\"\"\"\n"
            "    messages = [\n"
            "        SystemMessage(content=\"You are an assistant helping with a task.\"),\n"
            "        HumanMessage(content=f\"Current state: {state}\")\n"
            "    ]\n"
            "    \n"
            "    model = ChatOpenAI(temperature=0)\n"
            "    response = model.invoke(messages)\n"
            "    \n"
            "    # Process response and update state\n"
            "    # TODO: Add custom processing here\n"
            "    \n"
            "    return {**state, \"messages\": state[\"messages\"] + [response]}\n"
            "{%- elif node.type == \"tool\" %}\n"
            "def {{ node.name }}_node(state: GraphState) -> GraphState:\n"
            "    \"\"\"{{ node.description }}\"\"\"\n"
            "    # TODO: Implement tool logic here\n"
            "    {%- if node.config.tool %}\n"
            "    result = {{ node.config.tool }}(**state[\"{{ node.config.input }}\"])\n"
            "    return {**state, \"{{ node.config.output }}\": result}\n"
            "    {%- else %}\n"
            "    # Default implementation\n"
            "    return state\n"
            "    {%- endif %}\n"
            "{%- elif node.type == \"conditional\" %}\n"
            "def {{ node.name }}_node(state: GraphState) -> str:\n"
            "    \"\"\"{{ node.description }}\"\"\"\n"
            "    # Define the routing logic\n"
            "    # TODO: Implement conditional logic here\n"
            "    condition = \"default\"  # Replace with actual condition check\n"
            "    return condition\n"
            "{%- endif %}\n"
            "{%- endfor %}\n\n"
        )
        
        graph_build = (
            "# Build the graph\n"
            "def build_graph():\n"
            "    workflow = StateGraph(GraphState)\n"
            "    \n"
            "    # Add nodes\n"
            "    {%- for node in nodes %}\n"
            "    workflow.add_node(\"{{ node.name }}\", {{ node.name }}_node)\n"
            "    {%- endfor %}\n"
            "    \n"
            "    # Add edges\n"
            "    {%- for edge in edges %}\n"
            "    {%- if edge.condition %}\n"
            "    workflow.add_conditional_edges(\n"
            "        \"{{ edge.source }}\",\n"
            "        lambda state: {{ edge.source }}_node(state),\n"
            "        {\n"
            "            \"{{ edge.condition }}\": \"{{ edge.target }}\"\n"
            "        }\n"
            "    )\n"
            "    {%- else %}\n"
            "    workflow.add_edge(\"{{ edge.source }}\", \"{{ edge.target }}\")\n"
            "    {%- endif %}\n"
            "    {%- endfor %}\n"
            "    \n"
            "    # Set entrypoint\n"
            "    workflow.set_entry_point(\"{{ entrypoint }}\")\n"
            "    \n"
            "    return workflow.compile()\n\n"
        )
        
        execution = (
            "# Create the graph\n"
            "graph = build_graph()\n\n"
            "# Initialize state\n"
            "initial_state = GraphState(\n"
            "    {%- for attr in state %}\n"
            "    {{ attr.name }}={{ attr.default|default(\"None\") }},\n"
            "    {%- endfor %}\n"
            ")\n\n"
            "# Run the graph\n"
            "for output in graph.stream(initial_state):\n"
            "    if \"__end__\" not in output:\n"
            "        print(f\"Output: {output}\")\n"
        )
        
        # Combine all parts
        full_template = header + imports + state_class + tools_def + node_functions + graph_build + execution
        
        # Create a template from the combined parts
        return env.from_string(full_template)
    
    def get_default_config(self) -> Dict[str, Any]:
        """
        Get a default configuration for the LangGraph framework.
        
        Returns:
            A dictionary containing the default configuration
        """
        return {
            "nodes": [
                {
                    "name": "researcher",
                    "description": "Researches information on the given topic",
                    "type": "agent",
                    "config": {}
                },
                {
                    "name": "analyzer",
                    "description": "Analyzes the research results",
                    "type": "agent",
                    "config": {}
                },
                {
                    "name": "decision",
                    "description": "Makes a decision based on the analysis",
                    "type": "conditional",
                    "config": {}
                }
            ],
            "edges": [
                {
                    "source": "researcher",
                    "target": "analyzer",
                    "condition": None
                },
                {
                    "source": "analyzer",
                    "target": "decision",
                    "condition": None
                },
                {
                    "source": "decision",
                    "target": "researcher",
                    "condition": "needs_more_research"
                },
                {
                    "source": "decision",
                    "target": "END",
                    "condition": "complete"
                }
            ],
            "state": [
                {
                    "name": "messages",
                    "description": "The history of messages in the conversation",
                    "type": "List[AIMessage]",
                    "default": "[]"
                },
                {
                    "name": "research_results",
                    "description": "The results of the research",
                    "type": "str",
                    "default": "''"
                },
                {
                    "name": "analysis",
                    "description": "The analysis of the research results",
                    "type": "str",
                    "default": "''"
                }
            ],
            "entrypoint": "researcher",
            "tools": [
                {
                    "name": "search_tool",
                    "description": "Searches for information on the internet",
                    "args": ["query: str"]
                },
                {
                    "name": "summarize_tool",
                    "description": "Summarizes long text",
                    "args": ["text: str", "max_length: int = 100"]
                }
            ],
            "output_file": "langgraph_agent_system.py"
        }
    
    def get_required_keys(self) -> list:
        """
        Get the required keys for the LangGraph framework configuration.
        
        Returns:
            A list of required keys
        """
        return ["nodes", "edges", "state", "entrypoint"]
