import garch_lib as gc
import pandas as pd
import numpy as np
from arch import arch_model

# è¯»å–æ•°æ®
df = pd.read_csv('brett.csv')
returns = df['c_scaled'].values
window_data = returns[200:300]  # 100ä¸ªæ•°æ®ç‚¹

print("ğŸ” æ·±å…¥è°ƒè¯•ä¼˜åŒ–ç®—æ³•é—®é¢˜")
print("=" * 60)

# ä½¿ç”¨archåº“è·å–å‚è€ƒ
arch_model_obj = arch_model(window_data, vol='Garch', p=1, q=1, dist='ged', rescale=False)
arch_result = arch_model_obj.fit(disp='off', show_warning=False)

print(f"archåº“å‚æ•°:")
mu = arch_result.params['mu']
omega = arch_result.params['omega']
alpha = arch_result.params['alpha[1]']
beta = arch_result.params['beta[1]']
nu = arch_result.params['nu']

print(f"  mu: {mu:.6f}")
print(f"  omega: {omega:.6f}")
print(f"  alpha: {alpha:.6f}")
print(f"  beta: {beta:.6f}")
print(f"  nu: {nu:.6f}")
print(f"  ä¼¼ç„¶å€¼: {arch_result.loglikelihood:.6f}")

# ä½¿ç”¨å»å‡å€¼æ•°æ®
residuals = window_data - mu

# æµ‹è¯•1: æ£€æŸ¥garch_libçš„é»˜è®¤å‚æ•°
print(f"\nğŸ“Š æµ‹è¯•1: æ£€æŸ¥garch_libçš„é»˜è®¤å‚æ•°")
calc1 = gc.GarchCalculator(history_size=len(residuals) + 10)
calc1.add_returns(residuals.tolist())

# è·å–é»˜è®¤å‚æ•°
default_params = calc1.get_parameters()
print(f"  é»˜è®¤å‚æ•°: omega={default_params.omega:.6f}, alpha={default_params.alpha:.6f}")
print(f"            beta={default_params.beta:.6f}, nu={default_params.nu:.6f}")

# è®¡ç®—é»˜è®¤å‚æ•°çš„ä¼¼ç„¶å€¼
default_ll = calc1.calculate_log_likelihood()
print(f"  é»˜è®¤å‚æ•°ä¼¼ç„¶å€¼: {default_ll:.6f}")

# æµ‹è¯•2: å°è¯•å‚æ•°ä¼°è®¡
print(f"\nğŸ“Š æµ‹è¯•2: å‚æ•°ä¼°è®¡è¿‡ç¨‹")
result = calc1.estimate_parameters()
print(f"  ä¼°è®¡æ”¶æ•›: {result.converged}")
print(f"  è¿­ä»£æ¬¡æ•°: {result.iterations}")
print(f"  ä¼°è®¡ä¼¼ç„¶å€¼: {result.log_likelihood:.6f}")
print(f"  ä¼°è®¡å‚æ•°: omega={result.parameters.omega:.6f}, alpha={result.parameters.alpha:.6f}")
print(f"            beta={result.parameters.beta:.6f}, nu={result.parameters.nu:.6f}")

# æ£€æŸ¥å‚æ•°æ˜¯å¦çœŸçš„æ”¹å˜äº†
estimated_params = calc1.get_parameters()
print(f"  å½“å‰å‚æ•°: omega={estimated_params.omega:.6f}, alpha={estimated_params.alpha:.6f}")
print(f"            beta={estimated_params.beta:.6f}, nu={estimated_params.nu:.6f}")

# æµ‹è¯•3: æ‰‹åŠ¨è®¾ç½®archåº“å‚æ•°å¹¶è®¡ç®—ä¼¼ç„¶å€¼
print(f"\nğŸ“Š æµ‹è¯•3: æ‰‹åŠ¨è®¾ç½®archåº“å‚æ•°")
calc2 = gc.GarchCalculator(history_size=len(residuals) + 10)
calc2.add_returns(residuals.tolist())

arch_params = gc.GarchParameters()
arch_params.omega = omega
arch_params.alpha = alpha
arch_params.beta = beta
arch_params.nu = nu
calc2.set_parameters(arch_params)

arch_ll_garch = calc2.calculate_log_likelihood()
print(f"  archå‚æ•°åœ¨garch_libä¸­çš„ä¼¼ç„¶å€¼: {arch_ll_garch:.6f}")
print(f"  ä¸archåº“çš„å·®å¼‚: {arch_ll_garch - arch_result.loglikelihood:.6f}")

# æµ‹è¯•4: æ£€æŸ¥é¢„æµ‹å€¼
print(f"\nğŸ“Š æµ‹è¯•4: é¢„æµ‹å€¼å¯¹æ¯”")
forecast_default = calc1.forecast_volatility(1)
forecast_arch = calc2.forecast_volatility(1)

print(f"  é»˜è®¤å‚æ•°é¢„æµ‹: {forecast_default.volatility:.6f}")
print(f"  archå‚æ•°é¢„æµ‹: {forecast_arch.volatility:.6f}")

# archåº“é¢„æµ‹
arch_forecast = arch_result.forecast(horizon=1, reindex=False)
arch_vol = np.sqrt(arch_forecast.variance.values[-1, 0])
print(f"  archåº“é¢„æµ‹: {arch_vol:.6f}")

# æµ‹è¯•5: æ£€æŸ¥æ˜¯å¦æ˜¯å‚æ•°ä¼°è®¡æ ¹æœ¬ä¸å·¥ä½œ
print(f"\nğŸ“Š æµ‹è¯•5: å¤šæ¬¡å‚æ•°ä¼°è®¡")
for i in range(3):
    calc_test = gc.GarchCalculator(history_size=len(residuals) + 10)
    calc_test.add_returns(residuals.tolist())
    result_test = calc_test.estimate_parameters()
    print(f"  ç¬¬{i+1}æ¬¡ä¼°è®¡:")
    print(f"    æ”¶æ•›: {result_test.converged}, è¿­ä»£: {result_test.iterations}")
    print(f"    ä¼¼ç„¶å€¼: {result_test.log_likelihood:.6f}")
    print(f"    å‚æ•°: Ï‰={result_test.parameters.omega:.6f}, Î±={result_test.parameters.alpha:.6f}, Î²={result_test.parameters.beta:.6f}, Î½={result_test.parameters.nu:.6f}")

# æµ‹è¯•6: æ£€æŸ¥æ•°æ®æ˜¯å¦æ­£ç¡®ä¼ é€’
print(f"\nğŸ“Š æµ‹è¯•6: æ•°æ®æ£€æŸ¥")
calc3 = gc.GarchCalculator(history_size=len(residuals) + 10)
calc3.add_returns(residuals.tolist())

log_returns = calc3.get_log_returns()
print(f"  æ•°æ®ç‚¹æ•°: {len(log_returns)}")
print(f"  å‰5ä¸ªæ•°æ®ç‚¹: {log_returns[:5]}")
print(f"  å5ä¸ªæ•°æ®ç‚¹: {log_returns[-5:]}")
print(f"  ä¸è¾“å…¥æ•°æ®ä¸€è‡´: {np.allclose(log_returns, residuals.tolist())}")

print(f"\nğŸ” ç»“è®ºåˆ†æ:")
print(f"  1. é»˜è®¤å‚æ•°ä¼¼ç„¶å€¼: {default_ll:.2f}")
print(f"  2. archå‚æ•°ä¼¼ç„¶å€¼: {arch_ll_garch:.2f}")
print(f"  3. archåº“ä¼¼ç„¶å€¼: {arch_result.loglikelihood:.2f}")
print(f"  4. å‚æ•°ä¼°è®¡æ˜¯å¦æ”¹å˜å‚æ•°: {not (estimated_params.omega == default_params.omega and estimated_params.alpha == default_params.alpha)}")
print(f"  5. ä¼¼ç„¶å€¼å·®å¼‚: garch_libä¸archåº“å·®å¼‚ {arch_ll_garch - arch_result.loglikelihood:.2f}") 