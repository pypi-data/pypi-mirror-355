{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "2c895519",
            "metadata": {},
            "source": [
                "## Initialize"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "5fc3afa8",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from dotenv import load_dotenv\n",
                "load_dotenv()\n",
                "\n",
                "from openai import OpenAI\n",
                "\n",
                "model=\"claude-opus-4-20250514\"\n",
                "\n",
                "client_config = {\n",
                "    \"type\": \"ttt\",\n",
                "    \"client_type\": \"anthropic\",\n",
                "    \"model\": model\n",
                "    }\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a90ec814",
            "metadata": {},
            "source": [
                "### Generate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "71d1540b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "Normal:\n",
                        "\n",
                        "Raw:\n",
                        "{'id': 'msg_01Fok6pmtuoFEDnGKhkXcy9x', 'content': [{'citations': None, 'text': \"The old lighthouse keeper discovered the light he'd been tending for forty years had never worked, but the ships had always found their way home anyway.\", 'type': 'text'}], 'model': 'claude-opus-4-20250514', 'role': 'assistant', 'stop_reason': 'end_turn', 'stop_sequence': None, 'type': 'message', 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 13, 'output_tokens': 33, 'server_tool_use': None, 'service_tier': 'standard'}}\n",
                        "Extracted:\n",
                        "The old lighthouse keeper discovered the light he'd been tending for forty years had never worked, but the ships had always found their way home anyway.\n",
                        "\n",
                        "\n",
                        "Patched:\n",
                        "\n",
                        "Raw:\n",
                        "{'id': 'chatcmpl-9b0b0a5b-860b-4a06-bd87-9f435b94eee9', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'As the last library on Earth crumbled to dust, an old woman tucked the final book under her arm and began teaching the children to write their own.', 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': None}}], 'created': 1749551675, 'model': 'anthropic', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': None, 'usage': {'completion_tokens': 36, 'prompt_tokens': 13, 'total_tokens': 49, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'extract': <function attach_extractor.<locals>.<lambda> at 0x7b8b02d89090>}\n",
                        "Extracted:\n",
                        "As the last library on Earth crumbled to dust, an old woman tucked the final book under her arm and began teaching the children to write their own.\n",
                        "\n",
                        "\n",
                        "Async:\n",
                        "\n",
                        "Raw:\n",
                        "{'id': 'chatcmpl-4f6aca08-75ad-4559-a0f8-ed97b8c5b086', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': \"The old lighthouse keeper discovered that the mysterious signals he'd been receiving for forty years were just his own messages bouncing off a distant star, returning home like cosmic echoes of his loneliness.\", 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': None}}], 'created': 1749551679, 'model': 'anthropic', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': None, 'usage': {'completion_tokens': 43, 'prompt_tokens': 13, 'total_tokens': 56, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'extract': <function attach_extractor_async.<locals>.<lambda> at 0x7b8b203131c0>}\n",
                        "Extracted:\n",
                        "The old lighthouse keeper discovered that the mysterious signals he'd been receiving for forty years were just his own messages bouncing off a distant star, returning home like cosmic echoes of his loneliness.\n"
                    ]
                }
            ],
            "source": [
                "import anthropic\n",
                "\n",
                "model = \"claude-opus-4-20250514\"\n",
                "\n",
                "## Using anthropic client ────────────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nNormal:\\n\")\n",
                "\n",
                "client = anthropic.Anthropic()\n",
                "response = client.messages.create(\n",
                "    model=model,\n",
                "    max_tokens=1000,\n",
                "    messages=[\n",
                "        {\n",
                "            \"role\": \"user\",\n",
                "            \"content\": \"tell me a one sentence story\",\n",
                "        },\n",
                "    ],\n",
                ")\n",
                "print(f\"Raw:\\n{response.model_dump()}\\nExtracted:\\n{response.content[0].text}\")\n",
                "\n",
                "## Using OpenAI-Compatible client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nPatched:\\n\")\n",
                "\n",
                "from gai.llm.openai import OpenAI\n",
                "client = OpenAI(client_config=client_config)\n",
                "response = client.chat.completions.create(\n",
                "    model=client_config[\"model\"], \n",
                "    messages=[{\"role\":\"user\",\"content\":\"tell me a one sentence story\"}]\n",
                ")\n",
                "print(f\"Raw:\\n{response.model_dump()}\\nExtracted:\\n{response.extract()}\")\n",
                "\n",
                "## Using OpenAI-Compatible async client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nAsync:\\n\")\n",
                "\n",
                "from gai.llm.openai import AsyncOpenAI\n",
                "client = AsyncOpenAI(client_config=client_config)\n",
                "response = await client.chat.completions.create(\n",
                "    model=client_config[\"model\"], \n",
                "    messages=[{\"role\":\"user\",\"content\":\"tell me a one sentence story\"}]\n",
                ")\n",
                "print(f\"Raw:\\n{response.model_dump()}\\nExtracted:\\n{response.extract()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fa2921a1",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### Streaming"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "16f8cb3e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "Normal:\n",
                        "\n",
                        "[\n",
                        "    \"The old lighthouse\",\n",
                        "    \" keeper discovered that the strange signals he'd been receiving for\",\n",
                        "    \" forty years were actually replies to messages he'd forgotten\",\n",
                        "    \" sending into space as a lonely child.\"\n",
                        "]\n",
                        "\n",
                        "\n",
                        "Patched:\n",
                        "\n",
                        "The old lighthouse keeper discovered that the mysterious signals he'd been receiving for forty years were actually from his own future self, warning him not to retire next Tuesday.\n",
                        "\n",
                        "Async:\n",
                        "\n",
                        "The old lighthouse keeper discovered that the mysterious lights appearing on the horizon each night weren't ships in distress, but his daughter sailing home after twenty years to finally forgive him."
                    ]
                }
            ],
            "source": [
                "import anthropic\n",
                "\n",
                "model = \"claude-opus-4-20250514\"\n",
                "\n",
                "## Using anthropic client ────────────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nNormal:\\n\")\n",
                "\n",
                "import json\n",
                "client = anthropic.Anthropic()\n",
                "response = client.messages.create(\n",
                "    model=model,\n",
                "    max_tokens=1000,\n",
                "    messages=[\n",
                "        {\n",
                "            \"role\": \"user\",\n",
                "            \"content\": \"Tell me a one sentence story\",\n",
                "        },\n",
                "    ],\n",
                "    stream=True\n",
                ")\n",
                "chunks = []\n",
                "for chunk in response:\n",
                "    if chunk.type==\"content_block_delta\":\n",
                "        chunks.append(chunk.delta.text)\n",
                "print(json.dumps(chunks,indent=4))\n",
                "            \n",
                "## Using gai.llm.openai client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nPatched:\\n\")\n",
                "\n",
                "from gai.llm.openai import OpenAI\n",
                "client = OpenAI(client_config=client_config)\n",
                "response = client.chat.completions.create(\n",
                "    model=client_config[\"model\"], \n",
                "    messages=[{\"role\":\"user\",\"content\":\"tell me a one sentence story\"}],\n",
                "    stream=True\n",
                ")\n",
                "chunks = []\n",
                "for chunk in response:\n",
                "    chunk = chunk.extract()\n",
                "    if (isinstance(chunk, str)):\n",
                "        print(chunk, end=\"\", flush=True)\n",
                "\n",
                "\n",
                "import os\n",
                "from dotenv import load_dotenv\n",
                "load_dotenv()\n",
                "\n",
                "from openai import OpenAI\n",
                "\n",
                "model=\"claude-opus-4-20250514\"\n",
                "\n",
                "client_config = {\n",
                "    \"type\": \"ttt\",\n",
                "    \"client_type\": \"anthropic\",\n",
                "    \"model\": model\n",
                "    }\n",
                "\n",
                "# # Using gai.llm.openai async client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nAsync:\\n\")\n",
                "\n",
                "from gai.llm.openai import AsyncOpenAI\n",
                "client = AsyncOpenAI(client_config=client_config)\n",
                "response = await client.chat.completions.create(\n",
                "    model=client_config[\"model\"], \n",
                "    messages=[{\"role\":\"user\",\"content\":\"tell me a one sentence story\"}],\n",
                "    stream=True\n",
                ")\n",
                "chunks = []\n",
                "async for chunk in response:\n",
                "    if chunk:\n",
                "        chunk = chunk.extract()\n",
                "        if (isinstance(chunk, str)):\n",
                "            print(chunk, end=\"\", flush=True)\n",
                "    \n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "855d9e3c",
            "metadata": {},
            "source": [
                "---\n",
                "### Tool Call"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "08bc5771",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "Normal:\n",
                        "\n",
                        "{\n",
                        "    \"id\": \"msg_016918vfNbJ4rhurm8ish4vP\",\n",
                        "    \"content\": [\n",
                        "        {\n",
                        "            \"citations\": null,\n",
                        "            \"text\": \"I'll help you find the current time in Singapore.\",\n",
                        "            \"type\": \"text\"\n",
                        "        },\n",
                        "        {\n",
                        "            \"id\": \"toolu_01V6XGw6WjgWwcbuTggpmfRV\",\n",
                        "            \"input\": {\n",
                        "                \"search_query\": \"current time in Singapore\"\n",
                        "            },\n",
                        "            \"name\": \"google\",\n",
                        "            \"type\": \"tool_use\"\n",
                        "        }\n",
                        "    ],\n",
                        "    \"model\": \"claude-opus-4-20250514\",\n",
                        "    \"role\": \"assistant\",\n",
                        "    \"stop_reason\": \"tool_use\",\n",
                        "    \"stop_sequence\": null,\n",
                        "    \"type\": \"message\",\n",
                        "    \"usage\": {\n",
                        "        \"cache_creation_input_tokens\": 0,\n",
                        "        \"cache_read_input_tokens\": 0,\n",
                        "        \"input_tokens\": 578,\n",
                        "        \"output_tokens\": 68,\n",
                        "        \"server_tool_use\": null,\n",
                        "        \"service_tier\": \"standard\"\n",
                        "    }\n",
                        "}\n",
                        "\n",
                        "\n",
                        "Patched:\n",
                        "\n",
                        "[{'citations': None, 'text': \"I'll help you find the current time in Singapore.\", 'type': 'text'}, {'id': 'toolu_016E6Hp1oykLtiSvBC6AAsuY', 'input': {'search_query': 'current time in Singapore'}, 'name': 'google', 'type': 'tool_use'}]\n",
                        "\n",
                        "\n",
                        "Async:\n",
                        "\n",
                        "[{'citations': None, 'text': \"I'll help you find the current time in Singapore.\", 'type': 'text'}, {'id': 'toolu_01EhwZTCUr1X7zLnhpRqTEEm', 'input': {'search_query': 'current time in Singapore'}, 'name': 'google', 'type': 'tool_use'}]\n"
                    ]
                }
            ],
            "source": [
                "import anthropic\n",
                "\n",
                "model = \"claude-opus-4-20250514\"\n",
                "\n",
                "## Using anthropic client ────────────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nNormal:\\n\")\n",
                "\n",
                "client = anthropic.Anthropic()\n",
                "response = client.messages.create(\n",
                "    model=model, \n",
                "    messages=[{\"role\": \"user\", \"content\": \"What is the current time in Singapore?\"}],\n",
                "    tools=[\n",
                "        {\n",
                "            \"name\": \"google\",\n",
                "            \"description\": \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
                "            \"input_schema\": {\n",
                "                \"type\": \"object\",\n",
                "                \"properties\": {\n",
                "                    \"search_query\": {\n",
                "                        \"type\": \"string\",\n",
                "                        \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
                "                    }\n",
                "                },\n",
                "                \"required\": [\"search_query\"]\n",
                "            }\n",
                "        }\n",
                "    ],\n",
                "    max_tokens=1000,\n",
                ")\n",
                "import json\n",
                "print(json.dumps(response.model_dump(), indent=4))\n",
                "\n",
                "## Using OpenAI-Compatible client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nPatched:\\n\")\n",
                "\n",
                "from gai.llm.openai import OpenAI\n",
                "client = OpenAI(client_config=client_config)\n",
                "response = client.chat.completions.create(\n",
                "    model=client_config[\"model\"],\n",
                "    messages=[{\"role\": \"user\", \"content\": \"What is the current time in Singapore?\"}],\n",
                "    tools=[\n",
                "        {\n",
                "            \"type\": \"function\",\n",
                "            \"function\": {\n",
                "                \"name\": \"google\",\n",
                "                \"description\": \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
                "                \"parameters\": {\n",
                "                    \"type\": \"object\",\n",
                "                    \"properties\": {\n",
                "                        \"search_query\": {\n",
                "                            \"type\": \"string\",\n",
                "                            \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
                "                        }\n",
                "                    },\n",
                "                    \"required\": [\"search_query\"]\n",
                "                }\n",
                "            }\n",
                "        }\n",
                "    ]\n",
                ")\n",
                "\n",
                "# For anthropic, the result will be returned as serialized array of ContentBlocks as ChatCompletionMessage's content.\n",
                "\n",
                "print(response.extract())\n",
                "\n",
                "## Using OpenAI-Compatible async client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nAsync:\\n\")\n",
                "\n",
                "from gai.llm.openai import AsyncOpenAI\n",
                "client = AsyncOpenAI(client_config=client_config)\n",
                "response = await client.chat.completions.create(\n",
                "    model=client_config[\"model\"],\n",
                "    messages=[{\"role\": \"user\", \"content\": \"What is the current time in Singapore?\"}],\n",
                "    tools=[\n",
                "        {\n",
                "            \"type\": \"function\",\n",
                "            \"function\": {\n",
                "                \"name\": \"google\",\n",
                "                \"description\": \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
                "                \"parameters\": {\n",
                "                    \"type\": \"object\",\n",
                "                    \"properties\": {\n",
                "                        \"search_query\": {\n",
                "                            \"type\": \"string\",\n",
                "                            \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
                "                        }\n",
                "                    },\n",
                "                    \"required\": [\"search_query\"]\n",
                "                }\n",
                "            }\n",
                "        }\n",
                "    ],\n",
                "    tool_choice=\"required\"\n",
                ")\n",
                "print(response.extract())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7b90f024",
            "metadata": {},
            "source": [
                "#### Parameterless Tool Call"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "1a43a2b1",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[{\"citations\": null, \"text\": \"I'll get the current time in Singapore for you.\", \"type\": \"text\"}, {\"id\": \"toolu_0168bhSBi2TpewxdCn2oD657\", \"input\": {}, \"name\": \"get_current_time\", \"type\": \"tool_use\"}]\n"
                    ]
                }
            ],
            "source": [
                "import anthropic\n",
                "\n",
                "model = \"claude-opus-4-20250514\"\n",
                "\n",
                "from gai.llm.openai import AsyncOpenAI\n",
                "client = AsyncOpenAI(client_config={\n",
                "    \"client_type\": \"anthropic\",\n",
                "    \"model\": model,\n",
                "})\n",
                "response = await client.chat.completions.create(\n",
                "    model=client_config[\"model\"],\n",
                "    messages=[{\"role\": \"user\", \"content\": \"What is the current time in Singapore?\"}],\n",
                "    tools=[\n",
                "        {\n",
                "            \"type\": \"function\",\n",
                "            \"function\": {\n",
                "                \"name\": \"get_current_time\",\n",
                "                \"description\": \"Get current time in Singapore\",\n",
                "                \"parameters\": {\n",
                "                    \"type\": \"object\",\n",
                "                    \"properties\": {},\n",
                "                    \"required\": []\n",
                "                }\n",
                "            }\n",
                "        }\n",
                "    ],\n",
                "    tool_choice=\"required\"\n",
                ")\n",
                "print(response.extract())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ba9c4059",
            "metadata": {},
            "source": [
                "#### Streaming Tool Call\n",
                "\n",
                "Can't think of a good reason why tool call should be streamed but here it is provided to maintain compatibility with the original API.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "aebac906",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ChatCompletionChunk(id='chatcmpl-80d3bdbf-c73c-4cb4-884c-20fa2541bf44', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1749561267, model='anthropic', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, extract=<function attach_extractor_async.<locals>.extract_chunk_logic.<locals>.<lambda> at 0x756373569ab0>)\n",
                        "\n",
                        "ChatCompletionChunk(id='chatcmpl-401458cc-288f-445e-aa26-5a7aa578a75c', choices=[Choice(delta=ChoiceDelta(content=\"I'll help you find the current time\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1749561267, model='anthropic', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, extract=<function attach_extractor_async.<locals>.extract_chunk_logic.<locals>.<lambda> at 0x756371aef760>)\n",
                        "\n",
                        "ChatCompletionChunk(id='chatcmpl-8c6c7bfb-85f2-4df6-abbe-53081291658d', choices=[Choice(delta=ChoiceDelta(content=' in Singapore.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1749561267, model='anthropic', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, extract=<function attach_extractor_async.<locals>.extract_chunk_logic.<locals>.<lambda> at 0x756371aef5b0>)\n",
                        "\n",
                        "ChatCompletionChunk(id='chatcmpl-1f267b95-b77f-4e6b-8c13-f585645d8728', choices=[Choice(delta=ChoiceDelta(content=[{'citations': None, 'text': \"I'll help you find the current time in Singapore.\", 'type': 'text'}, {'id': 'toolu_01N2awJgbbqBER8nT15JL1or', 'input': {'search_query': 'current time in Singapore'}, 'name': 'google', 'type': 'tool_use'}], function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1749561268, model='anthropic', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, extract=<function attach_extractor_async.<locals>.extract_chunk_logic.<locals>.<lambda> at 0x756373569ab0>)\n",
                        "\n",
                        "ChatCompletionChunk(id='chatcmpl-6c3699e3-59e1-42e8-a9f4-ac211ef4705a', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='tool_calls', index=0, logprobs=None)], created=1749561268, model='anthropic', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, extract=<function attach_extractor_async.<locals>.extract_chunk_logic.<locals>.<lambda> at 0x756371aef010>)\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "model = \"claude-opus-4-20250514\"\n",
                "\n",
                "# ## Using OpenAI-Compatible client ───────────────────────────────────────────────────────────────────\n",
                "from rich import print as rprint\n",
                "from gai.llm.openai import AsyncOpenAI\n",
                "client = AsyncOpenAI(client_config=client_config)\n",
                "response = await client.chat.completions.create(\n",
                "    model=client_config[\"model\"],\n",
                "    messages=[{\"role\": \"user\", \"content\": \"What is the current time in Singapore?\"}],\n",
                "    tools=[\n",
                "        {\n",
                "            \"type\": \"function\",\n",
                "            \"function\": {\n",
                "                \"name\": \"google\",\n",
                "                \"description\": \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
                "                \"parameters\": {\n",
                "                    \"type\": \"object\",\n",
                "                    \"properties\": {\n",
                "                        \"search_query\": {\n",
                "                            \"type\": \"string\",\n",
                "                            \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
                "                        }\n",
                "                    },\n",
                "                    \"required\": [\"search_query\"]\n",
                "                }\n",
                "            }\n",
                "        }\n",
                "    ],\n",
                "    stream=True,\n",
                "    tool_choice=\"required\"\n",
                ")\n",
                "\n",
                "# The stream starts by returning a series of text chunks forming the text_block and ends with a final Message which returns the entirety of the result\n",
                "# corresponding to the result returned from an unstreamed call.\n",
                "content=None\n",
                "async for chunk in response:\n",
                "    if chunk:\n",
                "        print(chunk)\n",
                "        print()\n",
                "\n",
                "# async for chunk in response:\n",
                "#     if chunk:\n",
                "#         chunk = chunk.extract()\n",
                "#     if isinstance(chunk,str):\n",
                "#         print(chunk,end=\"\",flush=True)\n",
                "#     else:\n",
                "#         rprint(f\"[green]content={chunk}[/]\")\n",
                "        \n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fd45153e",
            "metadata": {},
            "source": [
                "When tool call is not needed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "4899c2d1",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "Patched:\n",
                        "\n",
                        "ChatCompletionChunk(id='chatcmpl-d34aeb69-6382-4ecf-a749-f71df87bb8ee', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1749561414, model='anthropic', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, extract=<function attach_extractor_async.<locals>.extract_chunk_logic.<locals>.<lambda> at 0x756370fd15a0>)\n",
                        "\n",
                        "ChatCompletionChunk(id='chatcmpl-71be066d-6d2a-4294-8295-5265fa4b3554', choices=[Choice(delta=ChoiceDelta(content='I', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1749561414, model='anthropic', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, extract=<function attach_extractor_async.<locals>.extract_chunk_logic.<locals>.<lambda> at 0x756370fd1900>)\n",
                        "\n",
                        "ChatCompletionChunk(id='chatcmpl-e3a5cd65-7675-416b-aece-a0a63e67c238', choices=[Choice(delta=ChoiceDelta(content=\" don't need to use any tools to\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1749561415, model='anthropic', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, extract=<function attach_extractor_async.<locals>.extract_chunk_logic.<locals>.<lambda> at 0x756370fd1870>)\n",
                        "\n",
                        "ChatCompletionChunk(id='chatcmpl-e03fcfb4-0016-4f53-a470-eb48b3f795bf', choices=[Choice(delta=ChoiceDelta(content=\" create a story for you. Here's a one sentence\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1749561415, model='anthropic', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, extract=<function attach_extractor_async.<locals>.extract_chunk_logic.<locals>.<lambda> at 0x756370fd1990>)\n",
                        "\n",
                        "ChatCompletionChunk(id='chatcmpl-539b53ca-02f1-4639-9d3f-e2a9ac7f7218', choices=[Choice(delta=ChoiceDelta(content=' story:\\n\\nThe old lighthouse keeper discovered a message', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1749561416, model='anthropic', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, extract=<function attach_extractor_async.<locals>.extract_chunk_logic.<locals>.<lambda> at 0x756370fd15a0>)\n",
                        "\n",
                        "ChatCompletionChunk(id='chatcmpl-10e44738-ae04-436c-ae95-c7aaed0a30f6', choices=[Choice(delta=ChoiceDelta(content=' in a bottle that had been written by his younger', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1749561416, model='anthropic', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, extract=<function attach_extractor_async.<locals>.extract_chunk_logic.<locals>.<lambda> at 0x756370fd1090>)\n",
                        "\n",
                        "ChatCompletionChunk(id='chatcmpl-d8452503-37d8-442b-a577-5a8107c05e01', choices=[Choice(delta=ChoiceDelta(content=' self forty years ago, containing the exact advice he neede', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1749561416, model='anthropic', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, extract=<function attach_extractor_async.<locals>.extract_chunk_logic.<locals>.<lambda> at 0x756370fd1000>)\n",
                        "\n",
                        "ChatCompletionChunk(id='chatcmpl-3a0ae883-1d81-4660-a767-534059864b4c', choices=[Choice(delta=ChoiceDelta(content='d to hear today.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1749561417, model='anthropic', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, extract=<function attach_extractor_async.<locals>.extract_chunk_logic.<locals>.<lambda> at 0x756370fd0310>)\n",
                        "\n",
                        "ChatCompletionChunk(id='chatcmpl-81266416-6641-4aba-9a55-db834488d775', choices=[Choice(delta=ChoiceDelta(content=[{'citations': None, 'text': \"I don't need to use any tools to create a story for you. Here's a one sentence story:\\n\\nThe old lighthouse keeper discovered a message in a bottle that had been written by his younger self forty years ago, containing the exact advice he needed to hear today.\", 'type': 'text'}], function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1749561417, model='anthropic', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, extract=<function attach_extractor_async.<locals>.extract_chunk_logic.<locals>.<lambda> at 0x756370fd1a20>)\n",
                        "\n",
                        "ChatCompletionChunk(id='chatcmpl-ede6866b-3c54-4e0c-978c-3d56321b1847', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1749561417, model='anthropic', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, extract=<function attach_extractor_async.<locals>.extract_chunk_logic.<locals>.<lambda> at 0x756370fd1510>)\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "model = \"claude-opus-4-20250514\"\n",
                "\n",
                "# ## Using OpenAI-Compatible client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nPatched:\\n\")\n",
                "\n",
                "from gai.llm.openai import AsyncOpenAI\n",
                "client = AsyncOpenAI(client_config=client_config)\n",
                "response = await client.chat.completions.create(\n",
                "    model=client_config[\"model\"],\n",
                "    messages=[{\"role\": \"user\", \"content\": \"Tell me a one sentence story\"}],\n",
                "    tools=[\n",
                "        {\n",
                "            \"type\": \"function\",\n",
                "            \"function\": {\n",
                "                \"name\": \"google\",\n",
                "                \"description\": \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
                "                \"parameters\": {\n",
                "                    \"type\": \"object\",\n",
                "                    \"properties\": {\n",
                "                        \"search_query\": {\n",
                "                            \"type\": \"string\",\n",
                "                            \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
                "                        }\n",
                "                    },\n",
                "                    \"required\": [\"search_query\"]\n",
                "                }\n",
                "            }\n",
                "        }\n",
                "    ],\n",
                "    stream=True,\n",
                ")\n",
                "\n",
                "async for chunk in response:\n",
                "    if chunk:\n",
                "        print(chunk)\n",
                "        print()\n",
                "    \n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ca93b541",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### Structured Output\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "8ad59356",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "Normal:\n",
                        "\n",
                        "{\n",
                        "    \"id\": \"msg_015oMv9grVTpyJy8Pqu87GEB\",\n",
                        "    \"content\": [\n",
                        "        {\n",
                        "            \"citations\": null,\n",
                        "            \"text\": \"I'll extract the structured information from this text about the book \\\"Foundation\\\".\",\n",
                        "            \"type\": \"text\"\n",
                        "        },\n",
                        "        {\n",
                        "            \"id\": \"toolu_015qCs4okfv3CdrNQ6hBSQ8Y\",\n",
                        "            \"input\": {\n",
                        "                \"title\": \"Foundation\",\n",
                        "                \"author\": \"Isaac Asimov\",\n",
                        "                \"published_year\": 1951,\n",
                        "                \"summary\": \"Foundation is a science fiction novel that is the first published in the Foundation Trilogy (later expanded into the Foundation series). It consists of a cycle of five interrelated short stories that collectively tell the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve the best of galactic civilization after the collapse of the Galactic Empire.\"\n",
                        "            },\n",
                        "            \"name\": \"structured_output\",\n",
                        "            \"type\": \"tool_use\"\n",
                        "        }\n",
                        "    ],\n",
                        "    \"model\": \"claude-opus-4-20250514\",\n",
                        "    \"role\": \"assistant\",\n",
                        "    \"stop_reason\": \"tool_use\",\n",
                        "    \"stop_sequence\": null,\n",
                        "    \"type\": \"message\",\n",
                        "    \"usage\": {\n",
                        "        \"cache_creation_input_tokens\": 0,\n",
                        "        \"cache_read_input_tokens\": 0,\n",
                        "        \"input_tokens\": 569,\n",
                        "        \"output_tokens\": 203,\n",
                        "        \"server_tool_use\": null,\n",
                        "        \"service_tier\": \"standard\"\n",
                        "    }\n",
                        "}\n",
                        "\n",
                        "\n",
                        "Patched:\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/workspaces/gai-sdk/.venv/lib/python3.10/site-packages/pydantic/main.py:519: UserWarning: Pydantic serializer warnings:\n",
                        "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [input_value=[{'citations': None, 'tex...t', 'type': 'tool_use'}], input_type=list])\n",
                        "  return self.__pydantic_serializer__.to_json(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{\n",
                        "    \"id\": \"chatcmpl-bf835a5c-af85-465e-9d71-637b9a2afb4a\",\n",
                        "    \"choices\": [\n",
                        "        {\n",
                        "            \"finish_reason\": \"stop\",\n",
                        "            \"index\": 0,\n",
                        "            \"logprobs\": null,\n",
                        "            \"message\": {\n",
                        "                \"content\": [\n",
                        "                    {\n",
                        "                        \"citations\": null,\n",
                        "                        \"text\": \"I'll extract the information about the Foundation novel and return it in JSON format.\",\n",
                        "                        \"type\": \"text\"\n",
                        "                    },\n",
                        "                    {\n",
                        "                        \"id\": \"toolu_01X8Zn8J3wjkdEPzci7xpNW6\",\n",
                        "                        \"input\": {\n",
                        "                            \"title\": \"Foundation\",\n",
                        "                            \"summary\": \"Foundation is a science fiction novel that is the first published in the Foundation Trilogy (later expanded into the Foundation series). It is a cycle of five interrelated short stories, first published as a single book by Gnome Press in 1951. The stories collectively tell the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve the best of galactic civilization after the collapse of the Galactic Empire.\",\n",
                        "                            \"author\": \"Isaac Asimov\",\n",
                        "                            \"published_year\": 1951\n",
                        "                        },\n",
                        "                        \"name\": \"structured_output\",\n",
                        "                        \"type\": \"tool_use\"\n",
                        "                    }\n",
                        "                ],\n",
                        "                \"refusal\": null,\n",
                        "                \"role\": \"assistant\",\n",
                        "                \"annotations\": null,\n",
                        "                \"audio\": null,\n",
                        "                \"function_call\": null,\n",
                        "                \"tool_calls\": null\n",
                        "            }\n",
                        "        }\n",
                        "    ],\n",
                        "    \"created\": 1749561534,\n",
                        "    \"model\": \"anthropic\",\n",
                        "    \"object\": \"chat.completion\",\n",
                        "    \"service_tier\": null,\n",
                        "    \"system_fingerprint\": null,\n",
                        "    \"usage\": {\n",
                        "        \"completion_tokens\": 221,\n",
                        "        \"prompt_tokens\": 570,\n",
                        "        \"total_tokens\": 791,\n",
                        "        \"completion_tokens_details\": null,\n",
                        "        \"prompt_tokens_details\": null\n",
                        "    }\n",
                        "}\n",
                        "\n",
                        "\n",
                        "Extracted:\n",
                        "\n",
                        "[{'citations': None, 'text': \"I'll extract the information about the Foundation novel and return it in JSON format.\", 'type': 'text'}, {'id': 'toolu_01X8Zn8J3wjkdEPzci7xpNW6', 'input': {'title': 'Foundation', 'summary': 'Foundation is a science fiction novel that is the first published in the Foundation Trilogy (later expanded into the Foundation series). It is a cycle of five interrelated short stories, first published as a single book by Gnome Press in 1951. The stories collectively tell the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve the best of galactic civilization after the collapse of the Galactic Empire.', 'author': 'Isaac Asimov', 'published_year': 1951}, 'name': 'structured_output', 'type': 'tool_use'}]\n",
                        "\n",
                        "\n",
                        "Patched:\n",
                        "\n",
                        "{\n",
                        "    \"id\": \"chatcmpl-2fd97ddc-947f-4f26-82bf-7b348ad09b61\",\n",
                        "    \"choices\": [\n",
                        "        {\n",
                        "            \"finish_reason\": \"stop\",\n",
                        "            \"index\": 0,\n",
                        "            \"logprobs\": null,\n",
                        "            \"message\": {\n",
                        "                \"content\": [\n",
                        "                    {\n",
                        "                        \"citations\": null,\n",
                        "                        \"text\": \"I'll extract the key information about the Foundation novel and return it in the requested JSON format.\",\n",
                        "                        \"type\": \"text\"\n",
                        "                    },\n",
                        "                    {\n",
                        "                        \"id\": \"toolu_01DsS1UpbVVjdQSHFzH7qswA\",\n",
                        "                        \"input\": {\n",
                        "                            \"title\": \"Foundation\",\n",
                        "                            \"summary\": \"Foundation is a science fiction novel that is the first published in the Foundation Trilogy (later expanded into the Foundation series). It consists of a cycle of five interrelated short stories, first published as a single book by Gnome Press in 1951. The stories collectively tell the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve the best of galactic civilization after the collapse of the Galactic Empire.\",\n",
                        "                            \"author\": \"Isaac Asimov\",\n",
                        "                            \"published_year\": 1951\n",
                        "                        },\n",
                        "                        \"name\": \"structured_output\",\n",
                        "                        \"type\": \"tool_use\"\n",
                        "                    }\n",
                        "                ],\n",
                        "                \"refusal\": null,\n",
                        "                \"role\": \"assistant\",\n",
                        "                \"annotations\": null,\n",
                        "                \"audio\": null,\n",
                        "                \"function_call\": null,\n",
                        "                \"tool_calls\": null\n",
                        "            }\n",
                        "        }\n",
                        "    ],\n",
                        "    \"created\": 1749561541,\n",
                        "    \"model\": \"anthropic\",\n",
                        "    \"object\": \"chat.completion\",\n",
                        "    \"service_tier\": null,\n",
                        "    \"system_fingerprint\": null,\n",
                        "    \"usage\": {\n",
                        "        \"completion_tokens\": 225,\n",
                        "        \"prompt_tokens\": 570,\n",
                        "        \"total_tokens\": 795,\n",
                        "        \"completion_tokens_details\": null,\n",
                        "        \"prompt_tokens_details\": null\n",
                        "    }\n",
                        "}\n",
                        "\n",
                        "\n",
                        "Extracted:\n",
                        "\n",
                        "[{'citations': None, 'text': \"I'll extract the key information about the Foundation novel and return it in the requested JSON format.\", 'type': 'text'}, {'id': 'toolu_01DsS1UpbVVjdQSHFzH7qswA', 'input': {'title': 'Foundation', 'summary': 'Foundation is a science fiction novel that is the first published in the Foundation Trilogy (later expanded into the Foundation series). It consists of a cycle of five interrelated short stories, first published as a single book by Gnome Press in 1951. The stories collectively tell the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve the best of galactic civilization after the collapse of the Galactic Empire.', 'author': 'Isaac Asimov', 'published_year': 1951}, 'name': 'structured_output', 'type': 'tool_use'}]\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "from pydantic import BaseModel\n",
                "class Book(BaseModel):\n",
                "    title: str\n",
                "    summary: str\n",
                "    author: str\n",
                "    published_year: int\n",
                "data = \"\"\"Foundation is a science fiction novel by American writer\n",
                "        Isaac Asimov. It is the first published in his Foundation Trilogy (later\n",
                "        expanded into the Foundation series). Foundation is a cycle of five\n",
                "        interrelated short stories, first published as a single book by Gnome Press\n",
                "        in 1951. Collectively they tell the early story of the Foundation,\n",
                "        an institute founded by psychohistorian Hari Seldon to preserve the best\n",
                "        of galactic civilization after the collapse of the Galactic Empire.\"\"\"       \n",
                "\n",
                "import anthropic\n",
                "\n",
                "model = \"claude-opus-4-20250514\"\n",
                "\n",
                "## Using anthropic client ────────────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nNormal:\\n\")\n",
                "\n",
                "client = anthropic.Anthropic()\n",
                "\n",
                "# Use tool calls to return structured output\n",
                "book_tool = {\n",
                "    \"name\": \"structured_output\",\n",
                "    \"description\": \"Extract and structure book information\",\n",
                "    \"input_schema\": Book.model_json_schema()\n",
                "}\n",
                "\n",
                "response = client.messages.create(\n",
                "    model=model,\n",
                "    max_tokens=1000,\n",
                "    temperature=0,\n",
                "    tools=[book_tool],\n",
                "    messages=[\n",
                "        {\n",
                "            \"role\": \"user\",\n",
                "            \"content\": f\"Extract structured output from this: {data}\"\n",
                "        }\n",
                "    ]\n",
                ")\n",
                "print(response.model_dump_json(indent=4))\n",
                "\n",
                "## Using OpenAI-Compatible client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nPatched:\\n\")\n",
                "\n",
                "from gai.llm.openai import OpenAI\n",
                "client = OpenAI(client_config=client_config)\n",
                "response = client.beta.chat.completions.parse(\n",
                "    model=client_config[\"model\"], \n",
                "    response_format=Book,\n",
                "    messages=[{\"role\":\"user\",\"content\":data}]\n",
                "    )\n",
                "print(response.model_dump_json(exclude={\"extract\"},indent=4))\n",
                "\n",
                "print(\"\\n\\nExtracted:\\n\")\n",
                "print(response.extract())\n",
                "\n",
                "## Using OpenAI-Compatible async client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nPatched:\\n\")\n",
                "\n",
                "from gai.llm.openai import AsyncOpenAI\n",
                "client = AsyncOpenAI(client_config=client_config)\n",
                "response = await client.beta.chat.completions.parse(\n",
                "    model=client_config[\"model\"], \n",
                "    response_format=Book,\n",
                "    messages=[{\"role\":\"user\",\"content\":data}]\n",
                "    )\n",
                "print(response.model_dump_json(exclude={\"extract\"},indent=4))\n",
                "\n",
                "print(\"\\n\\nExtracted:\\n\")\n",
                "print(response.extract())\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "808ce4d3",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### Serialization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "ffe978d2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "Opus-4-20250514:\n",
                        "\n",
                        "b'[{\"citations\":null,\"text\":\"Hello, how are you?\",\"type\":\"text\"},{\"id\":\"aaa\",\"input\":{\"search_query\":\"current weather in Singapore\"},\"name\":\"google\",\"type\":\"tool_use\"}]'\n",
                        "[TextBlock(citations=None, text='Hello, how are you?', type='text'), ToolUseBlock(id='aaa', input={'search_query': 'current weather in Singapore'}, name='google', type='tool_use')]\n"
                    ]
                }
            ],
            "source": [
                "from typing import List, Union, Annotated\n",
                "from anthropic.types import TextBlock, ToolUseBlock\n",
                "from pydantic import Field,BaseModel,TypeAdapter\n",
                "MessageBlock = Annotated[Union[TextBlock, ToolUseBlock],Field(discriminator=\"type\")]\n",
                "\n",
                "## Using Opus ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nOpus-4-20250514:\\n\")\n",
                "\n",
                "\n",
                "MessageList = TypeAdapter(List[MessageBlock])\n",
                "    \n",
                "messages = [\n",
                "    TextBlock(type=\"text\",text=\"Hello, how are you?\"),\n",
                "    ToolUseBlock(\n",
                "        id=\"aaa\",\n",
                "        type=\"tool_use\",\n",
                "        name=\"google\",\n",
                "        input={\"search_query\": \"current weather in Singapore\"}\n",
                "    )]\n",
                "\n",
                "message_list = MessageList.dump_json(messages)\n",
                "print(message_list)\n",
                "\n",
                "loaded = MessageList.validate_json(message_list)\n",
                "print(loaded)\n",
                "    "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
