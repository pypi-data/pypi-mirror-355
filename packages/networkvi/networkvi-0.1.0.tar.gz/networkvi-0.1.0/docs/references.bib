@Article{Ashuach2023,
  author   = {Ashuach, Tal and Gabitto, Mariano I. and Koodli, Rohan V. and Saldi, Giuseppe-Antonio and Jordan, Michael I. and Yosef, Nir},
  journal  = {Nature Methods},
  title    = {MultiVI: deep generative model for the integration of multimodal data},
  year     = {2023},
  issn     = {1548-7105},
  number   = {8},
  pages    = {1222--1231},
  volume   = {20},
  abstract = {Jointly profiling the transcriptome, chromatin accessibility and other molecular properties of single cells offers a powerful way to study cellular diversity. Here we present MultiVI, a probabilistic model to analyze such multiomic data and leverage it to enhance single-modality datasets. MultiVI creates a joint representation that allows an analysis of all modalities included in the multiomic input data, even for cells for which one or more modalities are missing. It is available at scvi-tools.org.},
  doi      = {10.1038/s41592-023-01909-9},
  refid    = {Ashuach2023},
  url      = {https://doi.org/10.1038/s41592-023-01909-9},
}

@Article{Arnoldt2024,
	title	= {Biologically Guided Variational Inference for Interpretable Multimodal Single-Cell Integration},
	author	= {Arnoldt, Lucas and Upmeier zu Belzen, Julius and Herrmann, Luis and Nguyen, Khue and Theis, Fabian and Wild, Benjamin and Eils, Roland},
	journal	= {bioRxiv},
	year	= {2025},
	publisher	= {bioRxiv}
}

@InProceedings{Luecken2021,
  author    = {Luecken, Malte and Burkhardt, Daniel and Cannoodt, Robrecht and Lance, Christopher and Agrawal, Aditi and Aliee, Hananeh and Chen, Ann and Deconinck, Louise and Detweiler, Angela and Granados, Alejandro and Huynh, Shelly and Isacco, Laura and Kim, Yang and Klein, Dominik and DE KUMAR, BONY and Kuppasani, Sunil and Lickert, Heiko and McGeever, Aaron and Melgarejo, Joaquin and Mekonen, Honey and Morri, Maurizio and M\"{u}ller, Michaela and Neff, Norma and Paul, Sheryl and Rieck, Bastian and Schneider, Kaylie and Steelman, Scott and Sterr, Michael and Treacy, Daniel and Tong, Alexander and Villani, Alexandra-Chloe and Wang, Guilin and Yan, Jia and Zhang, Ce and Pisco, Angela and Krishnaswamy, Smita and Theis, Fabian and Bloom, Jonathan M},
  booktitle = {Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks},
  title     = {A sandbox for prediction and integration of DNA, RNA, and proteins in single cells},
  year      = {2021},
  editor    = {J. Vanschoren and S. Yeung},
  volume    = {1},
  url       = {https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/158f3069a435b314a80bdcb024f8e422-Paper-round2.pdf},
}

@Article{Lotfollahi2022,
  author   = {Lotfollahi, Mohammad and Naghipourfar, Mohsen and Luecken, Malte D. and Khajavi, Matin and Büttner, Maren and Wagenstetter, Marco and Avsec, Žiga and Gayoso, Adam and Yosef, Nir and Interlandi, Marta and Rybakov, Sergei and Misharin, Alexander V. and Theis, Fabian J.},
  journal  = {Nature Biotechnology},
  title    = {Mapping single-cell data to reference atlases by transfer learning},
  year     = {2022},
  issn     = {1546-1696},
  number   = {1},
  pages    = {121--130},
  volume   = {40},
  abstract = {Large single-cell atlases are now routinely generated to serve as references for analysis of smaller-scale studies. Yet learning from reference data is complicated by batch effects between datasets, limited availability of computational resources and sharing restrictions on raw data. Here we introduce a deep learning strategy for mapping query datasets on top of a reference called single-cell architectural surgery (scArches). scArches uses transfer learning and parameter optimization to enable efficient, decentralized, iterative reference building and contextualization of new datasets with existing references without sharing raw data. Using examples from mouse brain, pancreas, immune and whole-organism atlases, we show that scArches preserves biological state information while removing batch effects, despite using four orders of magnitude fewer parameters than de novo integration. scArches generalizes to multimodal reference mapping, allowing imputation of missing modalities. Finally, scArches retains coronavirus disease 2019 (COVID-19) disease variation when mapping to a healthy reference, enabling the discovery of disease-specific cell states. scArches will facilitate collaborative projects by enabling iterative construction, updating, sharing and efficient use of reference atlases.},
  doi      = {10.1038/s41587-021-01001-7},
  refid    = {Lotfollahi2022},
  url      = {https://doi.org/10.1038/s41587-021-01001-7},
}

@Article{Ma2018,
  author   = {Ma, Jianzhu and Yu, Michael Ku and Fong, Samson and Ono, Keiichiro and Sage, Eric and Demchak, Barry and Sharan, Roded and Ideker, Trey},
  journal  = {Nature Methods},
  title    = {Using deep learning to model the hierarchical structure and function of a cell},
  year     = {2018},
  issn     = {1548-7105},
  number   = {4},
  pages    = {290--298},
  volume   = {15},
  abstract = {Embedding a deep-learning model in the known structure of cellular systems yields DCell, a ‘visible’ neural network that can be used to mechanistically interpret genotype-phenotype relationships.},
  doi      = {10.1038/nmeth.4627},
  refid    = {Ma2018},
  url      = {https://doi.org/10.1038/nmeth.4627},
}

@Misc{Vaswani2017,
  author        = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  title         = {Attention Is All You Need},
  year          = {2017},
  archiveprefix = {arXiv},
  eprint        = {1706.03762},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1706.03762},
}
