{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge generation using a resoning model\n",
    "\n",
    "- In this notebook, we will use the Nemotron Super 49B model to generate knowledge from a corpus of articles.\n",
    "- Specifically, we will use the Quality Corpus for this purpose.\n",
    "- The Nemotron Super 49B model will also be used not only for synthesizing training data but also for generation ICL examples for SDG.\n",
    "- Since Nemotron Super is a thinking model, we will leverage it to generate synthetic \"thinking data\" for customizing a smaller thinking model - in this case, the Nemotron Nano model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install sdg-hub\n",
    "\n",
    "```bash \n",
    "pip install sdg-hub==0.1.0a2\n",
    "```\n",
    "\n",
    "\n",
    "## Installing Vllm\n",
    "\n",
    "- Clone vllm repo\n",
    "- Checkout PR #15008\n",
    "- Build from source\n",
    "    ```bash\n",
    "    VLLM_USE_PRECOMPILED=1 pip install --editable .\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab/.conda/envs/research_sdg/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from openai import OpenAI\n",
    "\n",
    "endpoint = f\"http://localhost:8008/v1\"\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = endpoint\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "teacher_model = client.models.list().data[0].id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct ICL examples\n",
    "- We will use nemotron super 49B model to generated some ICL examples\n",
    "- We will use the generated ICLs to generate more examples from the quality corpus\n",
    "- You can customize these prompts according to your downstream task\n",
    "- Here we aim to create QA aimed at understanding not only specific details about articles but also to create a comprehensive understanding of the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_nemotron(msg):\n",
    "    response = client.chat.completions.create(\n",
    "        model=teacher_model,\n",
    "        messages=msg,\n",
    "        temperature=0.6,\n",
    "        top_p=0.95,\n",
    "        max_tokens=4096,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"zitongyang/entigraph-quality-corpus\", split='train').remove_columns(['entity', 'entigraph']).rename_columns({'raw': 'document', 'uid': 'document_outline'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Give me a short 3-4 line document and 3 detailed GRE-style thematic questions and answers based and grounded on the document.\"\n",
    "prompt = f\"Give me a short 8-9 line passage that has 2 paragraphs. Then, provide 3 detailed open-ended questions and their answers. Each question should require synthesizing or connecting ideas, entities, or concepts that appear in different parts of the passage\"\n",
    "prompt = f\"Give me a short 8-9 line article. Then provide 3 Question and Answer based on the article such that the answers are long, comprehensive, detailed, and are grounded in the article.\"\n",
    "msg = [{\"role\": \"system\", \"content\": f\"detailed thinking on\"}, {'role': 'user', 'content': prompt}]\n",
    "generated_qa_pairs = get_response_from_nemotron(msg)\n",
    "msg += [{\"role\": \"assistant\", \"content\": generated_qa_pairs}] + [{\"role\": \"user\", \"content\": \"You refine the answers from previous response such that you distill your thinking into the answer\"}]\n",
    "edited_qa_pairs = get_response_from_nemotron(msg)\n",
    "msg = msg + [{\"role\": \"assistant\", \"content\": edited_qa_pairs}] + [{\"role\": \"user\", \"content\": \"Can you parse the generated question and answer pairs into a json format? If there are any steps include them in the json's answer's field\"}]\n",
    "json_verified_qa_pairs = get_response_from_nemotron(msg)\n",
    "msg = msg + [{\"role\": \"assistant\", \"content\": json_verified_qa_pairs}] + [{\"role\": \"user\", \"content\": \"Verify the generated question and answer pairs from previous response are correct, complete and grounded in the document. Fix all the issues in the answer if any.\"}]\n",
    "verified_qa_pairs = get_response_from_nemotron(msg)\n",
    "print(generated_qa_pairs)\n",
    "print(\"-\"*3)\n",
    "print(edited_qa_pairs)\n",
    "print(\"-\"*3)\n",
    "print(json_verified_qa_pairs)\n",
    "print(\"-\"*3)\n",
    "print(verified_qa_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of ICL samples generated chaining above prompts from Nemotron Super"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Response 1** - Generate Initial Draft of Question and Answer Pairs\n",
    "```text\n",
    "<think>\n",
    "Okay, the user wants a short 3-4 line document and three detailed GRE-style thematic questions with answers based on it. Let me start by crafting the document. It needs to be concise but rich enough for questions. Maybe a philosophical or historical topic since those lend themselves to thematic analysis.\n",
    "\n",
    "I'll go with a quote from Nietzsche about morality. That's dense and can lead to questions on interpretation, implications, and comparisons. Now, the document should be 3-4 lines. Let me check the length. The Nietzsche passage I have in mind is four sentences. Perfect.\n",
    "\n",
    "Next, the questions. GRE thematic questions often ask for interpretation, analysis of assumptions, and application to another context. First question: Identify the main thesis and explain. Second: Analyze the assumption underlying the claim. Third: Apply the idea to a different field, like science.\n",
    "\n",
    "For the answers, they need to be detailed but not too long. Make sure each answer addresses all parts of the question. Check that the questions are indeed GRE-style—focusing on themes, structure, and application. Ensure the answers ground their points in the document. Avoid jargon, keep it clear. Let me review each part to ensure alignment with the user's request. Document length, question types, answer structure all seem to fit. Okay, that should work.\n",
    "</think>\n",
    "\n",
    "**Document (4 lines)**  \n",
    "Nietzsche argued that traditional morality is a \"slave morality\" created by the weak to subjugate the strong, claiming, \"The noble type of man experiences himself as the goal and measure of things; he does not require approval or justification from outsiders.\" In contrast, slave morality, rooted in resentment, posits equality and humility as virtues to constrain natural superiority. Nietzsche saw this as a perversion of life’s true will to power. Only the Übermensch could transcend such moral dichotomies.\n",
    "\n",
    "---\n",
    "\n",
    "**Thematic Questions & Answers**\n",
    "\n",
    "### **1. Interpretation of Thesis**  \n",
    "**Question:** Identify the central thesis of the passage and explain how the contrast between \"noble\" and \"slave\" morality supports Nietzsche’s broader philosophical claim.  \n",
    "**Answer:**  \n",
    "The thesis is that traditional morality is a subversive construct of the weak (\"slave morality\") to undermine natural hierarchy, contrasting with the self-affirming \"noble morality\" of the strong. The passage supports this by framing noble morality as intrinsic (e.g., \"the goal and measure of things\") and slave morality as reactive (\"rooted in resentment\"). This dichotomy underscores Nietzsche’s claim that conventional ethics are not objective but a political tool to dilute the \"will to power\" of exceptional individuals.\n",
    "\n",
    "### **2. Assumption Analysis**  \n",
    "**Question:** What unexamined assumption underlies Nietzsche’s critique of slave morality as a \"perversion of life\"? Analyze the implications if this assumption is challenged.  \n",
    "**Answer:**  \n",
    "The assumption is that \"life’s true will to power\" is a universal, instinctual drive that should not be morally constrained. If challenged (e.g., if cooperation, not domination, is life’s primary drive), Nietzsche’s critique collapses, as slave morality’s emphasis on equality could be seen as adaptive rather than perverse. This would invert his hierarchy, legitimizing collective ethics over individual supremacy.\n",
    "\n",
    "### **3. Application to Another Context**  \n",
    "**Question:** Apply Nietzsche’s framework to scientific progress. How might a \"noble\" vs. \"slave\" dynamic manifest in the pursuit of knowledge?  \n",
    "**Answer:**  \n",
    "A \"noble\" scientific ethos might prioritize unencumbered innovation (e.g., unfunded maverick researchers pursuing risky, visionary projects). Conversely, \"slave morality\" could manifest in bureaucratic, consensus-driven science (e.g., funding prioritizing collaborative, \"socially responsible\" projects over disruptive ideas). Nietzsche would argue the latter stifles genius, while defenders might see it as ensuring ethical accountability—a parallel to his moral critique.\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Response 2** - Verify Question and Answer Pairs\n",
    "```text\n",
    "<think>\n",
    "Okay, let me try to work through this. The user wants me to verify if the question and answer pairs generated earlier are correct, complete, and grounded in the document provided. First, I need to look at each question and answer carefully.\n",
    "\n",
    "Starting with the first question: Interpretation of Thesis. The question asks to identify the central thesis and explain how the contrast between noble and slave morality supports Nietzsche’s claim. The answer given states the thesis correctly as traditional morality being a slave morality created by the weak. It also explains the contrast by saying noble morality is intrinsic and slave is reactive. The document does mention \"noble type of man\" experiencing himself as the goal and slave morality rooted in resentment. So the answer seems accurate here. The support from the document is there, so this pair is correct.\n",
    "\n",
    "Next, the second question: Assumption Analysis. The question asks for an unexamined assumption in Nietzsche’s critique. The answer points out the assumption that the will to power is a universal drive that shouldn’t be constrained. The document mentions \"life’s true will to power\" as being perverted by slave morality. If this assumption is challenged, the critique would collapse. The implications analysis seems valid. The answer correctly identifies the assumption and discusses the consequences if it's challenged. This pair checks out too.\n",
    "\n",
    "Third question: Application to Another Context. Applying Nietzsche’s framework to science. The answer differentiates between a noble ethos (unencumbered innovation) and slave (bureaucratic consensus). The document doesn’t mention science, but the framework of noble vs. slave morality is applied conceptually. Nietzsche’s ideas are being extended appropriately here. The answer stays true to his philosophy even though the context is new. So this is correct as well.\n",
    "\n",
    "Now, checking completeness. Each question has a clear answer that addresses all parts. The answers reference the document specifically, like quoting \"goal and measure of things\" and \"rooted in resentment.\" They don’t introduce information not in the document. The assumptions are correctly identified based on the text. \n",
    "\n",
    "Grounded in the document: All key points in the answers are backed by the document. For example, the Übermensch is mentioned in the document and used in the first answer to support transcending moral dichotomies. The will to power is directly from the document. \n",
    "\n",
    "Are there any inaccuracies? Let me re-read the document. The document says slave morality posits equality and humility to constrain natural superiority. The answers reflect that. The second answer’s assumption about will to power being universal is in the document as \"life’s true will to power.\" The third question's application doesn't contradict the original ideas. \n",
    "\n",
    "I think all pairs are correct. The user might have been concerned if the answers added external info or misinterpreted the text, but they seem to align closely. Maybe the third question's answer could have a stronger link, but since it's an application, it's acceptable as long as the framework is applied correctly, which it is.\n",
    "</think>\n",
    "\n",
    "**Verification of Question & Answer Pairs**\n",
    "\n",
    "All three question-answer pairs are **correct, complete, and grounded in the document**. Below is a detailed breakdown:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Interpretation of Thesis**  \n",
    "- **Correctness**: ✅ The central thesis is accurately identified, and the contrast between \"noble\" and \"slave\" morality is explained using direct evidence from the document (e.g., \"goal and measure of things,\" \"rooted in resentment\").  \n",
    "- **Completeness**: ✅ Fully addresses both parts of the question (thesis + supporting contrast).  \n",
    "- **Grounding**: ✅ Quotes and concepts (e.g., \"intrinsic\" vs. \"reactive\") align with the passage.  \n",
    "\n",
    "---\n",
    "\n",
    "### **2. Assumption Analysis**  \n",
    "- **Correctness**: ✅ The assumption about \"will to power\" is correctly inferred from the phrase \"perversion of life’s true will to power.\"  \n",
    "- **Completeness**: ✅ Clearly states the assumption and analyzes implications if challenged.  \n",
    "- **Grounding**: ✅ Directly tied to the document’s language about \"life’s true will to power\" and its contrast with slave morality.  \n",
    "\n",
    "---\n",
    "\n",
    "### **3. Application to Another Context**  \n",
    "- **Correctness**: ✅ Faithfully applies Nietzsche’s framework to science without distorting his ideas.  \n",
    "- **Completeness**: ✅ Distinguishes \"noble\" (unfettered innovation) and \"slave\" (bureaucratic) dynamics, engaging with potential counterarguments.  \n",
    "- **Grounding**: ✅ While the *context* (science) is new, the moral dichotomy (\"unencumbered pursuit\" vs. \"constrained collective ethics\") is rooted in the document’s themes.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Overall Strengths**  \n",
    "1. **Document Alignment**: Answers cite specific phrases (e.g., \"goal and measure of things,\" \"rooted in resentment\") to support claims.  \n",
    "2. **Conceptual Accuracy**: No misinterpretation of Nietzsche’s terms (e.g., \"slave morality\" as reactive, \"Übermensch\" as transcendent).  \n",
    "3. **Depth of Analysis**: Questions 2 and 3 require critical thinking (assumption-testing, application) beyond mere recall.  \n",
    "\n",
    "### **Minor Suggestions for Enhancement (Optional)**  \n",
    "- For **Question 3**, adding a brief phrase from the document to the answer (e.g., \"mirroring how slave morality ‘constrains natural superiority’\") could strengthen explicit grounding.  \n",
    "- For **Question 2**, noting that the assumption also relies on Nietzsche’s value judgment that \"domination\" is more \"natural\" than cooperation could enrich the analysis.  \n",
    "\n",
    "---\n",
    "\n",
    "**Final Conclusion**: The pairs are well-designed, rigorous, and tightly anchored to the document. They effectively test interpretation, critical analysis, and thematic application—all hallmarks of GRE-style questions.  \n",
    "\n",
    "Let me know if you’d like revisions or additional pairs!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Response 3** - Parse Question and Answer Pairs into JSON Format\n",
    "```text\n",
    "<think>\n",
    "Okay, the user wants the question and answer pairs parsed into JSON format. Let me start by recalling the previous interaction. They had a document and three GRE-style questions with answers. Then they asked for verification, which I did, and now they want JSON.\n",
    "\n",
    "First, I need to structure each question and answer properly. JSON requires key-value pairs. Each question should have a \"Question\" key, \"Answer\", and maybe \"Type\" to categorize them. The original questions were labeled as 1, 2, 3, so I can use those as IDs.\n",
    "\n",
    "Looking at the first question: Interpretation of Thesis. The answer has bullet points for Correctness, Completeness, Grounding in the verification, but the actual answer is the paragraph before that. Wait, no. Wait, in the previous response, the answer for Question 1 was the paragraph starting with \"The thesis is...\", and then the verification had correctness etc. But the user now wants the original Q&A pairs in JSON, not the verification details.\n",
    "\n",
    "So I need to go back to the initial Q&A provided. Let me check:\n",
    "\n",
    "Original Q1:\n",
    "**1. Interpretation of Thesis**  \n",
    "**Question:** Identify the central thesis...  \n",
    "**Answer:** The thesis is... \n",
    "\n",
    "Yes. So each entry in JSON should have the question text and the answer text. The verification part was separate, but the user didn't ask for that in JSON, just the pairs.\n",
    "\n",
    "So for each of the three questions, structure as:\n",
    "\n",
    "{\n",
    "  \"id\": 1,\n",
    "  \"type\": \"Interpretation of Thesis\",\n",
    "  \"question\": \"Identify the central thesis...\",\n",
    "  \"answer\": \"The thesis is...\"\n",
    "},\n",
    "\n",
    "And similarly for the others. Also, include the document in JSON if needed, but the user specified \"question and answer pairs\", so maybe just the Q&A.\n",
    "\n",
    "Wait, the user said \"parse the generated question and answer pairs into a json format\". So the document is separate, but the pairs are the three questions with their answers.\n",
    "\n",
    "So the JSON should be an array of objects, each containing id, type, question, answer.\n",
    "\n",
    "Checking the original answer:\n",
    "\n",
    "The three questions are:\n",
    "\n",
    "1. Interpretation of Thesis\n",
    "2. Assumption Analysis\n",
    "3. Application to Another Context\n",
    "\n",
    "Each has a Question and Answer.\n",
    "\n",
    "So the JSON would look like:\n",
    "\n",
    "{\n",
    "  \"questions\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"type\": \"Interpretation of Thesis\",\n",
    "      \"question\": \"Identify the central thesis of the passage and explain how the contrast between 'noble' and 'slave' morality supports Nietzsche’s broader philosophical claim.\",\n",
    "      \"answer\": \"The thesis is that traditional morality is a subversive construct of the weak... This dichotomy underscores Nietzsche’s claim...\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": 2,\n",
    "      \"type\": \"Assumption Analysis\",\n",
    "      \"question\": \"What unexamined assumption underlies Nietzsche’s critique of slave morality as a 'perversion of life'? Analyze the implications if this assumption is challenged.\",\n",
    "      \"answer\": \"The assumption is that 'life’s true will to power' is a universal, instinctual drive... This would invert his hierarchy...\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": 3,\n",
    "      \"type\": \"Application to Another Context\",\n",
    "      \"question\": \"Apply Nietzsche’s framework to scientific progress. How might a 'noble' vs. 'slave' dynamic manifest in the pursuit of knowledge?\",\n",
    "      \"answer\": \"A 'noble' scientific ethos might prioritize unencumbered innovation... while defenders might see it as ensuring ethical accountability—a parallel to his moral critique.\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "I need to make sure the quotes are properly escaped in JSON. Also, check if the user wants the document included. The instruction says \"question and answer pairs\", so probably not. But maybe confirm. The original document was separate, so likely just the Q&A.\n",
    "\n",
    "Yes, the user's request was specifically about the generated pairs, so the above structure should be correct.\n",
    "\n",
    "Now, formatting the JSON correctly with escaped quotes and proper syntax. Also, ensuring that each key is properly named. The types are the question types as labeled. The IDs are 1,2,3. Questions and answers are copied exactly from the original.\n",
    "\n",
    "Double-checking for any markdown formatting in the answers. The original answers had line breaks but in JSON, line breaks can be preserved with \\n or just as continuous text. Since the user didn't specify, keeping as continuous is safer.\n",
    "\n",
    "So the final JSON should have the questions array with three entries as above.\n",
    "</think>\n",
    "\n",
    "Here’s the parsed JSON format for the question-answer pairs, including the document for context:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"document\": [\n",
    "    \"Nietzsche argued that traditional morality is a \\\"slave morality\\\" created by the weak to subjugate the strong, claiming, \\\"The noble type of man experiences himself as the goal and measure of things; he does not require approval or justification from outsiders.\\\"\",\n",
    "    \"In contrast, slave morality, rooted in resentment, posits equality and humility as virtues to constrain natural superiority.\",\n",
    "    \"Nietzsche saw this as a perversion of life’s true will to power.\",\n",
    "    \"Only the Übermensch could transcend such moral dichotomies.\"\n",
    "  ],\n",
    "  \"questions\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"type\": \"Interpretation of Thesis\",\n",
    "      \"question\": \"Identify the central thesis of the passage and explain how the contrast between \\\"noble\\\" and \\\"slave\\\" morality supports Nietzsche’s broader philosophical claim.\",\n",
    "      \"answer\": \"The thesis is that traditional morality is a subversive construct of the weak (\\\"slave morality\\\") to undermine natural hierarchy, contrasting with the self-affirming \\\"noble morality\\\" of the strong. The passage supports this by framing noble morality as intrinsic (e.g., \\\"the goal and measure of things\\\") and slave morality as reactive (\\\"rooted in resentment\\\"). This dichotomy underscores Nietzsche’s claim that conventional ethics are not objective but a political tool to dilute the \\\"will to power\\\" of exceptional individuals.\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": 2,\n",
    "      \"type\": \"Assumption Analysis\",\n",
    "      \"question\": \"What unexamined assumption underlies Nietzsche’s critique of slave morality as a \\\"perversion of life\\\"? Analyze the implications if this assumption is challenged.\",\n",
    "      \"answer\": \"The assumption is that \\\"life’s true will to power\\\" is a universal, instinctual drive that should not be morally constrained. If challenged (e.g., if cooperation, not domination, is life’s primary drive), Nietzsche’s critique collapses, as slave morality’s emphasis on equality could be seen as adaptive rather than perverse. This would invert his hierarchy, legitimizing collective ethics over individual supremacy.\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": 3,\n",
    "      \"type\": \"Application to Another Context\",\n",
    "      \"question\": \"Apply Nietzsche’s framework to scientific progress. How might a \\\"noble\\\" vs. \\\"slave\\\" dynamic manifest in the pursuit of knowledge?\",\n",
    "      \"answer\": \"A \\\"noble\\\" scientific ethos might prioritize unencumbered innovation (e.g., unfunded maverick researchers pursuing risky, visionary projects). Conversely, \\\"slave morality\\\" could manifest in bureaucratic, consensus-driven science (e.g., funding prioritizing collaborative, \\\"socially responsible\\\" projects over disruptive ideas). Nietzsche would argue the latter stifles genius, while defenders might see it as ensuring ethical accountability—a parallel to his moral critique.\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "### **Key Features of the JSON Structure**\n",
    "1. **Document**: Included as an array of sentences for clarity.\n",
    "2. **Questions**: Array with `id`, `type`, `question`, and `answer` fields.\n",
    "3. **Formatting**: Quotes are properly escaped (`\\\"`), and line breaks are omitted for compactness (add `\\n` if line breaks are preferred).\n",
    "\n",
    "### **Example Use Case (GRE Study Tool)**\n",
    "```json\n",
    "// Extracting a single question for display\n",
    "{\n",
    "  \"question\": questions[0].question,\n",
    "  \"answer\":   questions[0].answer\n",
    "}\n",
    "\n",
    "Let me know if you’d like further refinements (e.g., adding metadata like \"difficulty\" or \"keywords\")!\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "icls = [{\n",
    "  \"icl_document\": (\n",
    "    \"Nietzsche argued that traditional morality is a \\\"slave morality\\\" created by the weak to subjugate the strong, claiming, \\\"The noble type of man experiences himself as the goal and measure of things; he does not require approval or justification from outsiders.\\\"\",\n",
    "    \"In contrast, slave morality, rooted in resentment, posits equality and humility as virtues to constrain natural superiority.\",\n",
    "    \"Nietzsche saw this as a perversion of life’s true will to power.\",\n",
    "    \"Only the Übermensch could transcend such moral dichotomies.\"\n",
    "  ),\n",
    "  \"icl_query_1\": \"Identify the central thesis of the passage and explain how the contrast between \\\"noble\\\" and \\\"slave\\\" morality supports Nietzsche’s broader philosophical claim.\",\n",
    "  \"icl_response_1\": \"The thesis is that traditional morality is a subversive construct of the weak (\\\"slave morality\\\") to undermine natural hierarchy, contrasting with the self-affirming \\\"noble morality\\\" of the strong. The passage supports this by framing noble morality as intrinsic (e.g., \\\"the goal and measure of things\\\") and slave morality as reactive (\\\"rooted in resentment\\\"). This dichotomy underscores Nietzsche’s claim that conventional ethics are not objective but a political tool to dilute the \\\"will to power\\\" of exceptional individuals.\",\n",
    "  \n",
    "  \"icl_query_2\": \"What unexamined assumption underlies Nietzsche’s critique of slave morality as a \\\"perversion of life\\\"? Analyze the implications if this assumption is challenged.\",\n",
    "  \"icl_response_2\": \"The assumption is that \\\"life’s true will to power\\\" is a universal, instinctual drive that should not be morally constrained. If challenged (e.g., if cooperation, not domination, is life’s primary drive), Nietzsche’s critique collapses, as slave morality’s emphasis on equality could be seen as adaptive rather than perverse. This would invert his hierarchy, legitimizing collective ethics over individual supremacy.\",\n",
    "\n",
    "  \"icl_query_3\": \"Apply Nietzsche’s framework to scientific progress. How might a \\\"noble\\\" vs. \\\"slave\\\" dynamic manifest in the pursuit of knowledge?\",\n",
    "  \"icl_response_3\": \"A \\\"noble\\\" scientific ethos might prioritize unencumbered innovation (e.g., unfunded maverick researchers pursuing risky, visionary projects). Conversely, \\\"slave morality\\\" could manifest in bureaucratic, consensus-driven science (e.g., funding prioritizing collaborative, \\\"socially responsible\\\" projects over disruptive ideas). Nietzsche would argue the latter stifles genius, while defenders might see it as ensuring ethical accountability—a parallel to his moral critique.\"\n",
    "},\n",
    "{\n",
    "    \"icl_document\": (\n",
    "      \"The coastal town of Willow Creek, once renowned for its pristine beaches, now struggles with rampant pollution. Plastic debris and oil spills have devastated marine life, prompting a decline in tourism and fishing industries. Residents have organized weekly clean-up initiatives, but the scale of the problem overwhelms their efforts.\",\n",
    "      \"Technologists at the local university have developed an AI-powered buoy system to combat this. The buoys, equipped with solar panels and filtration technology, can identify and absorb oil spills while collecting microplastics. Data from the buoys is shared publicly, raising awareness and pressuring corporations to adopt sustainable practices. Though costly, the project has sparked hope for revitalizing the ecosystem and economy.\"\n",
    "    ),\n",
    "    \"icl_query_1\": \"How does the technological solution address the economic *and* environmental challenges highlighted in the document?\",\n",
    "    \"icl_response_1\": \"The buoys directly mitigate environmental harm by absorbing spills and collecting plastics, which could restore marine life. Economically, this restoration might revive tourism and fishing, reversing their decline. Public data-sharing also pressures corporations, potentially reducing pollution and creating a sustainable economic cycle aligned with environmental health.\",\n",
    "    \n",
    "    \"icl_query_2\": \"What implicit values or priorities do the community’s actions (clean-up initiatives) and the technologists’ project reflect, and how do these align or contrast?\",\n",
    "    \"icl_response_2\": \"Both reflect a prioritization of environmental stewardship and community engagement. The clean-ups emphasize collective responsibility, while the buoy project highlights innovation and systemic accountability (targeting corporations). They align in seeking solutions but contrast in scale and approach—manual vs. technological, local vs. systemic.\",\n",
    "    \n",
    "    \"icl_query_3\": \"Imagine the buoy project succeeds. What unintended consequences might arise from its impact, considering document's themes?\",\n",
    "    \"icl_response_3\": \"Success could lead to reduced community participation in clean-up efforts if residents perceive the technology as a sufficient solution. Economically, revitalization might exacerbate existing resource strains (e.g., overwhelming local infrastructure) or create dependency on the buoy system, undermining long-term sustainability if the technology falters.\"\n",
    "\n",
    "}\n",
    "]\n",
    "\n",
    "# Load the quality corpus\n",
    "ds = load_dataset(\"zitongyang/entigraph-quality-corpus\", split='train').remove_columns(['entity', 'entigraph']).rename_columns({'raw': 'document', 'uid': 'document_outline'})\n",
    "\n",
    "# Add ICLs to the dataset\n",
    "ds = [ds.map(lambda x: icl) for icl in icls]\n",
    "ds = concatenate_datasets(ds)\n",
    "\n",
    "# Add additional columns needed for the knowledge generation pipeline\n",
    "ds = ds.add_column('domain', ['Article']*len(ds))\n",
    "\n",
    "# We now have the seed data ready. Let's save it\n",
    "ds.to_json(\"seed_data.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once we have the right set of ICLs, we now start generating the data\n",
    "- For running nemotron with reasoning we need to add few new custom blocks to the pipeline\n",
    "    - Block for post-processing the thinking output\n",
    "    \n",
    "    Note: Since merging of [#87](https://github.com/Red-Hat-AI-Innovation-Team/sdg_hub/pull/87) you can also simply use the `start` and `end` tag in prompt\n",
    "    - Block for parsing based on regular expression\n",
    "- We we also register nemotron thinking prompt with `detailed thinking on`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdg_hub.flow import Flow\n",
    "from sdg_hub.pipeline import Pipeline\n",
    "from sdg_hub.sdg import SDG\n",
    "from sdg_hub.prompts import PromptRegistry\n",
    "from sdg_hub.blocks import BlockRegistry, Block\n",
    "from transformers import AutoTokenizer\n",
    "import re\n",
    "from typing import List\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nvidia/Llama-3_3-Nemotron-Super-49B-v1\")\n",
    "\n",
    "@PromptRegistry.register(\"nvidia/Llama-3_3-Nemotron-Super-49B-v1\")\n",
    "def nemotron_chat_template():\n",
    "    return \"\"\"{{- bos_token }}\n",
    "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}detailed thinking on{{- \"<|eot_id|>\" }}\n",
    "{%- for message in messages %}\n",
    "  {%- if message['role'] == 'assistant' and '</think>' in message['content'] %}\n",
    "    {%- set content = message['content'].split('</think>')[-1].lstrip() %}\n",
    "  {%- else %}\n",
    "    {%- set content = message['content'] %}\n",
    "  {%- endif %}\n",
    "  {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n' + content | trim + '<|eot_id|>' }}\n",
    "{%- endfor %}\n",
    "{%- if add_generation_prompt %}\n",
    "  {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
    "{%- endif %}\"\"\"\n",
    "\n",
    "ds = load_dataset('json', data_files=\"seed_data.jsonl\", split=\"train\")\n",
    "@BlockRegistry.register(\"PostProcessThinkingBlock\")\n",
    "class PostProcessThinkingBlock(Block):\n",
    "    def __init__(self, block_name: str, column_name: str) -> None:\n",
    "        super().__init__(block_name=block_name)  \n",
    "        self.column_name = column_name\n",
    "    \n",
    "    \n",
    "    def generate(self, samples: Dataset):\n",
    "        def post_process_thinking(x):\n",
    "            if '</think>' in x[self.column_name]:\n",
    "                x[self.column_name] = x[self.column_name].split('</think>')[-1].lstrip()\n",
    "            return x\n",
    "        samples = samples.map(post_process_thinking)\n",
    "        return samples\n",
    "\n",
    "@BlockRegistry.register(\"RegexParserBlock\")\n",
    "class RegexParserBlock(Block):\n",
    "    def __init__(self, block_name: str, column_name: str, parsing_pattern: str=\"\", parser_cleanup_tags: List[str]=[], output_cols: List[str]=[]) -> None:\n",
    "        super().__init__(block_name=block_name)\n",
    "        self.column_name = column_name\n",
    "        self.parsing_pattern = parsing_pattern\n",
    "        self.parser_cleanup_tags = parser_cleanup_tags\n",
    "        self.output_cols = output_cols\n",
    "\n",
    "    def generate(self, samples: Dataset):\n",
    "        \n",
    "        if self.parsing_pattern:\n",
    "            new_data = []\n",
    "            for sample in samples:\n",
    "                parsed_outputs = self._parse(sample[self.column_name])\n",
    "                \n",
    "                max_length = max(len(value) for value in parsed_outputs.values())\n",
    "                for values in zip(*(lst[:max_length] for lst in parsed_outputs.values())):\n",
    "                    new_data.append({**sample, **dict(zip(parsed_outputs.keys(), values))})\n",
    "            samples = Dataset.from_list(new_data)\n",
    "        if self.parser_cleanup_tags:\n",
    "            for clean_tag in self.parser_cleanup_tags:\n",
    "               samples = samples.map(lambda x: {column_name: x[column_name].replace(clean_tag, \"\") for column_name in self.output_cols})\n",
    "        return samples\n",
    "\n",
    "    def _parse(self, generated_string):      \n",
    "        pattern = re.compile(self.parsing_pattern, re.DOTALL)\n",
    "        all_matches = pattern.findall(generated_string)\n",
    "        matches = {column_name: [] for column_name in self.output_cols}\n",
    "        if all_matches and isinstance(all_matches[0], tuple):\n",
    "            for match in all_matches:\n",
    "                for column_name, value in zip(self.output_cols, match):\n",
    "                    value = value.strip()\n",
    "                    # for clean_tag in self.parser_cleanup_tags:\n",
    "                    #     value = value.replace(clean_tag, \"\")\n",
    "                    matches[column_name].append(value)\n",
    "        else:\n",
    "            matches[self.output_cols[0]] = (\n",
    "                [match.strip() for match in all_matches] if all_matches else []\n",
    "            )\n",
    "        return matches\n",
    "\n",
    "knowledge_agentic_pipeline = \"flows/synth_knowledge_reasoning_nemotron_super_49b_summary_diversity.yaml\"\n",
    "flow_cfg = Flow(client).get_flow_from_file(knowledge_agentic_pipeline)\n",
    "sdg = SDG(\n",
    "    [Pipeline(flow_cfg)],\n",
    "    num_workers=1,\n",
    "    batch_size=1,\n",
    "    save_freq=1000,\n",
    ")\n",
    "ds_subset = ds.select(range(1))\n",
    "\n",
    "# Generate data\n",
    "generated_data = sdg.generate(ds_subset, checkpoint_dir=\"Tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### Question\")\n",
    "print(generated_data['question'][2])\n",
    "print(\"### Response\")\n",
    "print(generated_data['response'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output from reasoning SDGpipeline\n",
    "\n",
    "### Question\n",
    "Apply the \"necessity vs. cosmetic\" dynamic from the article to the field of plastic surgery. How might the strategies dentists use to market discretionary treatments parallel or diverge from those in cosmetic surgery, and what does this reveal about consumer behavior in health industries?  \n",
    "\n",
    "### Response\n",
    "```text\n",
    "<think>\n",
    "Okay, let's tackle this question. The user wants me to apply the \"necessity vs. cosmetic\" dynamic from the dentistry article to plastic surgery. I need to compare the marketing strategies between dentists and cosmetic surgeons, see where they're similar or different, and what that says about consumer behavior.\n",
    "\n",
    "First, I'll recall the article. Dentists shifted from necessity (fillings) to cosmetics (whitening, etc.) using tools like intra-oral cameras, scare tactics, and upselling. They exploited the lack of insurance coverage, making patients pay out-of-pocket for discretionary treatments.\n",
    "\n",
    "Now, plastic surgery. Cosmetic procedures are already discretionary, so maybe the strategies are similar. Both use technology (like simulations) to show results. Dentists use intra-oral cameras; surgeons might use 3D imaging to show potential outcomes. Both might use marketing based on societal beauty standards.\n",
    "\n",
    "But there might be differences. Plastic surgery is more invasive, so maybe more emphasis on safety and long-term results. Dentists use scare tactics like mercury in fillings; surgeons might focus on health benefits (e.g., breast reduction for back pain) even if the primary motive is cosmetic.\n",
    "\n",
    "Consumer behavior: Both industries thrive on discretionary spending driven by vanity and anxiety induced by marketing. However, plastic surgery might have higher barriers due to cost and risk, so marketing might need to balance desire with reassurance about safety. The article mentions that dentists blur necessity and indulgence; surgeons might frame cosmetic procedures as investments in well-being or confidence.\n",
    "\n",
    "Wait, the question also asks what this reveals about consumer behavior. Probably that consumers prioritize appearance over health needs when given the option, and industries exploit this by creating perceived needs through technology and marketing. The lack of insurance coverage forces consumers to weigh discretionary spending, leading them to prioritize wants over needs if marketed effectively.\n",
    "\n",
    "Need to structure the answer: parallel strategies (technology, societal ideals, upselling), divergent strategies (invasiveness, health angles), and consumer insights (vanity-driven, influenced by marketing, willing to spend on desires when enabled by financial models).\n",
    "</think>\n",
    "\n",
    "\n",
    "Applying the \"necessity vs. cosmetic\" dynamic to plastic surgery reveals both parallels and divergences in marketing strategies. **Parallels** include the use of technology (e.g., 3D simulation in surgery, akin to intra-oral cameras in dentistry) to amplify perceived flaws and sell discretionary treatments. Both fields leverage societal beauty standards (e.g., \"Great American Smile\" in dentistry, ideal body types in surgery) and employ upselling tactics (\"treatment acceptance\" scripts in dentistry, bundling procedures in surgery). **Divergences** arise from surgery’s higher stakes: while dentists focus on low-risk, repeatable cosmetics, surgeons must balance vanity-driven marketing with reassurances about safety and long-term outcomes (e.g., framing breast augmentation as a \"confidence investment\").  \n",
    "\n",
    "This dynamic reveals that consumer behavior in health industries is **vulnerability-driven** and **market-shaped**. Patients prioritize discretionary aesthetics over necessary care when industries successfully manufacture anxiety (e.g., \"halimeters\" for halitosis, or surgical \"imperfection\" analyses) and align treatments with cultural ideals. The absence of insurance coverage for cosmetics forces a calculus where consumers weigh desires against costs, often favoring indulgences when framed as transformative. Ultimately, both fields exploit a **decoupling of health needs from consumer demands**, proving that profitability in discretionary health markets hinges on blurring clinical necessity with emotional and social aspiration.  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output from non-reasoning SDG pipeline\n",
    "### Question\n",
    "Analyze the economic paradox underlying the dental industry’s shift: Why did patients prioritize discretionary cosmetic treatments over medically necessary care?\n",
    "### Response\n",
    "The paradox stems from dentistry’s reliance on out-of-pocket spending (60% of costs). Cosmetic procedures (e.g., bleaching) were marketed as immediate, desirable investments in appearance, while necessary care (e.g., gum surgery) was perceived as inconvenient or costly with delayed benefits. Dentists capitalized on this by aggressively selling \"wants\" to offset the resistance to \"needs,\" ensuring profitability in a market where insurance coverage was limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### Faithfulness Evaluation\")\n",
    "print(generated_data['explanation'][2])\n",
    "print(\"### Judgment\")\n",
    "print(generated_data['judgment'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faithfulness Evaluation\n",
    "The question references a specific \"article\" without providing its content, violating Non-Referential Clarity as it relies on unprovided external context. While it requires specialized knowledge (Subject-Aware Completeness), the core framework (\"necessity vs. cosmetic\") is not defined within the question, making it dependent on external information.\n",
    "### Judgment\n",
    "YES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Mixing for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Nemotron Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "nemotron_ds = load_dataset(\"nvidia/Llama-Nemotron-Post-Training-Dataset-v1\", \"SFT\")\n",
    "nemotron_ds = nemotron_ds.filter(lambda x: x['used_in_training'] == 'yes')\n",
    "nemotron_ds = nemotron_ds.map(lambda x: {'question': x['input'][x['input'].find(\"user<|end_header_id|>\") + len(\"user<|end_header_id|>\") : x['input'].find(\"<|eot_id|><|start_header_id|>assistant\")].strip()})\n",
    "nemotron_ds = concatenate_datasets(nemotron_ds.values())\n",
    "nemotron_ds = nemotron_ds.shuffle(seed=894375).select(range(200000))\n",
    "nemotron_ds = nemotron_ds.add_column('unmask', [False]*nemotron_ds.num_rows)\n",
    "nemotron_ds = nemotron_ds.map(lambda x: {'messages': [{'role': 'system', 'content': 'detailed thinking on'}, {'role': 'user', 'content': x['question']}, {'role': 'assistant', 'content': x['output']}]})\n",
    "nemotron_ds = nemotron_ds.remove_columns(['input', 'output', 'category', 'license', 'reasoning', 'generator', 'used_in_training', 'question'])\n",
    "nemotron_ds.to_json(\"nemotron_replay_buffer_data.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create functions for data mixng with conversation templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_training_mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create quality training mix of: reasoning dataset, with non-reasoning dataset, nemotron replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For this tutorial, we will use the following document uids from the quality dataset:\n",
    "DOC_UIDS = [\n",
    "    ' Defining Decay Down by David Plotz',\n",
    "    ' Fight Clubbed by David Plotz',\n",
    "    ' I, Antichrist? by Jeffrey Goldberg',\n",
    "    \" It's Time To Keelhaul U-Haul! by Jeffrey Goldberg\",\n",
    "    \" My Father's Estate by Ben Stein\",\n",
    "    '\"Phone Me in Central Park\" by McConnell, James V.',\n",
    "    '...After a Few Words... by Garrett, Randall', \n",
    "    '...And It Comes Out Here by Del Rey, Lester',\n",
    "    'A Coffin for Jacob by Ludwig, Edward W.',\n",
    "    'A Fall of Glass by Lee, Stanley R.',\n",
    "    'A Filbert Is a Nut by Raphael, Rick',\n",
    "    'A Gift from Earth by Banister, Manly',\n",
    "    'A Gleeb for Earth by Schafhauser, Charles',\n",
    "    'A Good Year for the Roses? by David Edelstein',\n",
    "    'A Pail of Air by Leiber, Fritz',\n",
    "    'A Planet Named Joe by Hunter, Evan',\n",
    "    \"AI: what's the worst that could happen? by Harry Armstrong\",\n",
    "    'Accidental Death by Baily, Peter',\n",
    "    'All Day September by Kuykendall, Roger',\n",
    "    'Ambition by Bade, William L.',\n",
    "    'And Then the Town Took Off by Wilson, Richard',\n",
    "    'Atom Mystery [Young Atom Detective] by Coombs, Charles Ira',\n",
    "    'Beach Scene by King, Marshall',\n",
    "    'Big Ancestor by Wallace, F. L. (Floyd L.)',\n",
    "    'Birds of a Feather by Silverberg, Robert',\n",
    "    'Bodyguard by Gold, H. L. (Horace Leonard)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    " \n",
    "# Load tokenizer for pre-training formatting\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nvidia/Llama-3.1-Nemotron-Nano-8B-v1\")\n",
    "\n",
    "# Load non-reasoning dataset from nemotron super 49b\n",
    "nemotron_non_reasoning_ds = load_dataset(\"json\", data_dir=\"/new_data/knowledge_rh/quality/knowledge1.25_nemotron_super_49b/\", split=\"train\")\n",
    "nemotron_non_reasoning_ds = nemotron_non_reasoning_ds.filter(lambda x: x['score'] == '2' and x['judgment'] == 'YES')\n",
    "nemotron_non_reasoning_ds = nemotron_non_reasoning_ds.filter(lambda x: x['document_outline'] in DOC_UIDS)\n",
    "print(nemotron_non_reasoning_ds)\n",
    "\n",
    "# Load reasoning dataset from nemotron super 49b\n",
    "nemotron_reasoning_ds = load_dataset(\"json\", data_dir=\"/new_data/knowledge_rh/quality/synth_knowledge_reasoning_nemotron_super_49b/gen\", split=\"train\")\n",
    "nemotron_reasoning_ds = nemotron_reasoning_ds.filter(lambda x: x['score'] == '2' and x['judgment'] == 'YES')\n",
    "nemotron_reasoning_ds = nemotron_reasoning_ds.filter(lambda x: x['document_outline'] in DOC_UIDS)\n",
    "print(nemotron_reasoning_ds)\n",
    "# Load nemotron replay buffer\n",
    "nemotron_ds_replay_buffer = load_dataset(\"json\", data_files=\"/new_data/knowledge_rh/quality/training_mix/nemotron_replay_buffer_data.jsonl\", split=\"train\")\n",
    "\n",
    "\n",
    "# Create non-reasoning training mix\n",
    "nemotron_ds_training_mix = create_training_mix(nemotron_non_reasoning_ds, tokenizer, 'off').shuffle(seed=894375)\n",
    "\n",
    "# Create reasoning training mix\n",
    "nemotron_reasoning_ds = create_training_mix(nemotron_reasoning_ds, tokenizer, 'on')\n",
    "\n",
    "# Concatenate reasoning and non-reasoning training mixes\n",
    "quality_reasoning_ds = concatenate_datasets([nemotron_reasoning_ds, nemotron_ds_training_mix]).remove_columns(['metadata', 'id']) # .select(range(40000))\n",
    "print(quality_reasoning_ds)\n",
    "\n",
    "# Concatenate training mix with replay buffer\n",
    "training_mix = concatenate_datasets([quality_reasoning_ds, nemotron_ds_replay_buffer.shuffle(seed=894375).select(range(len(quality_reasoning_ds)))])\n",
    "\n",
    "print(training_mix)\n",
    "training_mix.to_json(\"/new_data/knowledge_rh/quality/training_mix/quality_knowledge_1.25_nemotron_49b_first_24.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train student model\n",
    "- Setup the training by cloning `https://github.com/instructlab/training` and following the instructions in the README\n",
    "- The create `train.py` using below code\n",
    "    ```python\n",
    "    import argparse\n",
    "    from instructlab.training.config import TorchrunArgs,TrainingArgs,DistributedBackend,FSDPOptions\n",
    "    from instructlab.training.main_ds import run_training\n",
    "    import os\n",
    "    def parse_args():\n",
    "        parser = argparse.ArgumentParser(description='Training script with configurable paths')\n",
    "        parser.add_argument('--data_path', type=str, required=True,\n",
    "                        help='Path to the training data file')\n",
    "        parser.add_argument('--model_path', type=str, required=True,\n",
    "                        help='Path to the model or model identifier')\n",
    "        parser.add_argument('--chat_tmpl_path', type=str, required=True,\n",
    "                        help='Path to the chat template file')\n",
    "        parser.add_argument('--exp_dir', type=str, required=True,\n",
    "                        help='Path to the experiment directory')\n",
    "        parser.add_argument('--parent_exp_dir', type=str, required=True,\n",
    "                        help='Path to the parent experiment directory')\n",
    "        return parser.parse_args()\n",
    "\n",
    "    def main():\n",
    "        args = parse_args()\n",
    "        \n",
    "        torch_args = TorchrunArgs(\n",
    "            nproc_per_node=8,\n",
    "            nnodes=1,\n",
    "            node_rank=0,\n",
    "            rdzv_id=123,\n",
    "            rdzv_endpoint=\"0.0.0.0:8888\",\n",
    "        )\n",
    "        output_dir = os.path.join(args.parent_exp_dir, args.exp_dir)\n",
    "        train_args = TrainingArgs(\n",
    "            model_path=args.model_path,\n",
    "            data_path=args.data_path,\n",
    "            ckpt_output_dir=output_dir,\n",
    "            data_output_dir=\"data/processed-data\",\n",
    "            max_seq_len=20000,\n",
    "            max_batch_len=25000,\n",
    "            num_epochs=5,\n",
    "            effective_batch_size=256,\n",
    "            learning_rate=5e-6,\n",
    "            warmup_steps=25,\n",
    "            save_samples=0,\n",
    "            use_dolomite=False,\n",
    "            checkpoint_at_epoch = True,\n",
    "            accelerate_full_state_at_epoch = False,\n",
    "            process_data=True,\n",
    "            chat_tmpl_path=args.chat_tmpl_path,\n",
    "            distributed_backend=DistributedBackend.FSDP,\n",
    "            fsdp_options=FSDPOptions(cpu_offload_params=False),\n",
    "        )\n",
    "\n",
    "        run_training(torch_args=torch_args,train_args=train_args)\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        main()\n",
    "    ```\n",
    "\n",
    "- Now create bash script with run command\n",
    "\n",
    "    ```shell\n",
    "    python train.py \\\n",
    "    --data_path \"quality_knowledge_1.25_nemotron_49b_first_24.jsonl\" \\\n",
    "    --model_path \"nvidia/Llama-3.1-Nemotron-Nano-8B-v1\" \\\n",
    "    --chat_tmpl_path \"<chat_template_path>\" \\\n",
    "    --exp_dir \"nano_customized_thinking_quality_model\" \\\n",
    "    --parent_exp_dir \"<parent_exp_dir>\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For reference: scripts for running SDG, starting student model and training\n",
    "\n",
    "### Start Teacher Model\n",
    "```shell\n",
    "export HUGGINGFACE_HUB_CACHE=\"/new_data/hf_cache\"   \n",
    "export HF_DATASETS_CACHE=\"/dev/shm/hf\"\n",
    "export HF_HOME=\"/new_data/hf_cache\"\n",
    "export HF_MODEL_CACHE=\"/new_data/hf_cache\"\n",
    "\n",
    "for i in $(seq 0 2 6); do\n",
    "    port=$((8000 + i/2))\n",
    "    CUDA_VISIBLE_DEVICES=$i,$((i+1)) python -m vllm.entrypoints.openai.api_server \\\n",
    "        --model nvidia/Llama-3_3-Nemotron-Super-49B-v1 \\\n",
    "        --dtype float16 \\\n",
    "        --tensor-parallel-size 2 \\\n",
    "        --port $port \\\n",
    "        --trust-remote-code > log_$((i/2+1)).log 2>&1 &\n",
    "done\n",
    "```\n",
    "\n",
    "### Run SDG in parallel\n",
    "```shell\n",
    "# Get dataset size and save into variable\n",
    "dataset_size=$(wc -l seed_data.jsonl | awk '{print $1}')\n",
    "number_of_processes=4\n",
    "port=8000\n",
    "for i in {0..4}; do\n",
    "    # Continue until i=4\n",
    "    if [ $i -eq 4 ]; then\n",
    "        break\n",
    "    fi\n",
    "    dataset_start_index=$((i * dataset_size / number_of_processes))\n",
    "    dataset_end_index=$((dataset_start_index + dataset_size / number_of_processes))\n",
    "    python generate.py --ds_path  seed_data.jsonl \\\n",
    "        --bs 2 --num_workers 10 \\\n",
    "        --save_path /new_data/knowledge_rh/quality/knowledge1.25_nemotron_super_49b/gen.jsonl \\\n",
    "        --flow flows/synth_knowledge1.5_nemotron_super_49b.yaml \\\n",
    "        --endpoint http://localhost:$port/v1 \\\n",
    "        --checkpoint_dir /new_data/knowledge_rh/quality/knowledge1.25_nemotron_super_49b/data_checkpoints \\\n",
    "        --save_freq 1000 \\\n",
    "        --dataset_start_index $dataset_start_index \\\n",
    "        --dataset_end_index $dataset_end_index > run_sdg_$i.log 2>&1 &\n",
    "    echo \"Starting process $i with dataset from $dataset_start_index to $dataset_end_index on port $port\"\n",
    "    port=$((port + 1))\n",
    "done\n",
    "```\n",
    "\n",
    "### Run SDG on new reasoning pipeline\n",
    "```shell\n",
    "# Get dataset size and save into variable\n",
    "dataset_size=$(wc -l seed_data.jsonl | awk '{print $1}')\n",
    "number_of_processes=4\n",
    "port=8000\n",
    "for i in {0..4}; do\n",
    "    # Continue until i=4\n",
    "    if [ $i -eq 4 ]; then\n",
    "        break\n",
    "    fi\n",
    "    dataset_start_index=$((i * dataset_size / number_of_processes))\n",
    "    dataset_end_index=$((dataset_start_index + dataset_size / number_of_processes))\n",
    "    python generate.py --ds_path  seed_data.jsonl \\\n",
    "        --bs 2 --num_workers 10 \\\n",
    "        --save_path /new_data/knowledge_rh/quality/synth_knowledge_reasoning_nemotron_super_49b/gen.jsonl \\\n",
    "        --flow synth_knowledge_reasoning_nemotron_super_49b.yaml \\\n",
    "        --endpoint http://localhost:$port/v1 \\\n",
    "        --checkpoint_dir /new_data/knowledge_rh/quality/synth_knowledge_reasoning_nemotron_super_49b/data_checkpoints \\\n",
    "        --save_freq 1000 \\\n",
    "        --dataset_start_index $dataset_start_index \\\n",
    "        --dataset_end_index $dataset_end_index > run_sdg_$i.log 2>&1 &\n",
    "    echo \"Starting process $i with dataset from $dataset_start_index to $dataset_end_index on port $port\"\n",
    "    port=$((port + 1))\n",
    "done\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_sdg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
