# C:\Users\CRVI\OneDrive - Hall & Wilcox\promptflowcustomtools\pf-reasoning-tool-proj\pf_reasoning_tool\yamls\reasoning_tool_call.yaml
# --- REVERTED to minimal working custom_llm state (like v0.0.7) ---

$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Tool.schema.json
name: Reasoning LLM Tool # Keep name
description: "Calls an OpenAI reasoning model on Azure OpenAI using a PromptTemplate, parsing specific markers (#system/#developer, #user)." # Simplified description
type: custom_llm
category: HW_PF_tools
module: pf_reasoning_tool.tools.reasoning_tool_call # Correct module path
function: reasoning_llm # Correct function name

default_prompt: | # Keep default prompt
  # system:
  You are a helpful AI assistant designed for reasoning tasks.

  # user:
  {{question}}

inputs:
  # NO explicit 'prompt' input defined here

  connection:
    type: [AzureOpenAIConnection, OpenAIConnection, CustomConnection]
    description: The connection object for OpenAI or Azure OpenAI.
  deployment_name:
    type: [string]
    description: Name of the Azure OpenAI deployment (e.g., your o3-mini deployment).
  max_completion_tokens:
    type: [int]
    description: Maximum number of tokens for the completion.
    default: 5000
    optional: true
    ui_hints: {text_box_size: md} # Keep medium size
  reasoning_effort:
    type: [string]
    description: Select the reasoning effort level for the model.
    default: "low"
    optional: true
    dynamic_list:
      func_path: pf_reasoning_tool.tools.reasoning_tool_call.get_reasoning_effort_options # Correct full path
      func_kwargs: []
    allow_manual_entry: false
    is_multi_select: false

  # ---> REMOVED temperature input <---
  # ---> REMOVED response_format input <---
  # ---> REMOVED json_schema_definition input <---


outputs:
  output:
    type: [string]
    description: The text response generated by the language model.