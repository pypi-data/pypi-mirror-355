{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "55beb66a623793bd"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "from lightstream.core.scnn import StreamingCNN, StreamingConv2d\n",
    "from torchvision.models import resnet18, resnet34, resnet50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:48:58.234549100Z",
     "start_time": "2024-04-03T13:48:56.382074800Z"
    }
   },
   "id": "821154fb6c154597"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:48:58.234549100Z",
     "start_time": "2024-04-03T13:48:58.233548200Z"
    }
   },
   "id": "ce68884f32700708"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model definition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95718ab1767415d4"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "padding = 0\n",
    "\n",
    "stream_net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Conv2d(16, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Conv2d(16, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 16, kernel_size=3, padding=padding), torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:48:58.368301300Z",
     "start_time": "2024-04-03T13:48:58.234549100Z"
    }
   },
   "id": "bd6f8d91181799c8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "for i, layer in enumerate(stream_net.modules()):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        layer.weight.data *= 1.0\n",
    "        \n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.zero_()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:48:58.433727700Z",
     "start_time": "2024-04-03T13:48:58.373300900Z"
    }
   },
   "id": "65a3d6c1f50a4d37"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (6): ReLU()\n",
      "  (7): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (8): ReLU()\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (11): ReLU()\n",
      "  (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (13): ReLU()\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(stream_net)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:48:58.629378800Z",
     "start_time": "2024-04-03T13:48:58.435730400Z"
    }
   },
   "id": "2206f8e70f1d06de"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configurations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6664c577e2c5beb"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "tile_size = 128*15\n",
    "img_size = 128*25\n",
    "\n",
    "cuda = True  # execute this notebook on the GPU\n",
    "verbose = True   # enable / disable logging\n",
    "dtype = torch.float64  # test with double precision"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:48:58.684584400Z",
     "start_time": "2024-04-03T13:48:58.618331300Z"
    }
   },
   "id": "7a0f0baa666c29c8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "stream_net.type(dtype)\n",
    "if cuda: stream_net.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:48:59.287839300Z",
     "start_time": "2024-04-03T13:48:58.688621900Z"
    }
   },
   "id": "f478abffc3ce9fdb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configure streamingCNN\n",
    "IMPORTANT: setting gather_gradients to True makes the class save all the gradients of the intermediate feature maps. This is needed because we want to compare the feature map gradients between streaming and conventional backpropagation. However this also counteracts the memory gains by StreamingCNN. If you want to test the memory efficiency, set gather_gradients to False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d37d70c0d3421f13"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "\n",
      " Output lost Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "testing shape gradient fix\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " Lost(top:0.0, left:0.0, bottom:0.0, right:0.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:0.0, left:0.0, bottom:1.0, right:1.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:2.0, left:2.0, bottom:3.0, right:3.0)\n",
      "testing shape gradient fix\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " Lost(top:4.0, left:4.0, bottom:5.0, right:5.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:8.0, left:8.0, bottom:10.0, right:10.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:10.0, left:10.0, bottom:12.0, right:12.0)\n",
      "testing shape gradient fix\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) \n",
      " Lost(top:12.0, left:12.0, bottom:14.0, right:14.0)\n",
      "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:24.0, left:24.0, bottom:28.0, right:28.0)\n",
      "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1)) \n",
      " Lost(top:26.0, left:26.0, bottom:30.0, right:30.0)\n",
      "\n",
      " Input gradient lost Lost(top:28.0, left:28.0, bottom:32.0, right:32.0)\n"
     ]
    }
   ],
   "source": [
    "sCNN = StreamingCNN(stream_net, \n",
    "                    tile_shape=(1, 3, tile_size, tile_size), \n",
    "                    verbose=True,\n",
    "                    saliency=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:08.540851600Z",
     "start_time": "2024-04-03T13:48:59.295843500Z"
    }
   },
   "id": "2cd870206b255a89"
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the verbose flag is True than StreamingCNN will print for every layer in the network the required overlap that is needed to reconstruct the feature maps and gradients. The higher this is, the more tiles are needed to be inferences. It is always beneficial to increase the tile size as much as possible to make use of all the GPU memory."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cad5bbd0be54b30"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate random image and fake label"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "667550f1a8f6d206"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "image = torch.FloatTensor(3, img_size, img_size).normal_(0, 1)\n",
    "target = torch.tensor(50.)  # large value so we get larger gradients\n",
    "\n",
    "image = image.type(dtype)\n",
    "target = target.type(dtype)\n",
    "\n",
    "if cuda:\n",
    "    target = target.cuda()\n",
    "    image = image.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:09.224757700Z",
     "start_time": "2024-04-03T13:49:08.547357200Z"
    }
   },
   "id": "cc4e388db2427829"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:09.232275Z",
     "start_time": "2024-04-03T13:49:09.228272Z"
    }
   },
   "id": "1b9bc232937996ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run through network using streaming"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c92cc440cd75645d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 396, 396])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor(0.0365812165, device='cuda:0', dtype=torch.float64)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_output = sCNN.forward(image[None])\n",
    "print(stream_output.shape)\n",
    "stream_output.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:09.985620600Z",
     "start_time": "2024-04-03T13:49:09.231273300Z"
    }
   },
   "id": "14ee58248a07a1af"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "stream_output.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:09.994132200Z",
     "start_time": "2024-04-03T13:49:09.991132800Z"
    }
   },
   "id": "762fdcf9850c4c7b"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.5017883420, device='cuda:0', dtype=torch.float64,\n       grad_fn=<SigmoidBackward0>)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.sigmoid(torch.mean(stream_output)); output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:10.175451900Z",
     "start_time": "2024-04-03T13:49:09.995132100Z"
    }
   },
   "id": "a833c157e215563c"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(2450.0729573390, device='cuda:0', dtype=torch.float64,\n       grad_fn=<MseLossBackward0>)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = criterion(output, target)\n",
    "loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:10.289096600Z",
     "start_time": "2024-04-03T13:49:10.174451700Z"
    }
   },
   "id": "6081081438ef32f5"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "loss.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:10.389334900Z",
     "start_time": "2024-04-03T13:49:10.292095900Z"
    }
   },
   "id": "555dd52023b8fad8"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 396, 396])\n",
      "torch.Size([1, 16, 396, 396])\n"
     ]
    }
   ],
   "source": [
    "print(stream_output.shape)\n",
    "print(stream_output.grad.shape)\n",
    "full_gradients = sCNN.backward(image[None], stream_output.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:24.408773200Z",
     "start_time": "2024-04-03T13:49:10.433226200Z"
    }
   },
   "id": "c2d36b3edafb4e6b"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 3200, 3200])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sCNN.saliency_map.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:24.414776100Z",
     "start_time": "2024-04-03T13:49:24.401262800Z"
    }
   },
   "id": "1acf48d6ac39e88b"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "streaming_conv_gradients = []\n",
    "\n",
    "for i, layer in enumerate(stream_net.modules()):\n",
    "    if isinstance(layer, StreamingConv2d):\n",
    "        if layer.weight.grad is not None:\n",
    "            streaming_conv_gradients.append(layer.weight.grad.clone()) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:24.562493Z",
     "start_time": "2024-04-03T13:49:24.417279600Z"
    }
   },
   "id": "9b4c6c1f339fa2e2"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "sCNN.disable()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:24.647303200Z",
     "start_time": "2024-04-03T13:49:24.568511700Z"
    }
   },
   "id": "9caf49cce06c5f0e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare to conventional training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74e7c24c47c0bfcb"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "stream_net.type(dtype)\n",
    "if cuda: stream_net.cuda()\n",
    "\n",
    "for i, layer in enumerate(stream_net.modules()):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        if layer.weight.grad is not None:\n",
    "            layer.weight.grad.data.zero_()\n",
    "            layer.bias.grad.data.zero_()\n",
    "            \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:24.739997900Z",
     "start_time": "2024-04-03T13:49:24.653307Z"
    }
   },
   "id": "f570eb5063cdd391"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "conventional_gradients = []\n",
    "inps = []\n",
    "\n",
    "def save_grad(module, grad_in, grad_out):\n",
    "    global conventional_gradients\n",
    "    conventional_gradients.append(grad_out[0].clone())\n",
    "        \n",
    "for i, layer in enumerate(stream_net.modules()):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        layer.register_backward_hook(save_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:24.853334800Z",
     "start_time": "2024-04-03T13:49:24.748508800Z"
    }
   },
   "id": "3b31e08e29427099"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This output should be the same as the streaming output, if so, the loss will also be the same:\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76e88ba324844ae5"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([1, 16, 396, 396])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.requires_grad = True\n",
    "conventional_output = stream_net(image[None]); conventional_output.max()\n",
    "conventional_output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:27.121491400Z",
     "start_time": "2024-04-03T13:49:27.086952900Z"
    }
   },
   "id": "f6974420d6615a1e"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 396, 396])\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([1, 16, 396, 396])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(conventional_output.shape)\n",
    "stream_output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:29.221035Z",
     "start_time": "2024-04-03T13:49:29.202021Z"
    }
   },
   "id": "c29f896aa692a1b"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 396, 396]) torch.Size([1, 16, 396, 396])\n",
      "Equal output to streaming\n"
     ]
    }
   ],
   "source": [
    "# NOTE: sometimes output can be slightly bigger \n",
    "# (if tiles do not fit nicely on input image according to output stride)\n",
    "# In that case this check may fail.\n",
    "print(stream_output.shape, conventional_output.shape)\n",
    "max_error = torch.abs(stream_output.detach().cpu() - conventional_output.detach().cpu()).max().item()\n",
    "\n",
    "if max_error < 1e-7:\n",
    "    print(\"Equal output to streaming\")\n",
    "else:\n",
    "    print(\"NOT equal output to streaming\"),\n",
    "    print(\"error:\", max_error)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:51.132674Z",
     "start_time": "2024-04-03T13:49:51.062985500Z"
    }
   },
   "id": "54e6961142a52c24"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.5017883420, device='cuda:0', dtype=torch.float64,\n       grad_fn=<SigmoidBackward0>)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.sigmoid(torch.mean(conventional_output)); output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:53.289584100Z",
     "start_time": "2024-04-03T13:49:53.274062900Z"
    }
   },
   "id": "dab0ce2d17f05bb8"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(2450.0729573390, device='cuda:0', dtype=torch.float64,\n       grad_fn=<MseLossBackward0>)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = criterion(output, target); loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:54.428980700Z",
     "start_time": "2024-04-03T13:49:54.411953200Z"
    }
   },
   "id": "c48adcad2f38750a"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "loss.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:50:02.247587900Z",
     "start_time": "2024-04-03T13:49:58.348670500Z"
    }
   },
   "id": "fbb061cb856557d6"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 16, 3198, 3198])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conventional_gradients[-1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:50:03.095908900Z",
     "start_time": "2024-04-03T13:50:03.087392600Z"
    }
   },
   "id": "39c710f3672801ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare the gradients of the input image\n",
    "Using the saliency argument, we can compute the gradient w.r.t to the input image. If streaming is the same as conventional training, these gradients should be roughly equal"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6161a9b953a30d5c"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.940933880509066e-23\n"
     ]
    }
   ],
   "source": [
    "diff = image.grad.detach().cpu().numpy() - sCNN.saliency_map[0].numpy()\n",
    "print(diff.max())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:51:16.006178900Z",
     "start_time": "2024-04-03T13:50:21.436557800Z"
    }
   },
   "id": "f5e23077c982b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare the gradients of the conv2d layers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fb109b0b711f846"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv layer 0 \t Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv layer 1 \t Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv layer 2 \t Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv layer 3 \t Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv layer 4 \t Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv layer 5 \t Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "normal_conv_gradients = []\n",
    "j = 0\n",
    "for i, layer in enumerate(stream_net.modules()):\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        if layer.weight.grad is not None:\n",
    "            normal_conv_gradients.append(layer.weight.grad) \n",
    "            print('Conv layer', j, '\\t', layer)\n",
    "            j += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:51:16.013185800Z",
     "start_time": "2024-04-03T13:51:16.008185100Z"
    }
   },
   "id": "df05ee0e7443ea52"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conventional \n",
      "\n",
      "Conv layer 0 \t average gradient size: 0.0036485273676345594\n",
      "Conv layer 1 \t average gradient size: 0.00781425919608402\n",
      "Conv layer 2 \t average gradient size: 0.012253580144481552\n",
      "Conv layer 3 \t average gradient size: 0.011272891094830938\n",
      "Conv layer 4 \t average gradient size: 0.013415015877887996\n",
      "Conv layer 5 \t average gradient size: 0.012631999051938828\n"
     ]
    }
   ],
   "source": [
    "print('Conventional', '\\n')\n",
    "\n",
    "for i in range(len(streaming_conv_gradients)):\n",
    "    print(\"Conv layer\", i, \"\\t average gradient size:\", \n",
    "          float(torch.mean(torch.abs(streaming_conv_gradients[i].data))))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:51:16.161575400Z",
     "start_time": "2024-04-03T13:51:16.017697400Z"
    }
   },
   "id": "7a564fe7a995e37b"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming \n",
      "\n",
      "Conv layer 0 \t average gradient size: 0.0036485273676345464\n",
      "Conv layer 1 \t average gradient size: 0.007814259196084018\n",
      "Conv layer 2 \t average gradient size: 0.012253580144481519\n",
      "Conv layer 3 \t average gradient size: 0.011272891094830935\n",
      "Conv layer 4 \t average gradient size: 0.013415015877888002\n",
      "Conv layer 5 \t average gradient size: 0.012631999051938785\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Streaming', '\\n')\n",
    "for i in range(len(normal_conv_gradients)):\n",
    "    print(\"Conv layer\", i, \"\\t average gradient size:\", \n",
    "          float(torch.mean(torch.abs(normal_conv_gradients[i].data))))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:51:16.204604400Z",
     "start_time": "2024-04-03T13:51:16.155571300Z"
    }
   },
   "id": "e7e4bd209a2a575b"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv layer 0 \t max difference between kernel gradients: 1.7867651802561113e-15\n",
      "Conv layer 1 \t max difference between kernel gradients: 2.643718577388654e-15\n",
      "Conv layer 2 \t max difference between kernel gradients: 1.341982081015658e-14\n",
      "Conv layer 3 \t max difference between kernel gradients: 9.520162436160717e-15\n",
      "Conv layer 4 \t max difference between kernel gradients: 5.162537064506978e-15\n",
      "Conv layer 5 \t max difference between kernel gradients: 2.525757381022231e-15\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(streaming_conv_gradients)):\n",
    "    diff = torch.abs(streaming_conv_gradients[i].data - normal_conv_gradients[i].data)\n",
    "    max_diff = diff.max()\n",
    "    print(\"Conv layer\", i, \"\\t max difference between kernel gradients:\", \n",
    "          float(max_diff))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:51:16.338404400Z",
     "start_time": "2024-04-03T13:51:16.204604400Z"
    }
   },
   "id": "c91a1edbfbd9e631"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
