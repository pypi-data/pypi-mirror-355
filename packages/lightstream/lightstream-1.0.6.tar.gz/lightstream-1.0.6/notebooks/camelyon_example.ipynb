{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:11:39.520463100Z",
     "start_time": "2024-04-03T12:11:17.901201400Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyvips\n",
    "import pandas as pd\n",
    "import albumentationsxl as A\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lightstream.models.resnet.resnet import StreamingResNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightning.pytorch import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "ROOT_DIR = Path(\"/data/pathology/archives/breast/camelyon/CAMELYON16\")\n",
    "label_df = pd.read_csv(str(ROOT_DIR / Path(\"evaluation/reference.csv\")))\n",
    "image_dir = ROOT_DIR / Path(\"images\")\n",
    "\n",
    "label_df[\"label\"] = label_df[\"class\"].apply(lambda x: 0 if x ==\"negative\" else 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:11:39.616482900Z",
     "start_time": "2024-04-03T12:11:39.521972100Z"
    }
   },
   "id": "a3471843663327ed"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "test_df = label_df[label_df[\"image\"].str.startswith(\"test\")]\n",
    "train_df = label_df[label_df[\"image\"].str.startswith(\"normal\") | label_df[\"image\"].str.startswith(\"tumor\")]\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42,stratify=train_df[\"label\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:17:49.126999400Z",
     "start_time": "2024-04-03T12:17:49.099297500Z"
    }
   },
   "id": "eb6081b00071e300"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Normalizing with imagenet statistics is done during streaming in scnn.py, so we don't do that here\n",
    "image_size=4096\n",
    "train_transforms  = A.Compose([A.CropOrPad(image_size, image_size), A.Flip(p=0.5), A.ToDtype(\"float\", scale=True), A.ToTensor()])\n",
    "test_transforms = A.Compose([A.CropOrPad(image_size, image_size), A.ToDtype(\"float\", scale=True), A.ToTensor()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:11:39.870735600Z",
     "start_time": "2024-04-03T12:11:39.730880700Z"
    }
   },
   "id": "d401d6004fc0dcf1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class CamelyonDataset(Dataset):\n",
    "    def __init__(self, image_dir: list, df: pd.DataFrame, transform: A.Compose| None=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.df = df\n",
    "        self.transforms = transform\n",
    "        self.df[\"image_path\"] = self.df[\"image\"].apply(lambda x: image_dir / Path(x).with_suffix(\".tif\"))\n",
    "        \n",
    "        self.images = self.df[\"image_path\"].tolist()\n",
    "        self.labels = self.df[\"label\"].tolist()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        try:\n",
    "            image = pyvips.Image.new_from_file(self.images[item], level=5)[0:3]\n",
    "        except Exception as e:\n",
    "            image = pyvips.Image.new_from_file(self.images[item], page=5)[0:3]\n",
    "            \n",
    "        label = self.labels[item]\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)[\"image\"]\n",
    "        return image, label\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:17:51.199715100Z",
     "start_time": "2024-04-03T12:17:51.191200200Z"
    }
   },
   "id": "cec38921fb05e15e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1822831/2746024284.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df[\"image_path\"] = self.df[\"image\"].apply(lambda x: image_dir / Path(x).with_suffix(\".tif\"))\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=CamelyonDataset(image_dir=image_dir, df=train_df, transform=train_transforms), num_workers=1)\n",
    "valid_loader = DataLoader(dataset=CamelyonDataset(image_dir=image_dir, df=val_df, transform=test_transforms), num_workers=1)\n",
    "test_loader = DataLoader(dataset=CamelyonDataset(image_dir=image_dir, df=test_df, transform=test_transforms), num_workers=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:17:52.457985800Z",
     "start_time": "2024-04-03T12:17:52.444468600Z"
    }
   },
   "id": "e6016bb9d625b3ab"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics None\n",
      "No tile cache found, calculating it now\n",
      "\n",
      "Converting modules to nn.Identity()\n",
      "Executing pre-streaming initialization callbacks (if any):\n",
      "\n",
      "Initializing streaming model\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) \n",
      " Lost(top:2.0, left:2.0, bottom:1.0, right:1.0)\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) \n",
      " Lost(top:2.0, left:2.0, bottom:1.0, right:1.0)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:3.0, left:3.0, bottom:2.0, right:2.0)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:4.0, left:4.0, bottom:3.0, right:3.0)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:5.0, left:5.0, bottom:4.0, right:4.0)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:6.0, left:6.0, bottom:5.0, right:5.0)\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) \n",
      " Lost(top:4.0, left:4.0, bottom:3.0, right:3.0)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:5.0, left:5.0, bottom:4.0, right:4.0)\n",
      "Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) \n",
      " Lost(top:3.0, left:3.0, bottom:2.0, right:2.0)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:6.0, left:6.0, bottom:5.0, right:5.0)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:7.0, left:7.0, bottom:6.0, right:6.0)\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) \n",
      " Lost(top:4.0, left:4.0, bottom:3.0, right:3.0)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:5.0, left:5.0, bottom:4.0, right:4.0)\n",
      "Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) \n",
      " Lost(top:4.0, left:4.0, bottom:3.0, right:3.0)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:6.0, left:6.0, bottom:5.0, right:5.0)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:7.0, left:7.0, bottom:6.0, right:6.0)\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) \n",
      " Lost(top:4.0, left:4.0, bottom:3.0, right:3.0)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:5.0, left:5.0, bottom:4.0, right:4.0)\n",
      "Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) \n",
      " Lost(top:4.0, left:4.0, bottom:3.0, right:3.0)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:6.0, left:6.0, bottom:5.0, right:5.0)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:7.0, left:7.0, bottom:6.0, right:6.0)\n",
      "\n",
      " Output lost Lost(top:7.0, left:7.0, bottom:6.0, right:6.0)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:7.0, left:7.0, bottom:6.0, right:6.0)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:8.0, left:8.0, bottom:7.0, right:7.0)\n",
      "Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) \n",
      " Lost(top:9.0, left:9.0, bottom:8.0, right:8.0)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:9.0, left:9.0, bottom:8.0, right:8.0)\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) \n",
      " Lost(top:10.0, left:10.0, bottom:9.0, right:9.0)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:22.0, left:22.0, bottom:21.0, right:21.0)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:23.0, left:23.0, bottom:22.0, right:22.0)\n",
      "Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) \n",
      " Lost(top:24.0, left:24.0, bottom:23.0, right:23.0)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:24.0, left:24.0, bottom:23.0, right:23.0)\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) \n",
      " Lost(top:25.0, left:25.0, bottom:24.0, right:24.0)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:52.0, left:52.0, bottom:51.0, right:51.0)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:52.0, left:52.0, bottom:51.0, right:51.0)\n",
      "Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) \n",
      " Lost(top:56.0, left:56.0, bottom:55.0, right:55.0)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:56.0, left:56.0, bottom:55.0, right:55.0)\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) \n",
      " Lost(top:55.0, left:55.0, bottom:54.0, right:54.0)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:112.0, left:112.0, bottom:111.0, right:111.0)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:113.0, left:113.0, bottom:112.0, right:112.0)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:120.0, left:120.0, bottom:119.0, right:119.0)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      " Lost(top:119.0, left:119.0, bottom:118.0, right:118.0)\n",
      "testing shape gradient fix\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) \n",
      " Lost(top:120.0, left:120.0, bottom:119.0, right:119.0)\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) \n",
      " Lost(top:241.0, left:241.0, bottom:239.0, right:239.0)\n",
      "\n",
      " Input gradient lost Lost(top:490.0, left:490.0, bottom:487.0, right:487.0)\n",
      "Restoring model weights\n",
      "Executing post-streaming initialization callbacks (if any):\n",
      "\n",
      "writing streaming cache file to /tmp/pycharm_project_341/notebooks/tile_cache_1_3_2880_2880\n",
      "WARNING: Streaming network will not be trained\n"
     ]
    }
   ],
   "source": [
    "model = StreamingResNet(model_name=\"resnet18\", tile_size=2880, num_classes=2, train_streaming_layers=False, loss_fn=torch.nn.CrossEntropyLoss())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:18:25.090734900Z",
     "start_time": "2024-04-03T12:17:53.452768800Z"
    }
   },
   "id": "e88744eab8f570f8"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        default_root_dir=\"./\",\n",
    "        accelerator=\"gpu\",\n",
    "        max_epochs=15,\n",
    "        devices=1,\n",
    "        precision=\"16-mixed\",\n",
    "        strategy=\"auto\",\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:18:25.487969400Z",
     "start_time": "2024-04-03T12:18:25.100927Z"
    }
   },
   "id": "1d39a4e5766a599e"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: ./lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type             | Params\n",
      "----------------------------------------------------\n",
      "0 | stream_network | StreamingCNN     | 11.2 M\n",
      "1 | head           | Sequential       | 1.0 K \n",
      "2 | loss_fn        | CrossEntropyLoss | 0     \n",
      "----------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "11.2 M    Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.710    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff9113679b4748f3ace1cfcd68f33371"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.\n",
      "/usr/local/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a105cd9ff59d429bacdf2b45fa85ffcf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93c933e94fa6441ca3b462b2322057d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2260f2628e5f4283b813716b82eff7f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea6287046f134448bc235dd6cd664236"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "660b884751954962a62679204dbbc04f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a93439a5cc084007acfe19c8e9447226"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c92b7510efe43ed8cd2223852de48d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40fbdb4b3f1e4f2e8ad95a031f8df675"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6343c0bad6824549b734dbef26b05618"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00416d6eb913428b984cef68419afdda"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2499c624c6f43a28ba5fba0c30dc360"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52521f76b2044a468be31c82276f590a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3cd578bfda734f2eb231b2018231e6c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a4bfbfb2d49451a9eb455baa0ea0ab5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c0258ccff24492ea90e5418918c15c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea02f46070d949fd8428aee10dad0d0c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=valid_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:38:49.424504300Z",
     "start_time": "2024-04-03T12:18:25.487969400Z"
    }
   },
   "id": "6428abfa349c40d6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
