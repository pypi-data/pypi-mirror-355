{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install flotorch-eval crewai plotly opentelemetry-api opentelemetry-sdk pandas ragas duckduckgo-search openlit langchain_aws\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../../..\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from opentelemetry import trace\n",
        "from opentelemetry.sdk.trace import TracerProvider\n",
        "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
        "from opentelemetry.sdk.trace.export.in_memory_span_exporter import InMemorySpanExporter\n",
        "\n",
        "\n",
        "# Create an in-memory span exporter\n",
        "memory_exporter = InMemorySpanExporter()\n",
        "span_processor = SimpleSpanProcessor(memory_exporter)\n",
        "\n",
        "# Set up the tracer provider and add the span processor\n",
        "tracer_provider = TracerProvider()\n",
        "tracer_provider.add_span_processor(span_processor)\n",
        "trace.set_tracer_provider(tracer_provider)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openlit\n",
        "\n",
        "# Initialize OpenLit - this will automatically instrument CrewAI when it's imported\n",
        "openlit.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai.tools import tool\n",
        "from duckduckgo_search import DDGS\n",
        "\n",
        "@tool('DuckDuckGoSearch')\n",
        "def search_tool(search_query: str):\n",
        "    \"\"\"Search the web for information on a given topic\"\"\"\n",
        "    return DDGS().text(search_query, max_results=5)\n",
        "\n",
        "@tool('SalesforceIntegration')\n",
        "def salesforce_tool(soql_query: str):\n",
        "    \"\"\"Call Salesforce API to get data\"\"\"\n",
        "    return \"Salesforce Integration\"\n",
        "\n",
        "from crewai import LLM\n",
        "\n",
        "model = LLM(\n",
        "    # model=\"sagemaker/INSERT ENDPOINT NAME\",\n",
        "    model=\"bedrock/us.amazon.nova-pro-v1:0\",\n",
        "    temperature=0.7, max_tokens=4*1024,\n",
        ")\n",
        "\n",
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "\n",
        "writer = Agent(\n",
        "        role=\"Writer\",\n",
        "        goal=\"You make GenAI concepts understandable for newbies exploring GenAI on AWS\",\n",
        "        backstory=\"You're an expert in writing crisp summaries about GenAI on AWS.\",\n",
        "        tools=[search_tool],\n",
        "        llm=model\n",
        "    )\n",
        "\n",
        "task = Task(description=(\"What is {topic}?\"),\n",
        "            expected_output=(\"Compose a short summary that includes the answer.\"),\n",
        "            agent=writer)\n",
        "\n",
        "crew = Crew(\n",
        "  agents=[writer],\n",
        "  tasks=[task],\n",
        "  share_crew=False\n",
        ")\n",
        "\n",
        "result = crew.kickoff({\"topic\": \"AWS Bedrock\"})\n",
        "print(result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spans = memory_exporter.get_finished_spans()\n",
        "\n",
        "print(\"Number of spans:\", len(spans))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_aws import ChatBedrockConverse\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "region = \"us-east-1\"\n",
        "\n",
        "bedrock_model = ChatBedrockConverse(\n",
        "    region_name=region,\n",
        "    endpoint_url=f\"https://bedrock-runtime.us-east-1.amazonaws.com\",\n",
        "    model_id=\"us.amazon.nova-micro-v1:0\"\n",
        ")\n",
        "\n",
        "llm = LangchainLLMWrapper(bedrock_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from flotorch_eval.agent_eval.core.converter import TraceConverter\n",
        "\n",
        "def create_trajectory(spans):\n",
        "    converter = TraceConverter()\n",
        "    trajectory = converter.from_spans(spans)\n",
        "    return trajectory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trajectory = create_trajectory(spans)\n",
        "trajectory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from flotorch_eval.agent_eval.core.evaluator import Evaluator\n",
        "from flotorch_eval.agent_eval.metrics.langchain_metrics import (\n",
        "    TrajectoryEvalWithLLMMetric,\n",
        "    TrajectoryEvalWithoutLLMMetric,\n",
        ")\n",
        "from flotorch_eval.agent_eval.metrics.latency_metrics import LatencyMetric\n",
        "# from flotorch_eval.agent_eval.metrics.ragas_metrics import (\n",
        "#     AgentGoalAccuracyMetric,\n",
        "#     ToolCallAccuracyMetric,\n",
        "# )\n",
        "from flotorch_eval.agent_eval.metrics.base import MetricConfig\n",
        "from flotorch_eval.agent_eval.metrics.usage_metrics import UsageMetric\n",
        "\n",
        "\n",
        "from flotorch_eval.agent_eval.metrics_new.agent_goal_accuracy import AgentGoalAccuracyMetric\n",
        "from flotorch_eval.agent_eval.metrics_new.tool_call_accuracy import ToolCallAccuracyMetric\n",
        "\n",
        "evaluator = Evaluator([\n",
        "    ToolCallAccuracyMetric(),\n",
        "    AgentGoalAccuracyMetric(llm=llm,config=MetricConfig(\n",
        "        metric_params={\n",
        "            \"reference_answer\": \"Amazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. It allows users to build generative AI applications with a choice of foundation models from different AI companies, using a single API. Users can customize these models with their data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI. Additionally, Amazon Bedrock enables the creation of generative AI workflows by connecting its features with other AWS services.\"  # optional\n",
        "        }\n",
        "    )),\n",
        "    TrajectoryEvalWithLLMMetric(llm = bedrock_model,config=MetricConfig(\n",
        "        metric_params={\n",
        "            \"reference_outputs\": [\n",
        "                {\"role\": \"user\", \"content\": \"What is AWS Bedrock?\"},\n",
        "                {\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": \"To compose a poem about Amazon Bedrock, I first need to gather information about what Amazon Bedrock is. I will use the available tool to search for this information.\",\n",
        "                    \"tool_calls\": [\n",
        "                        {\n",
        "                            \"function\": {\n",
        "                                \"name\": \"Search the web for information on a given topic\",\n",
        "                                \"arguments\": \"{\\\"search_query\\\": \\\"Amazon Bedrock\\\"}\"\n",
        "                            }\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "                {\"role\": \"tool\", \"content\": \"{\\\"searchParameters\\\": {\\\"q\\\": \\\"Amazon Bedrock\\\", \\\"type\\\": \\\"search\\\", \\\"num\\\": 5, \\\"engine\\\": \\\"google\\\"}, \\\"organic\\\": [{\\\"title\\\": \\\"Amazon Bedrock - Generative AI - AWS\\\", \\\"link\\\": \\\"https://aws.amazon.com/bedrock/\\\", \\\"snippet\\\": \\\"Amazon Bedrock Data Automation streamlines the generation of valuable insights from unstructured multimodal content such as documents, images, audio, and videos ...\\\", \\\"position\\\": 1, \\\"sitelinks\\\": [{\\\"title\\\": \\\"Amazon Bedrock\\\", \\\"link\\\": \\\"https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html\\\"}, {\\\"title\\\": \\\"Amazon Bedrock Pricing\\\", \\\"link\\\": \\\"https://aws.amazon.com/bedrock/pricing/\\\"}, {\\\"title\\\": \\\"Amazon Bedrock Documentation\\\", \\\"link\\\": \\\"https://docs.aws.amazon.com/bedrock/\\\"}, {\\\"title\\\": \\\"Amazon Bedrock FAQs\\\", \\\"link\\\": \\\"https://aws.amazon.com/bedrock/faqs/\\\"}, {\\\"title\\\": \\\"Amazon Bedrock Agents\\\", \\\"link\\\": \\\"https://aws.amazon.com/bedrock/agents/\\\"}]}, {\\\"title\\\": \\\"Getting Started with Amazon Bedrock - AWS\\\", \\\"link\\\": \\\"https://aws.amazon.com/awstv/watch/6ff4cd6fa97/\\\", \\\"snippet\\\": \\\"So check the region that you're currently in, make sure it's a region that's supported by Bedrock. Then I'm gonna scroll to the bottom of this ...\\\", \\\"position\\\": 2}], \\\"relatedSearches\\\": [{\\\"query\\\": \\\"Amazon Bedrock pricing\\\"}, {\\\"query\\\": \\\"Amazon Bedrock documentation\\\"}, {\\\"query\\\": \\\"Amazon Bedrock Claude\\\"}, {\\\"query\\\": \\\"Amazon Bedrock logo\\\"}, {\\\"query\\\": \\\"Amazon Bedrock DeepSeek\\\"}], \\\"credits\\\": 1}\"},\n",
        "                {\"role\": \"assistant\", \"content\": \"Based on the observation, I have learned that mazon Bedrock is a fully managed service that makes it easy to use foundation models from third-party providers and Amazon. It allows users to build generative AI applications with a choice of foundation models from different AI companies, using a single API. Users can customize these models with their data, orchestrate multistep tasks, trace reasoning, and apply guardrails for responsible AI. Additionally, Amazon Bedrock enables the creation of generative AI workflows by connecting its features with other AWS services.\"}\n",
        "            ]\n",
        "        }\n",
        "    )),\n",
        "    UsageMetric(config=MetricConfig(\n",
        "        metric_params={\"aws_region\": \"us-east-1\"}\n",
        "    )),\n",
        "    LatencyMetric()\n",
        "])\n",
        "\n",
        "# Evaluate trajectory\n",
        "results = await evaluator.evaluate(trajectory)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results.scores"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
