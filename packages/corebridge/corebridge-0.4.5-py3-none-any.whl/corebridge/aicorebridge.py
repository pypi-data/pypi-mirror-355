# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_aicorebridge.ipynb.

# %% auto 0
__all__ = ['annotated_arg_builders', 'build_historic_args', 'AICoreModule']

# %% ../nbs/01_aicorebridge.ipynb 4
import typing
import logging
import traceback
import inspect
import datetime
import json
import os
import time
import pandas, pandas as pd
import numpy, numpy as np

from dateutil import parser
from fastcore.basics import patch_to, patch
from .core import *
from . import __version__


# %% ../nbs/01_aicorebridge.ipynb 6
#| eval: false
syslog = logging.getLogger(__name__)

# %% ../nbs/01_aicorebridge.ipynb 7
#| eval: false
try:
    syslog.debug(f"Loading {__name__} {__version__} from {__file__}")
except:  # noqa: E722
    pass

# %% ../nbs/01_aicorebridge.ipynb 9
def build_historic_args(data:pd.DataFrame, history:dict|list) -> dict:
    """Create a timeseries DataFrame from historic data defined in `history`.

    Parameters
    ----------
    data : pd.DataFrame
        The input time-series DataFrame.
    history : dict or list of dicts
        Historic data definition, each item in the list is a dictionary with a startDate key to set the start of a section of historic data in the result and a column-value pair for each of the columns in the 

    Returns
    -------
    historic_data : dict
        Historic data in dictionary format where keys are column names and values are the historic values as numpy array.
    """

    if not history:
        return {}
    
    if isinstance(history, dict):
        return history
    
    if not isinstance(history, list):
        return {}
    
    if isinstance(data, pd.DataFrame):
        dates = data.index.astype(np.int64).astype(np.float64) / 1e9
        dates = dates.to_numpy()
    elif data.dtype.names is not None:
        dates = data.view(dtype=np.float64).reshape(data.shape[0],len(data.dtype))[:,0]
    else:
        dates = data[:,0]
    dates = dates.astype(np.int64)
    
    columns = list(set([K for I in history for K in I.keys() if K != 'startDate']))
    column_data = {K:np.full(len(dates), np.nan, dtype=np.float64) for K in columns}

    for I in history:
        date = parser.parse(str((I.pop('startDate','2000-01-01T00:00:00+00:00')))).timestamp()
        mask = np.greater_equal(dates, date)
        for K,V in I.items():
            column_data[K][mask] = V
    
    return column_data
    #return pd.DataFrame(column_data, index=data.index)


# %% ../nbs/01_aicorebridge.ipynb 15
class AICoreModule(AICoreModuleBase):
    def __init__(self, 
             processor:typing.Callable, # data processing function
             save_dir:str, # path where the module can keep files 
             assets_dir:str,
             *args, **kwargs):
    
        super().__init__(save_dir, assets_dir, *args, **kwargs)
        self._init_processor(processor)



# %% ../nbs/01_aicorebridge.ipynb 16
# TODO: Refactor into Processor classes to handle different funtion types

@patch
def _init_processor(
        self:AICoreModule, 
        processor:typing.Callable):
    """Initializes processor related variables on self"""
    
    self.processor = processor
    self.processor_signature = inspect.signature(self.processor)
    self.processor_params = dict(self.processor_signature.parameters)
    self.return_param = self.processor_params.pop('return', None)
    
    self.data_param, *self.call_params = list(self.processor_params.keys())

    if not (
        self.processor_params[self.data_param].annotation == pd.DataFrame
        or self.processor_params[self.data_param].annotation == np.ndarray

    ):

        self.data_param = None
        self.call_params = list(self.processor_params.keys())



# %% ../nbs/01_aicorebridge.ipynb 17
# can be overloaded
@patch
def call_processor(self:AICoreModule, calldata, **callargs):
    if self.data_param:
        return self.processor(calldata, **callargs)
    else:
        return self.processor(**callargs)


# %% ../nbs/01_aicorebridge.ipynb 19
@patch
def infer(self:AICoreModule, data:dict, *_, **kwargs):
    """Infer the data using the processor function."""

    msg=[
        f"Startup time: {self.init_time.isoformat()}",
        f"Corebridge version: {self.aicorebridge_version}",
    ]

    try:
        t00 = time.perf_counter_ns()
        kwargs["data"] = data
        msg+=[
            f"{self.processor.__name__}({self.processor_signature})",  
            f"Data: {type(data)} length: {len(data)}",    
            f"kwargs {list(kwargs.keys())}",       
            #f"init_args: {self.init_args}, init_kwargs: {self.init_kwargs}",
        ]

        # Pickup params, pop those that are not intended for the processor
        lastSeen = kwargs.pop('lastSeen', False)
        recordformat = kwargs.pop('format', "records").lower()
        timezone = kwargs.get('timezone', 'UTC')
        msg.append(f"lastSeen: {lastSeen}, recordformat: {recordformat}, timezone: {timezone}")

        samplerPeriod = kwargs.pop('samplerPeriod', self.init_kwargs.get('samplerPeriod','h'))
        samplerMethod = kwargs.pop('samplerMethod', self.init_kwargs.get('samplerMethod',None))
        reversed = kwargs.pop('reversed', False)

        calldata = self.get_call_data(
            data, 
            recordformat=recordformat,
            timezone=timezone)
            
        history = build_historic_args(calldata, kwargs.pop('history', {}))
        callargs = self.get_callargs(kwargs, history)

        # for arg, val in callargs.items():
        #     msg.append(f"{arg}: {val}")
        
        t02 = time.perf_counter_ns()
        calculated_result = self.call_processor(
            calldata, 
            **callargs
        )
        t03 = time.perf_counter_ns()
        msg.append(f"Processing time: {(t03-t02)/1e6:.1f} ms")
        msg.append(f"Preparation time: {(t02-t00)/1e6:.1f} ms")

        if isinstance(calculated_result, dict):
            msg.append(f"return-data ictionary keys: {calculated_result.keys()}")
            return {
                'msg':msg,
                'data': [calculated_result]
            }
        elif isinstance(calculated_result, list):
            msg.append(f"return-data list length: {len(calculated_result)}")
            return {
                'msg':msg,
                'data': calculated_result
            }

        try:
            result = timeseries_dataframe(
                calculated_result, 
                timezone=timezone)
            
            msg.append(f"result shape: {result.shape}")

            if samplerMethod:
                msg.append(f"Sampler: {samplerMethod}, period: {samplerPeriod}")
                result = timeseries_dataframe_resample(result, samplerPeriod, samplerMethod)

            msg.append(f"return-data shape: {result.shape}")

            if reversed:
                result = result[::-1]

            return {
                'msg':msg,
                'data': timeseries_dataframe_to_datadict(
                    result if not lastSeen else result[-1:],
                    recordformat=recordformat,
                    timezone=timezone,
                    popNaN=True)
            }
        
        # tries dataframe return
        except Exception as err:
            msg.append(f"No timeseries data, error={err}")
        
        df = pd.DataFrame(calculated_result)
        df
        df.columns = [f"value_{str(c)}" if isinstance(c, int) else str(c) for c in list(df.columns)]
        df.reset_index().to_dict(orient='records')
        return {
            'msg':msg,
            'data': df.reset_index().to_dict(orient='records')
        }

    
    # function try-catch
    except Exception as err:
        msg.append(''.join(traceback.format_exception(None, err, err.__traceback__)))
        return {
            'msg': msg,
            'data': []
        }


# %% ../nbs/01_aicorebridge.ipynb 21
# Specialized types for initializing annotated parameters
# Add types by adding a tuple with the type name and a builder function
annotated_arg_builders = {
    str(B[0]):B[1] for B in [
        (numpy.ndarray, lambda X: numpy.array(X, dtype=X.dtype))
    ]
}


# %% ../nbs/01_aicorebridge.ipynb 23
@patch
def init_annotated_param(self:AICoreModule, param_name, value):
    """
    Initialize argument for the processor call
    
    param_name: name of the parameter to be initialized
    value: value of the parameter read from infer data to be used for initialization
    
    """

    annotation = self.processor_signature.parameters[param_name].annotation
    #print(f"param_name: {param_name}, value: {value}, annotation: {annotation}")

    # try to convert value to one of the types in the builders of annotated_arg_builders
    for T in typing.get_args(annotation):
        try:
            builder = annotated_arg_builders.get(str(T), lambda X:T(X))
            return builder(value)
        
        except TypeError as err:
            continue

    try:
        return annotation(value)
    
    except TypeError as err:
        syslog.exception(f"Exception {str(err)} in fallback conversion to {annotation} of {type(value)}")

 

# %% ../nbs/01_aicorebridge.ipynb 24
@patch
def get_callargs(self:AICoreModule, kwargs, history):
    "Get arguments for the processor call"

    # Remove null / None values
    kwargs = {k:v for k,v in kwargs.items() if v is not None}
    
    call_args = {
        K:self.init_annotated_param(
            K,
            history.get(
                K,
                kwargs.get(
                    K,
                    self.init_kwargs.get(
                        K, 
                        history.get(
                            snake_case_to_camel_case(K),
                            kwargs.get(
                                snake_case_to_camel_case(K),
                                self.init_kwargs.get(
                                    snake_case_to_camel_case(K), 
                                    self.processor_signature.parameters[K].default
                                )
                            )
                        )
                    )
                )
            )
        )
        for K in self.call_params
    }

    return call_args


# %% ../nbs/01_aicorebridge.ipynb 27
@patch
def get_call_data(
        self:AICoreModule, 
        data:dict|list, 
        recordformat='records', 
        timezone='UTC'):
    
    "Convert data to the processor signature"
    
    if not self.data_param:
        return None

    df = set_time_index_zone(timeseries_dataframe_from_datadict(
        data, ['datetimeMeasure', 'time'], recordformat), timezone)

    df.sort_index(inplace=True)

    if self.processor_params[self.data_param].annotation == pd.DataFrame:
        return df
    elif len(df.columns) > 1:
        df.index = (df.index - datetime.datetime(1970,1,1, tzinfo=datetime.timezone.utc)) / datetime.timedelta(seconds=1)
        return df.to_records(index=True)
    else:
        df.index = (df.index - datetime.datetime(1970,1,1, tzinfo=datetime.timezone.utc)) / datetime.timedelta(seconds=1)
        return df.reset_index().to_numpy()
        
