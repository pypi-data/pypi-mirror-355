#! /usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Chain of Thought client for orchestrating multiple LLM calls.
"""

import asyncio
import time
from abc import ABC, abstractmethod
from enum import Enum
from typing import Callable, Dict, Any, Optional, List, Union
from dataclasses import dataclass, field

from sparrow.llm.openaiclient import OpenAIClient


class StepStatus(Enum):
    """æ­¥éª¤æ‰§è¡ŒçŠ¶æ€æšä¸¾"""
    PENDING = "pending"      # ç­‰å¾…æ‰§è¡Œ
    RUNNING = "running"      # æ­£åœ¨æ‰§è¡Œ
    COMPLETED = "completed"  # æ‰§è¡Œå®Œæˆ
    FAILED = "failed"        # æ‰§è¡Œå¤±è´¥
    TIMEOUT = "timeout"      # æ‰§è¡Œè¶…æ—¶
    CANCELLED = "cancelled"  # æ‰§è¡Œå–æ¶ˆ


class ChainStatus(Enum):
    """é“¾æ¡æ‰§è¡ŒçŠ¶æ€æšä¸¾"""
    PENDING = "pending"      # ç­‰å¾…æ‰§è¡Œ
    RUNNING = "running"      # æ­£åœ¨æ‰§è¡Œ
    COMPLETED = "completed"  # æ‰§è¡Œå®Œæˆ
    FAILED = "failed"        # æ‰§è¡Œå¤±è´¥
    TIMEOUT = "timeout"      # æ‰§è¡Œè¶…æ—¶
    CANCELLED = "cancelled"  # æ‰§è¡Œå–æ¶ˆ


@dataclass
class ExecutionConfig:
    """
    æ‰§è¡Œé…ç½®ç±»ã€‚
    
    Attributes:
        step_timeout: å•ä¸ªæ­¥éª¤çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNoneè¡¨ç¤ºæ— è¶…æ—¶
        chain_timeout: æ•´ä¸ªé“¾æ¡çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNoneè¡¨ç¤ºæ— è¶…æ—¶
        max_retries: å•ä¸ªæ­¥éª¤çš„æœ€å¤§é‡è¯•æ¬¡æ•°
        retry_delay: é‡è¯•é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
        enable_monitoring: æ˜¯å¦å¯ç”¨ç›‘æ§
        log_level: æ—¥å¿—çº§åˆ« ("DEBUG", "INFO", "WARNING", "ERROR")
        enable_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
    """
    step_timeout: Optional[float] = None
    chain_timeout: Optional[float] = None
    max_retries: int = 0
    retry_delay: float = 1.0
    enable_monitoring: bool = True
    log_level: str = "WARNING"
    enable_progress: bool = False


@dataclass
class StepExecutionInfo:
    """
    æ­¥éª¤æ‰§è¡Œä¿¡æ¯ã€‚
    
    Attributes:
        step_name: æ­¥éª¤åç§°
        status: æ‰§è¡ŒçŠ¶æ€
        start_time: å¼€å§‹æ—¶é—´
        end_time: ç»“æŸæ—¶é—´
        execution_time: æ‰§è¡Œæ—¶é—´
        retry_count: é‡è¯•æ¬¡æ•°
        error: é”™è¯¯ä¿¡æ¯
        memory_usage: å†…å­˜ä½¿ç”¨é‡ï¼ˆå¯é€‰ï¼‰
    """
    step_name: str
    status: StepStatus = StepStatus.PENDING
    start_time: Optional[float] = None
    end_time: Optional[float] = None
    execution_time: Optional[float] = None
    retry_count: int = 0
    error: Optional[str] = None
    memory_usage: Optional[float] = None


@dataclass
class ChainExecutionInfo:
    """
    é“¾æ¡æ‰§è¡Œä¿¡æ¯ã€‚
    
    Attributes:
        chain_id: é“¾æ¡ID
        status: æ‰§è¡ŒçŠ¶æ€
        start_time: å¼€å§‹æ—¶é—´
        end_time: ç»“æŸæ—¶é—´
        total_execution_time: æ€»æ‰§è¡Œæ—¶é—´
        steps_info: å„æ­¥éª¤æ‰§è¡Œä¿¡æ¯
        total_steps: æ€»æ­¥éª¤æ•°
        completed_steps: å·²å®Œæˆæ­¥éª¤æ•°
        error: é”™è¯¯ä¿¡æ¯
    """
    chain_id: str
    status: ChainStatus = ChainStatus.PENDING
    start_time: Optional[float] = None
    end_time: Optional[float] = None
    total_execution_time: Optional[float] = None
    steps_info: List[StepExecutionInfo] = field(default_factory=list)
    total_steps: int = 0
    completed_steps: int = 0
    error: Optional[str] = None


class ChainMonitor(ABC):
    """é“¾æ¡ç›‘æ§å™¨æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    async def on_chain_start(self, chain_info: ChainExecutionInfo) -> None:
        """é“¾æ¡å¼€å§‹æ‰§è¡Œæ—¶è°ƒç”¨"""
        pass
    
    @abstractmethod
    async def on_chain_end(self, chain_info: ChainExecutionInfo) -> None:
        """é“¾æ¡æ‰§è¡Œç»“æŸæ—¶è°ƒç”¨"""
        pass
    
    @abstractmethod
    async def on_step_start(self, step_info: StepExecutionInfo, chain_info: ChainExecutionInfo) -> None:
        """æ­¥éª¤å¼€å§‹æ‰§è¡Œæ—¶è°ƒç”¨"""
        pass
    
    @abstractmethod
    async def on_step_end(self, step_info: StepExecutionInfo, chain_info: ChainExecutionInfo) -> None:
        """æ­¥éª¤æ‰§è¡Œç»“æŸæ—¶è°ƒç”¨"""
        pass
    
    @abstractmethod
    async def on_error(self, error: Exception, chain_info: ChainExecutionInfo) -> None:
        """å‘ç”Ÿé”™è¯¯æ—¶è°ƒç”¨"""
        pass
    
    @abstractmethod
    async def on_timeout(self, timeout_type: str, chain_info: ChainExecutionInfo) -> None:
        """è¶…æ—¶æ—¶è°ƒç”¨"""
        pass


class DefaultChainMonitor(ChainMonitor):
    """é»˜è®¤é“¾æ¡ç›‘æ§å™¨å®ç°"""
    
    def __init__(self, config: ExecutionConfig):
        self.config = config
        self.log_levels = {"DEBUG": 0, "INFO": 1, "WARNING": 2, "ERROR": 3}
        self.current_level = self.log_levels.get(config.log_level, 1)
    
    def _should_log(self, level: str) -> bool:
        return self.log_levels.get(level, 1) >= self.current_level
    
    def _log(self, level: str, message: str) -> None:
        if self._should_log(level):
            timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
            print(f"[{timestamp}] [{level}] {message}")
    
    async def on_chain_start(self, chain_info: ChainExecutionInfo) -> None:
        if self.config.enable_monitoring:
            self._log("INFO", f"é“¾æ¡ {chain_info.chain_id} å¼€å§‹æ‰§è¡Œ")
    
    async def on_chain_end(self, chain_info: ChainExecutionInfo) -> None:
        if self.config.enable_monitoring:
            status_msg = f"é“¾æ¡ {chain_info.chain_id} æ‰§è¡Œç»“æŸ - çŠ¶æ€: {chain_info.status.value}"
            if chain_info.total_execution_time:
                status_msg += f", æ€»è€—æ—¶: {chain_info.total_execution_time:.2f}ç§’"
            status_msg += f", å®Œæˆæ­¥éª¤: {chain_info.completed_steps}/{chain_info.total_steps}"
            self._log("INFO", status_msg)
    
    async def on_step_start(self, step_info: StepExecutionInfo, chain_info: ChainExecutionInfo) -> None:
        if self.config.enable_monitoring:
            progress = f"({chain_info.completed_steps + 1}/{chain_info.total_steps})"
            self._log("DEBUG", f"æ­¥éª¤ {step_info.step_name} å¼€å§‹æ‰§è¡Œ {progress}")
            
            if self.config.enable_progress:
                progress_percent = ((chain_info.completed_steps + 1) / chain_info.total_steps) * 100
                print(f"æ‰§è¡Œè¿›åº¦: {progress_percent:.1f}% - {step_info.step_name}")
    
    async def on_step_end(self, step_info: StepExecutionInfo, chain_info: ChainExecutionInfo) -> None:
        if self.config.enable_monitoring:
            status_msg = f"æ­¥éª¤ {step_info.step_name} æ‰§è¡Œå®Œæˆ - çŠ¶æ€: {step_info.status.value}"
            if step_info.execution_time:
                status_msg += f", è€—æ—¶: {step_info.execution_time:.2f}ç§’"
            if step_info.retry_count > 0:
                status_msg += f", é‡è¯•æ¬¡æ•°: {step_info.retry_count}"
            self._log("DEBUG", status_msg)
    
    async def on_error(self, error: Exception, chain_info: ChainExecutionInfo) -> None:
        if self.config.enable_monitoring:
            self._log("ERROR", f"é“¾æ¡ {chain_info.chain_id} å‘ç”Ÿé”™è¯¯: {str(error)}")
    
    async def on_timeout(self, timeout_type: str, chain_info: ChainExecutionInfo) -> None:
        if self.config.enable_monitoring:
            self._log("WARNING", f"é“¾æ¡ {chain_info.chain_id} {timeout_type}è¶…æ—¶")


class ExecutionController:
    """æ‰§è¡Œæ§åˆ¶å™¨"""
    
    def __init__(self, config: ExecutionConfig):
        self.config = config
        self._cancelled = False
    
    def cancel(self) -> None:
        """å–æ¶ˆæ‰§è¡Œ"""
        self._cancelled = True
    
    def is_cancelled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ"""
        return self._cancelled
    
    async def check_timeout(self, start_time: float, timeout: Optional[float]) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¶…æ—¶"""
        if timeout is None:
            return False
        return (time.time() - start_time) > timeout


@dataclass
class StepResult:
    """
    å•ä¸ªæ­¥éª¤çš„æ‰§è¡Œç»“æœã€‚
    
    Attributes:
        step_name: æ­¥éª¤åç§°
        messages: å‘é€ç»™LLMçš„æ¶ˆæ¯åˆ—è¡¨
        response: LLMçš„å“åº”å†…å®¹
        model_params: ä½¿ç”¨çš„æ¨¡å‹å‚æ•°
        execution_time: æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
        status: æ‰§è¡ŒçŠ¶æ€
        retry_count: é‡è¯•æ¬¡æ•°
        error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    """
    step_name: str
    messages: List[Dict[str, Any]]
    response: str
    model_params: Dict[str, Any] = field(default_factory=dict)
    execution_time: Optional[float] = None
    status: StepStatus = StepStatus.COMPLETED
    retry_count: int = 0
    error: Optional[str] = None


@dataclass
class Context:
    """
    é“¾æ¡æ‰§è¡Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
    
    Attributes:
        query: åˆå§‹ç”¨æˆ·æŸ¥è¯¢ï¼ˆå¯é€‰ï¼Œç”¨äºé€šç”¨åœºæ™¯ï¼‰
        history: æ‰€æœ‰æ­¥éª¤çš„æ‰§è¡Œå†å²
        custom_data: è‡ªå®šä¹‰æ•°æ®å­—å…¸ï¼Œç”¨äºå­˜å‚¨ä»»æ„é¢å¤–ä¿¡æ¯
        execution_info: é“¾æ¡æ‰§è¡Œä¿¡æ¯ï¼ˆç”¨äºç›‘æ§ï¼‰
    """
    history: List[StepResult] = field(default_factory=list)
    query: Optional[str] = None
    custom_data: Dict[str, Any] = field(default_factory=dict)
    execution_info: Optional[ChainExecutionInfo] = None
    
    def get_last_response(self) -> Optional[str]:
        """è·å–æœ€åä¸€ä¸ªæ­¥éª¤çš„å“åº”ã€‚"""
        return self.history[-1].response if self.history else None
    
    def get_response_by_step(self, step_name: str) -> Optional[str]:
        """æ ¹æ®æ­¥éª¤åç§°è·å–å“åº”ã€‚"""
        for step_result in self.history:
            if step_result.step_name == step_name:
                return step_result.response
        return None
    
    def get_step_count(self) -> int:
        """è·å–å·²æ‰§è¡Œçš„æ­¥éª¤æ•°é‡ã€‚"""
        return len(self.history)
    
    def add_custom_data(self, key: str, value: Any) -> None:
        """æ·»åŠ è‡ªå®šä¹‰æ•°æ®ã€‚"""
        self.custom_data[key] = value
    
    def get_custom_data(self, key: str, default: Any = None) -> Any:
        """è·å–è‡ªå®šä¹‰æ•°æ®ã€‚"""
        return self.custom_data.get(key, default)
    
    def get_execution_summary(self) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œæ‘˜è¦ä¿¡æ¯"""
        total_time = sum(s.execution_time or 0 for s in self.history)
        total_retries = sum(s.retry_count for s in self.history)
        failed_steps = [s.step_name for s in self.history if s.status == StepStatus.FAILED]
        
        return {
            "total_steps": len(self.history),
            "total_execution_time": total_time,
            "total_retries": total_retries,
            "failed_steps": failed_steps,
            "success_rate": len([s for s in self.history if s.status == StepStatus.COMPLETED]) / len(self.history) if self.history else 0
        }


@dataclass
class Step:
    """
    å®šä¹‰æ€æƒ³é“¾ä¸­çš„ä¸€ä¸ªæ­¥éª¤ã€‚

    Attributes:
        name: æ­¥éª¤çš„å”¯ä¸€åç§°ã€‚
        prepare_messages_fn: ä¸€ä¸ªå¯è°ƒç”¨å¯¹è±¡ï¼Œæ¥æ”¶ä¸Šä¸‹æ–‡ï¼ˆContextï¼‰ï¼Œè¿”å›ç”¨äºLLMè°ƒç”¨çš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆList[Dict]ï¼‰ã€‚
        get_next_step_fn: ä¸€ä¸ªå¯è°ƒç”¨å¯¹è±¡ï¼Œæ¥æ”¶å½“å‰æ­¥éª¤çš„å“åº”ï¼ˆstrï¼‰å’Œå®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆContextï¼‰ï¼Œè¿”å›ä¸‹ä¸€ä¸ªæ­¥éª¤çš„åç§°ï¼ˆstrï¼‰æˆ–Noneè¡¨ç¤ºç»“æŸã€‚
        model_params: è°ƒç”¨LLMæ—¶ä½¿ç”¨çš„æ¨¡å‹å‚æ•°ï¼Œä¾‹å¦‚ model, temperatureç­‰ã€‚
    """
    name: str
    prepare_messages_fn: Callable[[Context], List[Dict[str, Any]]]
    get_next_step_fn: Callable[[str, Context], Optional[str]]
    model_params: Dict[str, Any] = field(default_factory=dict)


@dataclass
class LinearStep:
    """
    å®šä¹‰çº¿æ€§é“¾æ¡ä¸­çš„ä¸€ä¸ªæ­¥éª¤ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰ã€‚
    
    Attributes:
        name: æ­¥éª¤çš„å”¯ä¸€åç§°ã€‚
        prepare_messages_fn: ä¸€ä¸ªå¯è°ƒç”¨å¯¹è±¡ï¼Œæ¥æ”¶ä¸Šä¸‹æ–‡ï¼ˆContextï¼‰ï¼Œè¿”å›ç”¨äºLLMè°ƒç”¨çš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆList[Dict]ï¼‰ã€‚
        model_params: è°ƒç”¨LLMæ—¶ä½¿ç”¨çš„æ¨¡å‹å‚æ•°ï¼Œä¾‹å¦‚ model, temperatureç­‰ã€‚
    """
    name: str
    prepare_messages_fn: Callable[[Context], List[Dict[str, Any]]]
    model_params: Dict[str, Any] = field(default_factory=dict)


class ChainOfThoughtClient:
    """
    ä¸€ä¸ªå®¢æˆ·ç«¯ï¼Œç”¨äºæ‰§è¡Œç”±å¤šä¸ªæ­¥éª¤ç»„æˆçš„æ€æƒ³é“¾ï¼ˆChain of Thoughtï¼‰ã€‚
    å®ƒå…è®¸æ ¹æ®ä¸€ä¸ªæ¨¡å‹è°ƒç”¨çš„ç»“æœåŠ¨æ€å†³å®šä¸‹ä¸€ä¸ªè°ƒç”¨çš„æ¨¡å‹å’Œå†…å®¹ã€‚
    """

    def __init__(self, openai_client: OpenAIClient, execution_config: Optional[ExecutionConfig] = None):
        """
        åˆå§‹åŒ–æ€æƒ³é“¾å®¢æˆ·ç«¯ã€‚

        Args:
            openai_client: ä¸€ä¸ª OpenAIClient å®ä¾‹ï¼Œç”¨äºæ‰§è¡Œåº•å±‚çš„LLMè°ƒç”¨ã€‚
            execution_config: æ‰§è¡Œé…ç½®ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®ã€‚
        """
        self.openai_client = openai_client
        self.steps: Dict[str, Step] = {}
        self.execution_config = execution_config or ExecutionConfig()
        self.monitor: ChainMonitor = DefaultChainMonitor(self.execution_config)
        self._chain_counter = 0

    def set_monitor(self, monitor: ChainMonitor) -> None:
        """è®¾ç½®è‡ªå®šä¹‰ç›‘æ§å™¨"""
        self.monitor = monitor

    def add_step(self, step: Step):
        """
        å‘å®¢æˆ·ç«¯æ³¨å†Œä¸€ä¸ªæ­¥éª¤ã€‚

        Args:
            step: ä¸€ä¸ª Step å®ä¾‹ã€‚
        """
        if step.name in self.steps:
            raise ValueError(f"æ­¥éª¤ '{step.name}' å·²å­˜åœ¨ã€‚è¯·ç¡®ä¿æ¯ä¸ªæ­¥éª¤åç§°å”¯ä¸€ã€‚")
        self.steps[step.name] = step

    def add_steps(self, steps: List[Step]):
        """
        å‘å®¢æˆ·ç«¯æ‰¹é‡æ³¨å†Œå¤šä¸ªæ­¥éª¤ã€‚

        Args:
            steps: Step å®ä¾‹çš„åˆ—è¡¨ã€‚
        """
        for step in steps:
            self.add_step(step)

    def create_linear_chain(self, linear_steps: List[LinearStep], chain_name: str = "linear_chain"):
        """
        åˆ›å»ºä¸€ä¸ªçº¿æ€§çš„æ­¥éª¤é“¾æ¡ï¼Œæ¯ä¸ªæ­¥éª¤æŒ‰é¡ºåºæ‰§è¡Œã€‚
        
        Args:
            linear_steps: LinearStep å®ä¾‹çš„åˆ—è¡¨ï¼ŒæŒ‰æ‰§è¡Œé¡ºåºæ’åˆ—ã€‚
            chain_name: é“¾æ¡çš„åç§°å‰ç¼€ã€‚
        """
        if not linear_steps:
            raise ValueError("çº¿æ€§é“¾æ¡è‡³å°‘éœ€è¦ä¸€ä¸ªæ­¥éª¤ã€‚")
        
        def create_next_step_fn(current_index: int, total_steps: int):
            """ä¸ºçº¿æ€§é“¾æ¡åˆ›å»ºnext_stepå‡½æ•°"""
            def next_step_fn(response: str, context: Context) -> Optional[str]:
                if current_index < total_steps - 1:
                    return f"{chain_name}_{current_index + 1}"
                else:
                    return None  # ç»“æŸé“¾æ¡
            return next_step_fn
        
        # è½¬æ¢LinearStepä¸ºStepå¹¶æ³¨å†Œ
        for i, linear_step in enumerate(linear_steps):
            step_name = f"{chain_name}_{i}"
            full_step = Step(
                name=step_name,
                prepare_messages_fn=linear_step.prepare_messages_fn,
                get_next_step_fn=create_next_step_fn(i, len(linear_steps)),
                model_params=linear_step.model_params
            )
            self.add_step(full_step)
        
        return f"{chain_name}_0"  # è¿”å›ç¬¬ä¸€ä¸ªæ­¥éª¤çš„åç§°

    def create_context(self, initial_data: Optional[Dict[str, Any]] = None) -> Context:
        """
        åˆ›å»ºä¸€ä¸ªæ–°çš„ä¸Šä¸‹æ–‡å¯¹è±¡ã€‚
        
        Args:
            initial_data: åˆå§‹æ•°æ®å­—å…¸ï¼Œå¯ä»¥åŒ…å« 'query' å’Œå…¶ä»–è‡ªå®šä¹‰å­—æ®µ
            
        Returns:
            æ–°åˆ›å»ºçš„Contextå¯¹è±¡
        """
        if initial_data is None:
            return Context()
        
        # æå–ç‰¹æ®Šå­—æ®µ
        query = initial_data.get('query')
        
        # å‰©ä½™å­—æ®µä½œä¸ºcustom_data
        custom_data = {k: v for k, v in initial_data.items() if k != 'query'}
        
        return Context(
            query=query,
            custom_data=custom_data
        )

    def _generate_chain_id(self) -> str:
        """ç”Ÿæˆé“¾æ¡ID"""
        self._chain_counter += 1
        return f"chain_{self._chain_counter}_{int(time.time())}"

    async def _execute_step_with_retry(
        self,
        step: Step,
        context: Context,
        controller: ExecutionController,
        step_info: StepExecutionInfo,
        chain_info: ChainExecutionInfo,
        show_step_details: bool = False
    ) -> Optional[str]:
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤ï¼ŒåŒ…å«é‡è¯•é€»è¾‘"""
        last_error = None
        
        for attempt in range(self.execution_config.max_retries + 1):
            if controller.is_cancelled():
                step_info.status = StepStatus.CANCELLED
                return None
            
            step_info.retry_count = attempt
            
            try:
                # å‡†å¤‡æ¶ˆæ¯
                messages = step.prepare_messages_fn(context)
                
                # æ˜¾ç¤ºæ­¥éª¤è¯¦ç»†ä¿¡æ¯ - è¾“å…¥
                if show_step_details:
                    print(f"\nğŸ“ æ­¥éª¤ '{step_info.step_name}' è¾“å…¥æ¶ˆæ¯:")
                    for i, msg in enumerate(messages):
                        role = msg.get('role', 'unknown')
                        content = msg.get('content', '')
                        print(f"   {i+1}. [{role}]: {content[:100]}{'...' if len(content) > 100 else ''}")
                    print(f"ğŸ”§ æ¨¡å‹å‚æ•°: {step.model_params}")
                    if attempt > 0:
                        print(f"ğŸ”„ é‡è¯•ç¬¬ {attempt} æ¬¡")
                
                # æ‰§è¡ŒLLMè°ƒç”¨
                start_time = time.time()
                
                # åˆ›å»ºè¶…æ—¶ä»»åŠ¡
                llm_task = self.openai_client.chat_completions(
                    messages=messages,
                    preprocess_msg=True,
                    show_progress=False,  # LLMè°ƒç”¨çš„è¿›åº¦æ¡å§‹ç»ˆå…³é—­
                    **step.model_params
                )
                
                if self.execution_config.step_timeout:
                    response_content = await asyncio.wait_for(
                        llm_task, 
                        timeout=self.execution_config.step_timeout
                    )
                else:
                    response_content = await llm_task
                
                execution_time = time.time() - start_time
                step_info.execution_time = execution_time
                
                if response_content is None or not isinstance(response_content, str):
                    raise ValueError("LLMè°ƒç”¨è¿”å›ç©ºå“åº”")
                
                # æ˜¾ç¤ºæ­¥éª¤è¯¦ç»†ä¿¡æ¯ - è¾“å‡º
                if show_step_details:
                    print(f"âœ… æ­¥éª¤ '{step_info.step_name}' è¾“å‡ºå“åº”:")
                    print(f"   ğŸ“„ å“åº”å†…å®¹: {response_content[:200]}{'...' if len(response_content) > 200 else ''}")
                    print(f"   â±ï¸  æ‰§è¡Œæ—¶é—´: {execution_time:.3f}ç§’")
                    if attempt > 0:
                        print(f"   ğŸ”„ é‡è¯•æˆåŠŸ")
                
                step_info.status = StepStatus.COMPLETED
                return response_content
                
            except asyncio.TimeoutError:
                step_info.status = StepStatus.TIMEOUT
                step_info.error = f"æ­¥éª¤æ‰§è¡Œè¶…æ—¶ï¼ˆ{self.execution_config.step_timeout}ç§’ï¼‰"
                if show_step_details:
                    print(f"â° æ­¥éª¤ '{step_info.step_name}' æ‰§è¡Œè¶…æ—¶")
                    print(f"   âš ï¸  è¶…æ—¶æ—¶é—´: {self.execution_config.step_timeout}ç§’")
                await self.monitor.on_timeout("step", chain_info)
                last_error = TimeoutError(step_info.error)
                
            except Exception as e:
                step_info.status = StepStatus.FAILED
                step_info.error = str(e)
                if show_step_details:
                    print(f"âŒ æ­¥éª¤ '{step_info.step_name}' æ‰§è¡Œå¤±è´¥")
                    print(f"   ğŸ› é”™è¯¯ç±»å‹: {type(e).__name__}")
                    print(f"   ğŸ“ é”™è¯¯ä¿¡æ¯: {str(e)}")
                    if attempt < self.execution_config.max_retries:
                        print(f"   ğŸ”„ å°†åœ¨ {self.execution_config.retry_delay}ç§’åé‡è¯•...")
                last_error = e
                await self.monitor.on_error(e, chain_info)
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…é‡è¯•é—´éš”
            if attempt < self.execution_config.max_retries:
                await asyncio.sleep(self.execution_config.retry_delay)
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
        if last_error:
            raise last_error
        
        return None

    async def execute_chain(
        self,
        initial_step_name: str,
        initial_context: Optional[Union[Dict[str, Any], Context]] = None,
        show_step_details: bool = False
    ) -> Context:
        """
        å¼‚æ­¥æ‰§è¡Œä¸€ä¸ªå®Œæ•´çš„æ€æƒ³é“¾ã€‚

        Args:
            initial_step_name: èµ·å§‹æ­¥éª¤çš„åç§°ã€‚
            initial_context: ä¼ é€’ç»™ç¬¬ä¸€ä¸ªæ­¥éª¤çš„åˆå§‹ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥æ˜¯å­—å…¸æˆ–Contextå¯¹è±¡ã€‚
            show_step_details: æ˜¯å¦æ˜¾ç¤ºæ¯ä¸ªæ­¥éª¤çš„è¯¦ç»†ä¿¡æ¯ï¼ˆè¾“å…¥æ¶ˆæ¯ã€è¾“å‡ºå“åº”ã€æ‰§è¡Œæ—¶é—´ç­‰ï¼‰ã€‚

        Returns:
            è¿”å›åŒ…å«æ‰€æœ‰æ­¥éª¤å†å²è®°å½•çš„æœ€ç»ˆä¸Šä¸‹æ–‡ã€‚
        """
        if initial_step_name not in self.steps:
            raise ValueError(f"èµ·å§‹æ­¥éª¤ '{initial_step_name}' æœªæ³¨å†Œã€‚")

        # å¤„ç†åˆå§‹ä¸Šä¸‹æ–‡
        if isinstance(initial_context, Context):
            context = initial_context
        elif isinstance(initial_context, dict):
            context = self.create_context(initial_context)
        else:
            context = Context()
        
        # åˆ›å»ºæ‰§è¡Œä¿¡æ¯å’Œæ§åˆ¶å™¨
        chain_id = self._generate_chain_id()
        chain_info = ChainExecutionInfo(
            chain_id=chain_id,
            status=ChainStatus.RUNNING,
            start_time=time.time()
        )
        context.execution_info = chain_info
        
        controller = ExecutionController(self.execution_config)
        
        # ä¼°ç®—æ€»æ­¥éª¤æ•°ï¼ˆç®€å•é¢„ä¼°ï¼‰
        chain_info.total_steps = len(self.steps)  # è¿™æ˜¯ä¸€ä¸ªä¿å®ˆä¼°è®¡
        
        try:
            await self.monitor.on_chain_start(chain_info)
            
            current_step_name: Optional[str] = initial_step_name
            chain_start_time = time.time()

            while current_step_name:
                # æ£€æŸ¥é“¾æ¡è¶…æ—¶
                if self.execution_config.chain_timeout:
                    if await controller.check_timeout(chain_start_time, self.execution_config.chain_timeout):
                        chain_info.status = ChainStatus.TIMEOUT
                        await self.monitor.on_timeout("chain", chain_info)
                        break
                
                # æ£€æŸ¥å–æ¶ˆçŠ¶æ€
                if controller.is_cancelled():
                    chain_info.status = ChainStatus.CANCELLED
                    break
                
                if current_step_name not in self.steps:
                    raise ValueError(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç°æœªæ³¨å†Œçš„æ­¥éª¤ '{current_step_name}'ã€‚")

                step = self.steps[current_step_name]
                
                # åˆ›å»ºæ­¥éª¤æ‰§è¡Œä¿¡æ¯
                step_info = StepExecutionInfo(
                    step_name=current_step_name,
                    status=StepStatus.RUNNING,
                    start_time=time.time()
                )
                
                chain_info.steps_info.append(step_info)
                await self.monitor.on_step_start(step_info, chain_info)

                try:
                    # æ‰§è¡Œæ­¥éª¤ï¼ˆåŒ…å«é‡è¯•é€»è¾‘ï¼‰
                    response_content = await self._execute_step_with_retry(
                        step, context, controller, step_info, chain_info, show_step_details
                    )
                    
                    if response_content is None:
                        break  # æ­¥éª¤æ‰§è¡Œå¤±è´¥æˆ–è¢«å–æ¶ˆ
                    
                    step_info.end_time = time.time()
                    step_info.execution_time = step_info.end_time - (step_info.start_time or 0)
                    
                    # è®°å½•æ­¥éª¤ç»“æœ
                    step_result = StepResult(
                        step_name=current_step_name,
                        messages=step.prepare_messages_fn(context),
                        response=response_content,
                        model_params=step.model_params,
                        execution_time=step_info.execution_time,
                        status=step_info.status,
                        retry_count=step_info.retry_count,
                        error=step_info.error
                    )
                    context.history.append(step_result)
                    
                    chain_info.completed_steps += 1
                    await self.monitor.on_step_end(step_info, chain_info)

                    # å†³å®šä¸‹ä¸€æ­¥
                    next_step_name = step.get_next_step_fn(response_content, context)
                    current_step_name = next_step_name
                    
                except Exception as e:
                    step_info.status = StepStatus.FAILED
                    step_info.error = str(e)
                    step_info.end_time = time.time()
                    
                    await self.monitor.on_step_end(step_info, chain_info)
                    await self.monitor.on_error(e, chain_info)
                    
                    chain_info.status = ChainStatus.FAILED
                    chain_info.error = str(e)
                    break

            # è®¾ç½®é“¾æ¡ç»“æŸçŠ¶æ€
            chain_info.end_time = time.time()
            chain_info.total_execution_time = chain_info.end_time - chain_info.start_time
            
            if chain_info.status == ChainStatus.RUNNING:
                chain_info.status = ChainStatus.COMPLETED
            
            await self.monitor.on_chain_end(chain_info)

        except Exception as e:
            chain_info.status = ChainStatus.FAILED
            chain_info.error = str(e)
            chain_info.end_time = time.time()
            if chain_info.start_time:
                chain_info.total_execution_time = chain_info.end_time - chain_info.start_time
            
            await self.monitor.on_error(e, chain_info)
            await self.monitor.on_chain_end(chain_info)
            raise

        return context

    async def execute_chains_batch(
        self,
        chain_requests: List[Dict[str, Any]],
        show_step_details: bool = False
    ) -> List[Context]:
        """
        å¹¶å‘æ‰§è¡Œå¤šä¸ªæ€æƒ³é“¾ã€‚

        Args:
            chain_requests: ä¸€ä¸ªè¯·æ±‚åˆ—è¡¨ï¼Œæ¯ä¸ªè¯·æ±‚æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å« 'initial_step_name' å’Œ 'initial_context'ã€‚
                ä¾‹å¦‚: [{'initial_step_name': 'step1', 'initial_context': {'query': 'ä½ å¥½'}}]
            show_step_details: æ˜¯å¦æ˜¾ç¤ºæ¯ä¸ªæ­¥éª¤çš„è¯¦ç»†ä¿¡æ¯ï¼ˆè¾“å…¥æ¶ˆæ¯ã€è¾“å‡ºå“åº”ã€æ‰§è¡Œæ—¶é—´ç­‰ï¼‰ã€‚

        Returns:
            ä¸€ä¸ªç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯å¯¹åº”è°ƒç”¨é“¾çš„æœ€ç»ˆä¸Šä¸‹æ–‡ã€‚
        """
        tasks = []
        for request in chain_requests:
            task = self.execute_chain(
                initial_step_name=request['initial_step_name'],
                initial_context=request.get('initial_context'),
                show_step_details=show_step_details
            )
            tasks.append(task)

        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        final_results = []
        for result in results:
            if isinstance(result, Exception):
                # åˆ›å»ºä¸€ä¸ªé”™è¯¯ä¸Šä¸‹æ–‡
                error_context = Context()
                error_context.execution_info = ChainExecutionInfo(
                    chain_id=self._generate_chain_id(),
                    status=ChainStatus.FAILED,
                    error=str(result)
                )
                final_results.append(error_context)
            else:
                final_results.append(result)
        
        return final_results 