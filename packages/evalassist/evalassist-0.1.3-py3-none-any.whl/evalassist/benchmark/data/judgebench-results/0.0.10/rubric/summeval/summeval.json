{
    "name": "summeval",
    "description": "This benchmark provides a dataset featuring summaries generated by various recent summarization models trained on a news-based dataset. It includes expert and crowd-sourced annotations evaluating the summaries.",
    "link": "https://github.com/Yale-LILY/SummEval",
    "type": "rubric",
    "dataset": {
        "name": "judgebench-summeval",
        "description": ""
    },
    "tags": [
        "Judgebench",
        "graded"
    ],
    "criteriaBenchmarks": [
        {
            "name": "coherence",
            "evaluatorBenchmarks": [
                {
                    "evaluator_id": "Llama3-70b",
                    "laaj_version": "0.0.10",
                    "results": {
                        "agreement": 0.12,
                        "p_bias": 0.86,
                        "pearson": 0.047
                    }
                },
                {
                    "evaluator_id": "Mixtral",
                    "laaj_version": "0.0.10",
                    "results": {
                        "agreement": 0.09,
                        "p_bias": 0.76,
                        "pearson": 0.086
                    }
                },
                {
                    "evaluator_id": "Llama3-8b",
                    "laaj_version": "0.0.10",
                    "results": {
                        "agreement": 0.1,
                        "p_bias": 0.81,
                        "pearson": 0.129
                    }
                },
                {
                    "evaluator_id": "GPT-4o",
                    "laaj_version": "0.0.10",
                    "results": {
                        "agreement": 0.13,
                        "p_bias": 0.33,
                        "pearson": 0.096
                    }
                }
            ]
        },
        {
            "name": "consistency",
            "evaluatorBenchmarks": [
                {
                    "evaluator_id": "Llama3-70b",
                    "laaj_version": "0.0.10",
                    "results": {
                        "agreement": 0.12,
                        "p_bias": 0.84,
                        "pearson": 0.14
                    }
                },
                {
                    "evaluator_id": "Mixtral",
                    "laaj_version": "0.0.10",
                    "results": {
                        "agreement": 0.21,
                        "p_bias": 0.87,
                        "pearson": 0.062
                    }
                },
                {
                    "evaluator_id": "Llama3-8b",
                    "laaj_version": "0.0.10",
                    "results": {
                        "agreement": 0.26,
                        "p_bias": 0.86,
                        "pearson": -0.008
                    }
                },
                {
                    "evaluator_id": "GPT-4o",
                    "laaj_version": "0.0.10",
                    "results": {
                        "agreement": 0.33,
                        "p_bias": 0.68,
                        "pearson": 0.166
                    }
                }
            ]
        },
        {
            "name": "fluency",
            "evaluatorBenchmarks": [
                {
                    "evaluator_id": "Llama3-70b",
                    "laaj_version": "0.0.10",
                    "results": {
                        "agreement": 0,
                        "p_bias": 0.62,
                        "pearson": 0.066
                    }
                },
                {
                    "evaluator_id": "Mixtral",
                    "laaj_version": "0.0.10",
                    "results": {
                        "agreement": 0.04,
                        "p_bias": 0.61,
                        "pearson": -0.015
                    }
                },
                {
                    "evaluator_id": "Llama3-8b",
                    "laaj_version": "0.0.10",
                    "results": {
                        "agreement": 0.03,
                        "p_bias": 0.65,
                        "pearson": 0.053
                    }
                },
                {
                    "evaluator_id": "GPT-4o",
                    "laaj_version": "0.0.10",
                    "results": {
                        "agreement": 0,
                        "p_bias": 0.62,
                        "pearson": 0.271
                    }
                }
            ]
        },
        {
            "name": "relevance",
            "evaluatorBenchmarks": [
                {
                    "evaluator_id": "Llama3-70b",
                    "laaj_version": "0.0.10",
                    "results": {
                        "agreement": 0.08,
                        "p_bias": 0.81,
                        "pearson": -0.283
                    }
                },
                {
                    "evaluator_id": "Mixtral",
                    "laaj_version": "0.0.10",
                    "results": {
                        "agreement": 0.12,
                        "p_bias": 0.83,
                        "pearson": -0.37
                    }
                },
                {
                    "evaluator_id": "Llama3-8b",
                    "laaj_version": "0.0.10",
                    "results": {
                        "agreement": 0.12,
                        "p_bias": 0.83,
                        "pearson": -0.124
                    }
                },
                {
                    "evaluator_id": "GPT-4o",
                    "laaj_version": "0.0.10",
                    "results": {
                        "agreement": 0.13,
                        "p_bias": 0.53,
                        "pearson": 0.305
                    }
                }
            ]
        }
    ]
}
