{
    "name": "roscoe-cosmos-overall",
    "description": "This benchmark involves human-judged datasets that evaluate the quality of step-by-step reasoning in generated outputs. Human annotations were collected from a subset of several datasets to assess the reasoning quality in the responses generated by a language model. The benchmark includes two data splits for each dataset: one evaluates the overall quality of the generated responses, while the other assesses the quality of individual reasoning steps.",
    "link": "https://dl.fbaipublicfiles.com/parlai/projects/roscoe/annotations.zip",
    "type": "rubric",
    "dataset": {
        "name": "roscoe-cosmos-overall",
        "description": ""
    },
    "tags": [
        "Judgebench"
    ],
    "criteriaBenchmarks": [
        {
            "name": "Overall Quality",
            "evaluatorBenchmarks": [
                {
                    "evaluator_id": "Mixtral",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.292,
                        "p_bias": 0.518,
                        "pearson": 0.697
                    }
                },
                {
                    "evaluator_id": "Llama3-8b",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.267,
                        "p_bias": 0.385,
                        "pearson": 0.407
                    }
                },
                {
                    "evaluator_id": "Llama3-70b",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.385,
                        "p_bias": 0.277,
                        "pearson": 0.681
                    }
                },
                {
                    "evaluator_id": "Prometheus",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.277,
                        "p_bias": 0.426,
                        "pearson": 0.577
                    }
                },
                {
                    "evaluator_id": "GPT-4o",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.267,
                        "p_bias": 0.538,
                        "pearson": 0.328
                    }
                }
            ]
        },
        {
            "name": "Coherency",
            "evaluatorBenchmarks": [
                {
                    "evaluator_id": "Mixtral",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.251,
                        "p_bias": 0.523,
                        "pearson": 0.527
                    }
                },
                {
                    "evaluator_id": "Llama3-70b",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.436,
                        "p_bias": 0.303,
                        "pearson": 0.43
                    }
                },
                {
                    "evaluator_id": "Prometheus",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.21,
                        "p_bias": 0.292,
                        "pearson": 0.466
                    }
                },
                {
                    "evaluator_id": "GPT-4o",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.282,
                        "p_bias": 0.595,
                        "pearson": 0.225
                    }
                },
                {
                    "evaluator_id": "Llama3-8b",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.108,
                        "p_bias": 0.41,
                        "pearson": 0.379
                    }
                }
            ]
        },
        {
            "name": "Missing Steps",
            "evaluatorBenchmarks": [
                {
                    "evaluator_id": "Mixtral",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.554,
                        "p_bias": 0.005,
                        "pearson": null
                    }
                },
                {
                    "evaluator_id": "Llama3-70b",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.559,
                        "p_bias": 0.026,
                        "pearson": 0.05
                    }
                },
                {
                    "evaluator_id": "Prometheus",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.554,
                        "p_bias": 0.026,
                        "pearson": 0.011
                    }
                },
                {
                    "evaluator_id": "GPT-4o",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.544,
                        "p_bias": 0.344,
                        "pearson": 0.02
                    }
                },
                {
                    "evaluator_id": "Llama3-8b",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.554,
                        "p_bias": 0.005,
                        "pearson": null
                    }
                }
            ]
        },
        {
            "name": "Contradiction",
            "evaluatorBenchmarks": [
                {
                    "evaluator_id": "Mixtral",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.733,
                        "p_bias": 0.585,
                        "pearson": 0.289
                    }
                },
                {
                    "evaluator_id": "Llama3-70b",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.615,
                        "p_bias": 0.472,
                        "pearson": 0.18
                    }
                },
                {
                    "evaluator_id": "Prometheus",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.395,
                        "p_bias": 0.262,
                        "pearson": 0.068
                    }
                },
                {
                    "evaluator_id": "GPT-4o",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.431,
                        "p_bias": 0.415,
                        "pearson": 0.106
                    }
                },
                {
                    "evaluator_id": "Llama3-8b",
                    "laaj_version": "0.0.14",
                    "results": {
                        "agreement": 0.692,
                        "p_bias": 0.164,
                        "pearson": 0.232
                    }
                }
            ]
        }
    ]
}
