Metadata-Version: 2.4
Name: ollama-code
Version: 0.4.9
Summary: Ein autonomer KI-Entwicklungsassistent mit lokalem Ollama-Backend.
Author-email: Dein Name <deine@email.com>
License-Expression: MIT
Project-URL: Homepage, https://github.com/dein-username/openai-coder
Project-URL: Bug Tracker, https://github.com/dein-username/openai-coder/issues
Classifier: Programming Language :: Python :: 3
Classifier: Operating System :: OS Independent
Classifier: Development Status :: 4 - Beta
Classifier: Environment :: Web Environment
Classifier: Intended Audience :: Developers
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Requires-Dist: eel>=0.14.0
Requires-Dist: requests>=2.28.0

# üî• Atlas Code

**Autonomer KI-Entwicklungsassistent mit lokalem Ollama-Backend**

Atlas ist ein intelligenter, autonomer KI-Agent, der Aufgaben vollst√§ndig und selbstst√§ndig ausf√ºhrt - genau wie Claude Code, aber mit lokalen Ollama-Modellen.

---

## ‚ú® **Was ist Atlas?**

Atlas Code ist ein minimalistisches Terminal-Interface mit einem hochintelligenten KI-Agenten, der:

- **ü§ñ Autonom arbeitet** - F√ºhrt Aufgaben vollst√§ndig aus ohne weitere Nachfragen
- **üñãÔ∏è Live-Typewriter** - Elegante Echtzeit-Textausgabe mit Cursor-Animation
- **üöÄ Performance-optimiert** - Conversation-Caching f√ºr l√§ngere Gespr√§che
- **üîí Sicher** - Sandbox-Modus standardm√§√üig aktiv
- **‚ö° Ollama-nativ** - Funktioniert ausschlie√ülich mit lokalen Modellen

---

## üéØ **Hauptfeatures**

### **Autonome Ausf√ºhrung**
```
Du: "Erstelle eine Python-Funktion f√ºr Fibonacci-Zahlen"
Atlas: Analysiert ‚Üí Schreibt Code ‚Üí Testet ‚Üí Optimiert ‚Üí Fertig!
```

### **Live-Typewriter-Effekt**
- Immer aktiv, kein Umschalten n√∂tig
- Oranges Gl√ºhen (Atlas-Farbe: #E67E22)
- Blinkender Cursor ‚ñå w√§hrend der Eingabe

### **Smart Performance**
- **Conversation-Caching**: Optimierte Kontextverwaltung
- **Token-Limiting**: Automatisches K√ºrzen langer Gespr√§che
- **Live-Metriken**: Tokens/Sekunde, Gesamt-Tokens, Timer

### **Terminal-√Ñsthetik**
- Glassmorphism-Design aus dem AgentSuite-Projekt
- Kompakte, minimalistische UI
- Responsive f√ºr alle Bildschirmgr√∂√üen

---

## üöÄ **Quick Start**

### **Voraussetzungen**
```bash
# 1. Ollama installieren
# https://ollama.ai

# 2. Modell herunterladen
ollama pull deepseek-coder-v2:16b

# 3. Ollama starten
ollama serve
```

### **Installation**
```bash
# Dependencies installieren
pip install -r requirements.txt

# Atlas starten
python main.py
```

**Atlas √∂ffnet sich automatisch unter:** `http://localhost:8080`

---

## üí¨ **Verwendung**

### **Einfach schreiben und Enter dr√ºcken**
```
Nachricht an Atlas eingeben...
```

**Keine Kommandos, keine Modi - einfach nat√ºrlich schreiben!**

### **Beispiel-Gespr√§che**
```
Du: Wie hei√üt du?
Atlas: Ich bin Atlas, dein Entwicklungsassistent.

Du: Erstelle eine REST API in Python
Atlas: [Schreibt vollst√§ndigen Flask-Code mit Endpunkten]

Du: Verbessere die Performance 
Atlas: [Analysiert Code, optimiert, testet √Ñnderungen]
```

### **Shortcuts**
- `Enter` ‚Üí Nachricht senden
- `ESC` ‚Üí Verarbeitung abbrechen
- Auto-Scroll zu neuen Nachrichten

---

## üîß **Technische Details**

### **Architektur**
```
Atlas Code
‚îú‚îÄ‚îÄ Backend (Python + Eel)
‚îÇ   ‚îú‚îÄ‚îÄ AtlasAgent - Konversations-Management  
‚îÇ   ‚îú‚îÄ‚îÄ Ollama-Integration - Streaming + Tokens
‚îÇ   ‚îî‚îÄ‚îÄ Conversation-Cache - Performance
‚îî‚îÄ‚îÄ Frontend (Vanilla JS + CSS)
    ‚îú‚îÄ‚îÄ Terminal-Interface
    ‚îú‚îÄ‚îÄ Typewriter-Effekt
    ‚îî‚îÄ‚îÄ Live-Token-Tracking
```

### **Performance-Optimierungen**
- **Conversation-Cache**: Begrenzt auf 50 Nachrichten
- **Token-Throttling**: Updates alle 100ms
- **Context-Limiting**: Nur relevante Historie (8 letzte Nachrichten)
- **Memory-Management**: Automatisches Cache-Cleanup

### **Sicherheit**
- **Sandbox-Standard**: Arbeitet in `workspace/` Verzeichnis
- **Kontrollierte Ausf√ºhrung**: Code wird nur nach Best√§tigung ausgef√ºhrt
- **Lokale Modelle**: Keine externen API-Calls

---

## ‚öôÔ∏è **Konfiguration**

### **Modell √§ndern**
```python
# In main.py
MODEL_NAME = "dein-bevorzugtes-modell"
```

### **Performance tunen**
```python
# Konversationsl√§nge anpassen
MAX_CONVERSATION_LENGTH = 50  # Standard

# Token-Update-Intervall
last_token_update = 0.1  # 100ms (Standard)
```

### **Sandbox deaktivieren**
Atlas kann auf Vollzugriff umgestellt werden, l√§uft aber standardm√§√üig sicher im Sandbox-Modus.

---

## üìä **Token-Metriken**

Die Status-Bar zeigt Live-Metriken:

```
üî• Atlas bereit | üìÅ Sandbox | Live: 42T | Total: 1337T | 15/s | 02:45
```

- **Live**: Tokens der aktuellen Antwort
- **Total**: Session-Gesamt-Tokens  
- **Speed**: Tokens pro Sekunde
- **Timer**: Session-Dauer

---

## üé® **Design-Prinzipien**

### **Atlas-Identit√§t**
- **Farbe**: Orange (#E67E22) mit Gl√ºh-Effekt
- **Name**: "Atlas" - kurz, pr√§gnant, stark
- **Verhalten**: Autonom, vollst√§ndig, hilfreich

### **Terminal-Authentizit√§t**
- Monospace-Fonts f√ºr Code
- Glassmorphism-Effekte
- Minimalistisch und fokussiert
- Keine √ºberfl√ºssigen UI-Elemente

### **Performance-First**
- Kompakte Bundle-Gr√∂√üe (kein Tailwind)
- Optimierte DOM-Struktur
- Effiziente Event-Handling

---

## üîÑ **Unterschiede zu Claude Code**

| Feature | Claude Code | Atlas Code |
|---------|-------------|------------|
| **Backend** | Anthropic API | Lokale Ollama-Modelle |
| **Modelle** | Claude-Familie | Beliebige Ollama-Modelle |
| **UI** | Sidebar + Chat | Terminal-Interface |
| **Identit√§t** | Claude | Atlas |
| **Performance** | Cloud-basiert | Lokal optimiert |
| **Autonomie** | ‚úÖ Vollst√§ndig | ‚úÖ Vollst√§ndig |

---

## üõ†Ô∏è **Erweiterte Features**

### **Conversation-Management**
```python
# Automatisches Context-Management
def build_conversation_context(self, new_message: str) -> str:
    # Intelligente Kontextverk√ºrzung
    # Performance-optimierte Historie
    # Relevanz-basierte Filterung
```

### **Smart Token-Tracking**
```python
def realistic_token_count(text):
    # GPT-√§hnliche Tokenisierung
    # Subwort-Unterst√ºtzung
    # Deutsche Sprache optimiert
```

### **Live-Updates**
```javascript
// Echtzeit Token-Updates
function token_update(data) {
    // Throttled auf 100ms
    // Smooth UI-Updates
    // Performance-Monitoring
}
```

---

## üéØ **Roadmap**

- [ ] **Multi-Model-Support**: Wechsel zwischen verschiedenen Ollama-Modellen
- [ ] **Plugin-System**: Erweiterbare Funktionalit√§ten
- [ ] **Export-Features**: Chat-Verlauf und Code-Snippets exportieren
- [ ] **Themes**: Anpassbare UI-Themes
- [ ] **Mobile-App**: Native Mobile-Version

---

## ü§ù **Entwicklung**

### **Debugging**
```bash
# Backend-Logs
python main.py

# Frontend-Entwicklung  
# Browser DevTools (F12)
```

### **Testing**
```bash
# Ollama-Verbindung testen
curl http://localhost:11434/api/tags

# Modell-Status pr√ºfen
ollama list
```

---

## üìÑ **Lizenz**

MIT-Lizenz - Siehe `LICENSE` f√ºr Details.

---

## üôè **Credits**

- **Ollama** - Lokale LLM-Infrastruktur
- **Eel** - Python-JavaScript-Bridge
- **AgentSuite** - Terminal-Design-Inspiration
- **Claude Code** - Autonomie-Konzept-Inspiration

---

**Atlas Code - Dein autonomer Entwicklungsassistent. Lokal. Intelligent. Vollst√§ndig.** üî•
