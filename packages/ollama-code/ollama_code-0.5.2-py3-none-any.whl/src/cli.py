#!/usr/bin/env python3
"""
Kommandozeilen-Interface f√ºr ollama-code
Behandelt verschiedene Umgebungsmodi und Konfigurationen.
"""

import sys
import argparse
from pathlib import Path

# F√ºge das Projekt-Hauptverzeichnis zum Python-Pfad hinzu
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from src import config
from src.main_runner import main as start_main_app

def show_host_setup_help():
    """Zeigt Hilfe f√ºr die Host-Konfiguration"""
    print("üîß Host-Konfiguration f√ºr Ollama")
    print("=" * 50)
    print()
    print("F√ºr die verschiedenen Umgebungsmodi muss Ollama entsprechend konfiguriert werden:")
    print()
    print("üìç LOKALES SYSTEM (local):")
    print("   - Ollama l√§uft direkt auf demselben System")
    print("   - Standard-Konfiguration: http://localhost:11434")
    print("   - Keine weitere Konfiguration n√∂tig")
    print()
    print("üìç VIRTUELLE MASCHINE (vm):")
    print("   - Ollama l√§uft auf dem Host-System, Code in VM")
    print("   - Linux VM: Ollama muss auf allen Interfaces lauschen")
    print("     Befehl: OLLAMA_HOST=0.0.0.0 ollama serve")
    print("   - Windows Host: Firewall-Regel f√ºr Port 11434 erstellen")
    print("   - Docker: host.docker.internal:11434 verwenden")
    print()
    print("üìç NETZWERK (net):")
    print("   - Ollama l√§uft auf einem anderen Rechner im Netzwerk")
    print("   - Server-Konfiguration: OLLAMA_HOST=0.0.0.0 ollama serve")
    print("   - Client-Konfiguration: IP-Adresse des Servers anpassen")
    print("   - Firewall: Port 11434 freigeben")
    print()
    print("üîç Weitere Informationen:")
    print("   - Ollama Dokumentation: https://ollama.ai/")
    print("   - Netzwerk-Troubleshooting: ollama-code --test-connection")

def test_connection():
    """Testet die Verbindung zu Ollama"""
    import requests
    
    print(f"üîç Teste Verbindung zu Ollama...")
    print(f"   URL: {config.OLLAMA_URL}")
    print(f"   Modus: {config.CURRENT_ENVIRONMENT}")
    print()
    
    try:
        # Test der Basis-Verbindung
        response = requests.get(f"{config.OLLAMA_URL}/api/tags", timeout=10)
        
        if response.status_code == 200:
            print("‚úÖ Ollama-Server ist erreichbar!")
            
            # √úberpr√ºfe verf√ºgbare Modelle
            data = response.json()
            models = data.get("models", [])
            
            if models:
                print(f"üìã Verf√ºgbare Modelle ({len(models)}):")
                for model in models:
                    name = model.get("name", "Unbekannt")
                    size = model.get("size", 0)
                    size_mb = round(size / (1024 * 1024), 1)
                    print(f"   - {name} ({size_mb} MB)")
                
                # √úberpr√ºfe ob das konfigurierte Modell verf√ºgbar ist
                if any(config.MODEL_NAME in m.get("name", "") for m in models):
                    print(f"‚úÖ Konfiguriertes Modell '{config.MODEL_NAME}' ist verf√ºgbar!")
                else:
                    print(f"‚ö†Ô∏è  Konfiguriertes Modell '{config.MODEL_NAME}' nicht gefunden!")
                    print(f"   Installiere es mit: ollama pull {config.MODEL_NAME}")
            else:
                print("‚ö†Ô∏è  Keine Modelle installiert!")
                print(f"   Installiere ein Modell mit: ollama pull {config.MODEL_NAME}")
                
        else:
            print(f"‚ùå Ollama-Server antwortet mit Status {response.status_code}")
            print("   M√∂gliche Ursachen:")
            print("   - Ollama ist nicht gestartet")
            print("   - Falsche URL-Konfiguration")
            print("   - Netzwerk-/Firewall-Probleme")
            
    except requests.exceptions.ConnectError:
        print("‚ùå Verbindung fehlgeschlagen - Server nicht erreichbar!")
        print()
        print("üîß L√∂sungsvorschl√§ge:")
        print(f"   1. Pr√ºfe ob Ollama l√§uft: curl {config.OLLAMA_URL}/api/tags")
        print("   2. Pr√ºfe die Umgebungskonfiguration:")
        print("      - Lokal: ollama-code local")
        print("      - VM: ollama-code vm")  
        print("      - Netzwerk: ollama-code net")
        print("   3. Host-Setup-Hilfe: ollama-code host")
        
    except requests.exceptions.Timeout:
        print("‚ùå Verbindung ist zu langsam (Timeout)!")
        print("   - Pr√ºfe die Netzwerkverbindung")
        print("   - Server k√∂nnte √ºberlastet sein")
        
    except Exception as e:
        print(f"‚ùå Unerwarteter Fehler: {e}")

def main():
    """Hauptfunktion f√ºr die Kommandozeilen-Schnittstelle"""
    parser = argparse.ArgumentParser(
        description="Ollama Code - Autonomer KI-Entwicklungsassistent mit intelligenter Umgebungserkennung",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
üöÄ UMGEBUNGSMODI:
  local   Lokales System - Ollama l√§uft direkt auf dem Host (localhost:11434)
  vm      VM/Container - Automatische Host-Erkennung f√ºr WSL/Docker/VMs
  net     Netzwerk - Ollama l√§uft auf einem anderen Rechner (anpassbar)

üîí SICHERHEITSMODI:
  safe      Safe Mode - Nur Chat, keine Systemzugriffe
  base      Base Mode - Aktueller Pfad + Unterordner, Dateien lesen/schreiben
  hell-out  Let The Hell Out - Vollzugriff auf System (GEF√ÑHRLICH!)

üìñ BEISPIELE:
  ollama-code                              Startet im Safe Mode (Standard)
  ollama-code --security base              Startet im Base Mode
  ollama-code --security hell-out          Startet mit Vollzugriff
  ollama-code --mode vm --security base    VM-Modus + Base-Sicherheit
  ollama-code --auto-accept                Aktiviert Auto-Accept f√ºr Befehle
  
üîß KONFIGURATION & TESTS:
  ollama-code --config                     Zeigt aktuelle Konfiguration
  ollama-code --test                       Testet Verbindung
  ollama-code --security-info              Zeigt Sicherheitsmodus-Info
  ollama-code --host                       Host-Setup-Hilfe

üåê UNIVERSELLE UNTERST√úTZUNG:
  ‚Ä¢ Automatische Host-Erkennung f√ºr WSL/Docker/VMs
  ‚Ä¢ Interaktive Befehlsbest√§tigung mit Pfeiltasten
  ‚Ä¢ Context-Management f√ºr 4k Token Limit
  ‚Ä¢ Glowing-Text-Effekt f√ºr KI-Ausgaben
        """
    )
    
    parser.add_argument(
        '--mode',
        choices=['local', 'vm', 'net'],
        default='local',
        help='Umgebungsmodus: local=localhost, vm=auto-detect host, net=netzwerk (Standard: local)'
    )
    
    parser.add_argument(
        '--host',
        action='store_true',
        help='Zeigt detaillierte Host-Setup-Hilfe f√ºr alle Umgebungen'
    )
    
    parser.add_argument(
        '--test',
        action='store_true',
        help='Testet Ollama-Verbindung mit gew√§hltem Modus (kombinierbar mit --mode)'
    )
    
    parser.add_argument(
        '--config',
        action='store_true', 
        help='Zeigt aktuelle Konfiguration und erkannte Umgebung'
    )
    
    parser.add_argument(
        '--security',
        choices=['safe', 'base', 'hell-out'],
        default='safe',
        help='Sicherheitsmodus: safe=nur chat, base=lokaler zugriff, hell-out=vollzugriff'
    )
    
    parser.add_argument(
        '--auto-accept',
        action='store_true',
        help='Aktiviert Auto-Accept f√ºr Befehlsausf√ºhrung'
    )
    
    parser.add_argument(
        '--security-info',
        action='store_true',
        help='Zeigt detaillierte Sicherheitsmodus-Informationen'
    )
    
    args = parser.parse_args()
    
    # Zuerst pr√ºfen ob es Info-Befehle sind (nicht die Hauptapp starten)
    if args.host:
        show_host_setup_help()
        return
        
    if args.test:
        # Umgebungsmodus setzen f√ºr korrekten Test
        config.set_environment_mode(args.mode)
        test_connection()
        return
        
    if args.security_info:
        print("üîí Verf√ºgbare Sicherheitsmodi:")
        for mode_key, mode_info in config.SECURITY_MODES.items():
            print(f"\nüìç {mode_key.upper()}:")
            print(f"   Name: {mode_info['name']}")
            print(f"   Beschreibung: {mode_info['description']}")
            print(f"   Dateizugriff: {'Ja' if mode_info['file_access'] else 'Nein'}")
            print(f"   Terminal: {'Ja' if mode_info['terminal_access'] else 'Nein'}")
            if 'file_operations' in mode_info:
                print(f"   Erlaubte Operationen: {', '.join(mode_info['file_operations'])}")
        return
    
    if args.config:
        # Modi setzen f√ºr korrekte Anzeige
        config.set_environment_mode(args.mode)
        config.set_security_mode(args.security)
        if args.auto_accept:
            config.AUTO_ACCEPT_ENABLED = True
            
        env_info = config.get_current_environment_info()
        sec_info = config.get_current_security_info()
        
        print("üìã Aktuelle Konfiguration:")
        print(f"   Umgebung: {env_info['mode']} ({env_info['url']})")
        print(f"   Sicherheit: {sec_info['mode']} ({sec_info['config']['name']})")
        print(f"   Auto-Accept: {'Ein' if sec_info['auto_accept'] else 'Aus'}")
        print(f"   Modell: {config.MODEL_NAME}")
        print(f"   Max Tokens: {config.MAX_CONTEXT_TOKENS}")
        return
    
    # Modi setzen und Hauptanwendung starten
    try:
        config.set_environment_mode(args.mode)
        config.set_security_mode(args.security)
        
        if args.auto_accept:
            config.AUTO_ACCEPT_ENABLED = True
            print("ü§ñ Auto-Accept aktiviert")
        
        if args.mode != 'local':
            print(f"üöÄ Starte ollama-code im {args.mode.upper()}-Modus...")
            
    except ValueError as e:
        print(f"‚ùå {e}")
        return
    
    # Hauptanwendung starten
    start_main_app()

if __name__ == "__main__":
    main()