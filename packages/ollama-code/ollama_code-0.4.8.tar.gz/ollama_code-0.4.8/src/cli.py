#!/usr/bin/env python3
"""
Kommandozeilen-Interface f√ºr ollama-code
Behandelt verschiedene Umgebungsmodi und Konfigurationen.
"""

import sys
import argparse
from pathlib import Path

# F√ºge das Projekt-Hauptverzeichnis zum Python-Pfad hinzu
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from src import config
from src.main_runner import main as start_main_app

def show_host_setup_help():
    """Zeigt Hilfe f√ºr die Host-Konfiguration"""
    print("üîß Host-Konfiguration f√ºr Ollama")
    print("=" * 50)
    print()
    print("F√ºr die verschiedenen Umgebungsmodi muss Ollama entsprechend konfiguriert werden:")
    print()
    print("üìç LOKALES SYSTEM (local):")
    print("   - Ollama l√§uft direkt auf demselben System")
    print("   - Standard-Konfiguration: http://localhost:11434")
    print("   - Keine weitere Konfiguration n√∂tig")
    print()
    print("üìç VIRTUELLE MASCHINE (vm):")
    print("   - Ollama l√§uft auf dem Host-System, Code in VM")
    print("   - Linux VM: Ollama muss auf allen Interfaces lauschen")
    print("     Befehl: OLLAMA_HOST=0.0.0.0 ollama serve")
    print("   - Windows Host: Firewall-Regel f√ºr Port 11434 erstellen")
    print("   - Docker: host.docker.internal:11434 verwenden")
    print()
    print("üìç NETZWERK (net):")
    print("   - Ollama l√§uft auf einem anderen Rechner im Netzwerk")
    print("   - Server-Konfiguration: OLLAMA_HOST=0.0.0.0 ollama serve")
    print("   - Client-Konfiguration: IP-Adresse des Servers anpassen")
    print("   - Firewall: Port 11434 freigeben")
    print()
    print("üîç Weitere Informationen:")
    print("   - Ollama Dokumentation: https://ollama.ai/")
    print("   - Netzwerk-Troubleshooting: ollama-code --test-connection")

def test_connection():
    """Testet die Verbindung zu Ollama"""
    import requests
    
    print(f"üîç Teste Verbindung zu Ollama...")
    print(f"   URL: {config.OLLAMA_URL}")
    print(f"   Modus: {config.CURRENT_ENVIRONMENT}")
    print()
    
    try:
        # Test der Basis-Verbindung
        response = requests.get(f"{config.OLLAMA_URL}/api/tags", timeout=10)
        
        if response.status_code == 200:
            print("‚úÖ Ollama-Server ist erreichbar!")
            
            # √úberpr√ºfe verf√ºgbare Modelle
            data = response.json()
            models = data.get("models", [])
            
            if models:
                print(f"üìã Verf√ºgbare Modelle ({len(models)}):")
                for model in models:
                    name = model.get("name", "Unbekannt")
                    size = model.get("size", 0)
                    size_mb = round(size / (1024 * 1024), 1)
                    print(f"   - {name} ({size_mb} MB)")
                
                # √úberpr√ºfe ob das konfigurierte Modell verf√ºgbar ist
                if any(config.MODEL_NAME in m.get("name", "") for m in models):
                    print(f"‚úÖ Konfiguriertes Modell '{config.MODEL_NAME}' ist verf√ºgbar!")
                else:
                    print(f"‚ö†Ô∏è  Konfiguriertes Modell '{config.MODEL_NAME}' nicht gefunden!")
                    print(f"   Installiere es mit: ollama pull {config.MODEL_NAME}")
            else:
                print("‚ö†Ô∏è  Keine Modelle installiert!")
                print(f"   Installiere ein Modell mit: ollama pull {config.MODEL_NAME}")
                
        else:
            print(f"‚ùå Ollama-Server antwortet mit Status {response.status_code}")
            print("   M√∂gliche Ursachen:")
            print("   - Ollama ist nicht gestartet")
            print("   - Falsche URL-Konfiguration")
            print("   - Netzwerk-/Firewall-Probleme")
            
    except requests.exceptions.ConnectError:
        print("‚ùå Verbindung fehlgeschlagen - Server nicht erreichbar!")
        print()
        print("üîß L√∂sungsvorschl√§ge:")
        print(f"   1. Pr√ºfe ob Ollama l√§uft: curl {config.OLLAMA_URL}/api/tags")
        print("   2. Pr√ºfe die Umgebungskonfiguration:")
        print("      - Lokal: ollama-code local")
        print("      - VM: ollama-code vm")  
        print("      - Netzwerk: ollama-code net")
        print("   3. Host-Setup-Hilfe: ollama-code host")
        
    except requests.exceptions.Timeout:
        print("‚ùå Verbindung ist zu langsam (Timeout)!")
        print("   - Pr√ºfe die Netzwerkverbindung")
        print("   - Server k√∂nnte √ºberlastet sein")
        
    except Exception as e:
        print(f"‚ùå Unerwarteter Fehler: {e}")

def main():
    """Hauptfunktion f√ºr die Kommandozeilen-Schnittstelle"""
    parser = argparse.ArgumentParser(
        description="Ollama Code - Autonomer KI-Entwicklungsassistent",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Beispiele:
  ollama-code                 Startet die Anwendung (lokaler Modus)
  ollama-code --mode vm       Startet im VM-Modus
  ollama-code --mode net      Startet im Netzwerk-Modus
  ollama-code --host          Zeigt Host-Konfigurationshilfe
  ollama-code --test          Testet Ollama-Verbindung
  ollama-code --config        Zeigt aktuelle Konfiguration
        """
    )
    
    parser.add_argument(
        '--mode',
        choices=['local', 'vm', 'net'],
        default='local',
        help='Umgebungsmodus: local (Standard), vm (Virtuelle Maschine), net (Netzwerk)'
    )
    
    parser.add_argument(
        '--host',
        action='store_true',
        help='Zeigt Host-Konfigurationshilfe'
    )
    
    parser.add_argument(
        '--test',
        action='store_true',
        help='Testet die Verbindung zu Ollama'
    )
    
    parser.add_argument(
        '--config',
        action='store_true', 
        help='Zeigt aktuelle Konfiguration'
    )
    
    args = parser.parse_args()
    
    # Zuerst pr√ºfen ob es Info-Befehle sind (nicht die Hauptapp starten)
    if args.host:
        show_host_setup_help()
        return
        
    if args.test:
        # Umgebungsmodus setzen f√ºr korrekten Test
        config.set_environment_mode(args.mode)
        test_connection()
        return
        
    if args.config:
        # Umgebungsmodus setzen f√ºr korrekte Anzeige
        config.set_environment_mode(args.mode)
        info = config.get_current_environment_info()
        print("üìã Aktuelle Konfiguration:")
        print(f"   Modus: {info['mode']}")
        print(f"   URL: {info['url']}")
        print(f"   Beschreibung: {info['description']}")
        print(f"   Modell: {config.MODEL_NAME}")
        return
    
    # Umgebungsmodus setzen und Hauptanwendung starten
    try:
        config.set_environment_mode(args.mode)
        if args.mode != 'local':
            print(f"üöÄ Starte ollama-code im {args.mode.upper()}-Modus...")
    except ValueError as e:
        print(f"‚ùå {e}")
        return
    
    # Hauptanwendung starten
    start_main_app()

if __name__ == "__main__":
    main()