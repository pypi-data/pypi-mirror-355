[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "datalineagepy"
version = "1.0.6"
authors = [
    {name = "Arbaz Nazir", email = "arbaznazir4@gmail.com"},
]
description = "A comprehensive Python library for tracking and visualizing data lineage in pandas and PySpark workflows"
readme = "README.md"
license = {text = "MIT"}
requires-python = ">=3.8"
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research", 
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9", 
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: Scientific/Engineering :: Information Analysis",
    "Topic :: Database",
    "Topic :: System :: Logging",
    "Topic :: System :: Monitoring",
]
keywords = [
    "data-lineage", 
    "pandas", 
    "pyspark", 
    "data-engineering", 
    "data-governance", 
    "data-quality",
    "etl",
    "data-pipeline",
    "data-tracking",
    "metadata",
    "data-catalog",
    "data-discovery"
]
dependencies = [
    "pandas>=1.3.0",
    "numpy>=1.20.0", 
    "networkx>=2.5",
    "plotly>=5.0.0",
    "jinja2>=3.0.0",
    "pydantic>=1.8.0"
]

[project.optional-dependencies]
# Database connectors
database = [
    "sqlalchemy>=1.4.0",
    "psycopg2-binary>=2.8.0",
    "pymysql>=1.0.0", 
    "pyodbc>=4.0.0"
]

# File format support
files = [
    "pyarrow>=5.0.0",
    "fastparquet>=0.8.0",
    "chardet>=4.0.0",
    "openpyxl>=3.0.0",
    "ijson>=3.1.0"
]

# Cloud storage support
cloud = [
    "boto3>=1.20.0",
    "azure-storage-blob>=12.0.0", 
    "google-cloud-storage>=2.0.0",
    "minio>=7.0.0"
]

# Streaming support
streaming = [
    "kafka-python>=2.0.0",
    "confluent-kafka>=1.8.0",
    "redis>=4.0.0"
]

# Big data support
spark = [
    "pyspark>=3.0.0"
]

# Machine learning support
ml = [
    "scikit-learn>=1.0.0",
    "mlflow>=1.20.0"
]

# Development dependencies
dev = [
    "pytest>=6.0.0",
    "pytest-cov>=3.0.0",
    "black>=22.0.0",
    "flake8>=4.0.0",
    "mypy>=0.950",
    "pre-commit>=2.15.0"
]

# All optional dependencies
all = [
    "datalineagepy[database,files,cloud,streaming,spark,ml]"
]

[project.urls]
Homepage = "https://github.com/Arbaznazir/DataLineagePy"
Documentation = "https://github.com/Arbaznazir/DataLineagePy/blob/main/docs/index.md"
Repository = "https://github.com/Arbaznazir/DataLineagePy.git"
"Bug Tracker" = "https://github.com/Arbaznazir/DataLineagePy/issues"
Changelog = "https://github.com/Arbaznazir/DataLineagePy/blob/main/CHANGELOG.md"

[project.entry-points."datalineagepy.connectors"]
postgresql = "datalineagepy.connectors.database:PostgreSQLConnector"
mysql = "datalineagepy.connectors.database:MySQLConnector"
sqlite = "datalineagepy.connectors.database:SQLiteConnector"
file = "datalineagepy.connectors.file:FileConnector"

[tool.setuptools]
package-dir = {"" = "."}

[tool.setuptools.packages.find]
where = ["."]
include = ["datalineagepy*"]
exclude = ["tests*", "docs*", "examples*"]

[tool.setuptools.package-data]
datalineagepy = ["*.json", "*.yaml", "*.yml", "templates/*"]

[tool.black]
line-length = 88
target-version = ['py38']

[tool.isort]
profile = "black"
line_length = 88

[tool.mypy]
python_version = "3.8"
warn_return_any = true
warn_unused_configs = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = "test_*.py"
python_classes = "Test*"
python_functions = "test_*"
addopts = "-v"

[tool.coverage.run]
source = ["datalineagepy"]
omit = ["*/tests/*", "*/examples/*"]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise AssertionError",
    "raise NotImplementedError",
] 